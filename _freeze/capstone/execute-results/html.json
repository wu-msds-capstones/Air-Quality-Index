{
  "hash": "7f971dbc14029856ed6ef8e958a847c8",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle-block-banner: true\ntitle: \"Unveiling the Drivers of Clean Air\"\nsubtitle: \"Analysis of Portland Air Quality (AQI)\"\ndate: \"2024-08-01\"\nauthor:\n  - name: Stéphane Berhault\n    orcid: 0009-0003-5357-629X\n    email: sgberhault@willamette.edu\n    affiliation: \n      - name: Willamette University\n        city: Portland\n        state: OR\n        url: https://willamette.edu\n  - name: Jake Warmflash\n    email: jwarmflash@willamette.edu\n    affiliation: \n      - name: Willamette University\n        city: Portland\n        state: OR\n        url: https://willamette.edu\nkeywords:\n  - AQI\n  - Time Series\n  - Prophet\n  - SARIMAX\n  - Scikit-Learn\nexecute:\n  echo: false\n  warning: false\njupyter: python3\nformat:\n  html:\n    theme: cerulean\n    fig-width: 8\n    fig-height: 6\n    code-fold: true\n    code-tools:\n      source: false\n      toggle: false\n      caption: none\n    smooth-scroll: true\n    toc: true\n    toc-location: left\n    toc-title: Contents\n    number-sections: false\n    other-links:\n      - text: Airnow Open Data\n        href: https://www.airnow.gov\n    code-links:\n      - text: Sweetviz Analysis Report\n        icon: file-code\n        href: SWEETVIZ_REPORT.html\n      - text: ydata Analysis Report\n        icon: file-code\n        href: your_report2.html\n    html-math-method: mathjax\n    css: styles.css\n---\n\n# Introduction\nIn their journal article published in The American Journal of Public Health, Jacobs, Burgess, and Abbott tell the story of the Donora Pennsylvania Smog crisis. On October 30, 1948, the Donora High School Football team played through a dense smog to complete the game with hundreds of fans in the audience, despite very poor visibility. The team, fueled by resilience, took pride in playing through poor conditions, a testament to the high spirit of the small town. Soon after, calls to the town’s medical offices began flooding in, complaining of difficulty breathing and respiratory issues. Donora, Pennsylvania, was a town of metalworks, built by the American Steel and Wire company and the Donora Zinc Works company, which made up major parts of the town’s economy. The heavy smog and pollution clouds that covered the sky had been viewed as a sign of prosperity, owing to the industrial might that powered their economy. Within just twelve hours, seventeen people would be dead, 1440 seriously affected, and 4470 with mild to moderate conditions---almost half the town’s working population (Jacobs, Burgess, Abbott). \n\nThis event, known as the Donora Smog of 1948, prompted the country into taking a closer look at the negative impacts of air pollution. Widespread debate surrounding the event led to the first legislation aimed at regulating the air quality within the United States, ushering in a new era of tracking, combatting, and reversing the ill effects of poor air quality. The quality of air we breathe has direct impacts on our health. We must understand the factors that contribute to poor air quality and how we individually and collectively contribute to these changes. Until we can visualize the impact we have on our atmosphere, we will continue behavior that negatively impacts the air around us. \n\nIn this project, we will focus on the key factors influencing air quality in Portland, Oregon. We aim to understand the complex interplay between various environmental and human-made factors that contribute to high air pollution levels. Initially, we were surprised to discover that Portland, the city we reside in, has some of the best air quality for a city of its size in the United States. This led us to narrow our focus to understanding the factors that contribute to these favorable outcomes in this city.\n\nOur project aims to develop and validate machine learning models to analyze the various factors influencing air quality. By focusing on Portland in comparison to other large US cities, we hope to find things Portland does that lead to the greater AQI outcomes. Our approach will consider a range of variables, including meteorological conditions, pollution sources, transit systems, park land, and livestock. Through this analysis, we aim to provide actionable insights and recommendations for sustaining and improving air quality. By examining both the contributors to clean air and the sources of pollution, we can understand the factors affecting air quality and develop comprehensive strategies for enhancement.\n\n\n# Background\nFederal regulation of air quality in the United States began in 1955 with the Air Pollution Control Act. This new piece of legislation provided funding for initial research into air quality and pollution in the US. Building off this and privately funded research, Congress passed the Clean Air Act of 1963, establishing the first federal regulation for controlling air pollution. This act established a new federal program within the US Public Health Service, dedicated to the monitoring and control of air quality. In 1967, Congress passed the Air Quality Act, which introduced more federal oversight and enforcement policies, allowing extensive monitoring of interstate air pollution. This all led to the passage of the 1970 Clean Air Act, aimed at restricting and regulating emissions, measuring and reducing pollutant particles, and addressing upcoming pollution threats (Environmental Protection Agency).\n\nAlso established in 1970, the Environmental Protection Agency (EPA) implemented and monitored the requirements established by these rulings. The EPA's authority extended beyond federal lands and roads to include all companies operating within the United States. Enforcement authority was expanded to allow upholding these established standards, and prevent companies from circumventing the law.  Much of the improvement in the quality of air in the US over the past fifty years can be attributed to these regulations. In 1990, when deaths due to air quality were first measured, an estimated 135,000 Americans died. By 2010, that number had dropped to 71,000 (Zhang et al.). Despite the significant improvements led by the federal guidelines of the late 70s, nearly four in ten Americans still live in places where they are exposed to unhealthy air (American Lung Association).\n\nIn 1999, the EPA developed the Air Quality Index (AQI), creating an easily understood measurement of air quality. The AQI measures air pollution levels on a scale from 0 to 500, divided into six categories. A score of 0 to 50 represents good air quality which poses little or no risk to those breathing it in, while a score above 300 signifies emergency conditions, an extremely high risk which impacts everyone. This measurement is mainly derived from five major pollutants: ozone, particulate matter (2.5μm and 10μm), carbon monoxide, nitrogen dioxide, and sulfur dioxide (Airnow.gov). Poor air quality has been linked to a variety of diseases including respiratory infections, stroke, heart disease, lung cancer, and chronic obstructive pulmonary disease, among others (World Health Organization). An estimated seven million premature deaths annually can be attributed to air pollution, which equates to a global mean loss of life expectancy of 2.9 years, making it the largest environmental risk factor for disease and premature death (Fuller, Landrigan, Balakrishnan, et. al.). Thus, it is important to understand factors that contribute to poor air quality, and outcomes that can be attributed to the state of the AQI.\n\nThese harmful factors can originate from a variety of sources. Anything that releases a foreign substance into the air can lower the quality of the air. This includes smoking, vehicle exhaust, combustion processes for production and manufacturing, household cleaning products, appliances, central air and heating systems, agriculture pesticides, livestock, shipping and transportation, and much more. Individually, we can reduce our individual contributions by lowering our reliance on personal vehicles, watching our power usage, supporting companies that monitor and address their emissions, and more. However, there are many factors beyond our control. Larger pollutant sources, such as manufacturing and transportation, are often regulated to some extent but may still release significant amounts of pollutants into the atmosphere which we as individuals have no say over (Manisalidis, Stavropoulou, Stavropoulos, Bezirtzoglou). It is challenging to restrict and watch our personal contributions to the polluting of the environment without worrying about what others are doing. Measuring and analyzing the impact these pollutants have on air quality is a crucial step towards addressing these issues.\n\n## Data Ethics\nThe ethical implications of conducting this analysis should always be considered and addressed. Air quality has historically impacted lower income communities significantly more. Marginalized communities may be built near major pollution sources such as factories or highways. In Portland, for example, Interstate 5 completed construction in 1966. It was part of an Oregon State Highway Department (OSHD) development, a project run by the state as a part of the Federal Aid Highway Act. The highway was built on the existing Minnesota Avenue, cutting North Portland, the heart of Portland’s African American community in half. It was decided to avoid affecting the higher income downtown properties. In fact, the OSHD contracted work on the Minnesota Ave portion of the highway to private contractors, in an effort to avoid a political battle (Oregon Encyclopedia). Today, the neighborhoods surrounding the large highway have worse AQI outcomes than those further away, all other factors equal (Shandas and George). Any recommendations given by this analysis should properly consider the ramifications of those impacted. \n\nAnother important ethical issue to be aware of is data transparency. Data can be used to push a specific narrative without faking or editing the specific data points. By leaving out important information, pushing correlated data as causation to push an agenda, or by purposely misconstruing what the data mean, one can create a narrative that can misinform or deceive readers. All analysis methodology must be openly discussed to ensure full understanding by audiences. This leads to credibility, reproducibility, and trust in the methods and conclusions of any piece of data analysis. All data is sourced from credible online sources that are open about their collection methods. Data privacy is addressed and no personalized information is given. Limitations are also addressed allowing readers to understand where any uncertainty may be.\n\n\n# Methods\nPython will be the primary programming language used to conduct this analysis. We will also use R language in statistical applications. To perform our analysis, we will employ the NumPy and Pandas libraries for data manipulation, Matplotlib and Seaborn for visualization, and Time Series forecasting algorithms such as Prophet and SARIMAX. We will address data inconsistencies, missing values and ensure that data is in a tidy format. We may need to normalize or standardize data if necessary and create new features through aggregation to enhance the model’s performance.\n\n## Prophet\nProphet is an open-source forecasting tool developed by Meta, designed for forecasting time series data. It is suited for datasets with strong seasonal, monthly, weekly, or daily patterns, and it handles missing data and outliers well. We utilized prophet to gain a quick understanding of our AQI patterns, seeking to understand basic trends before conducting a more thorough analysis.\n\nKey features of Prophet include seasonality detection and holiday incorporation, while providing easy use and understanding for users. We can use this software to get complex understanding from simple applications.\n\nTo conduct this analysis, we prepare data into a two column table, date and AQI. Prophet uses the trends of past data to highlight similarities over days of the year, weeks, months, and seasons. From this, prophet is able to generate its predictions, cross validate, and give performance metrics such as mean absolute percentage error to quantify the accuracy of the results\n\n## SARIMAX​​\nThe most common method used in time series forecasting is known as the ARIMA model. We will use an extended version called SARIMAX (*Seasonal Auto Regressive Integrated Moving Averages with exogenous factor*)\n\n- *(S) Seasonality*: Accounts for recurring patterns or cycles in the data.\n- *(AR) AutoRegressive*: Uses past values to predict future values.\n- *(I) Integrated*: Applies differencing to make the time series stationary.\n- *(MA) Moving Average*: Uses past forecast errors in the prediction.\n- *(X) eXogenous factors*: Incorporates external variables that may influence the forecast.\n\nThe SARIMAX model is used when the data sets have seasonal cycles. In the dataset concerning the air quality/AQI there is a seasonal pattern. SARIMAX is a model that can be fitted to time series data in order to better understand or predict future points. SARIMAX is particularly useful for forecasting time series data that exhibits both trends and seasonality.\nThere are three distinct integers (p,d,q) that are used to parametrize SARIMAX models. Because of that, SARIMAX models are denoted with the notation SARIMAX(p,d,q). Together these three parameters account for seasonality, trend, and noise in datasets:\n\n- *p* is the auto-regressive part of the model. It allows us to incorporate the effect of past values into our model.\n- *d* is the integrated part of the model. This includes terms in the model that incorporate the amount of differencing (the number of past time points to subtract from the current value) to apply the time series.\n- *q* is the moving average part of the model. This allows us to set the error of our model as a linear combination of the error values observed at previous time points in the past.  \n\nWe use a tuning technique called grid search method that attempts to compute the optimum values of the hyperparameters. We are trying to find the right p,d,q values that would be given as an input to the SARIMAX time series model.\n\n## Akaike Information Criteria (AIC)\nThe Akaike Information Criterion (AIC) is a measure used to compare different statistical models. It helps in model selection by balancing the goodness of fit and the complexity of the model. When comparing two models, the one with the lower AIC is generally \"better\".\n\nHere’s how to interpret the AIC value:\n\n- *AIC Value*: A lower AIC value indicates a better-fitting model. It means the model has a good balance between accuracy and complexity.\n- *Comparative Measure*: AIC is most useful when comparing multiple models. The model with the lowest AIC among a set of candidate models is generally preferred.\n- *Penalty for Complexity*: AIC includes a penalty for the number of parameters in the model. This discourages overfitting by penalizing models that use more parameters without a corresponding improvement in fit.\n\n## Train-Test-Split\nRigorous validation is paramount to establishing the model's reliability and practical application. To ensure the model's generalizability, we will employ a train-test split. This approach safeguards against overfitting by exposing the model to unseen data, allowing for a more accurate assessment of its predictive capabilities.\n\nBy partitioning the dataset, we can:\n\n- *Evaluate performance*: Measure the model's accuracy on unseen data.\n- *Detect overfitting*: Identify discrepancies between training and testing performance.\n- *Assess generalization*: Determine the model's ability to handle new data.\n- *Quantify reliability*: Calculate confidence intervals for prediction accuracy.\n- *Iteratively improve*: Use insights to refine the model.\n\nThis rigorous process underpins the credibility and utility of our research findings.\nTo split the data, we follow the recommended 70:30 ratio, 70% of the data is the training data, and 30% of the data is the testing data.\n\n## Hypothesis Testing\nHypothesis tests for significance are conducted to understand the significance of differences in datasets. Statistics are done in R using a variety of statistical methods and measurements:\n\n- *Null Hypothesis*: This serves as the baseline of a hypothesis test. It represents the idea that there is no effect, difference, or relationship between tested variables. Any observed differences are due to random chance. \n- *Alternate Hypothesis*: On the other hand, the alternative hypothesis suggests a potential effect, difference, or relationship between tested variables exists. It reflects what is hoped to be found by the data.\n- *Independence*: The idea that data in one sample or population has no impact on the data in another sample or population.\n- *Normal Distribution*: A continuous probability distribution symmetric around the mean. It is characterized by mean and standard deviation.\n- *Normal QQ Plot*: A plot to measure the normality of a distribution. It compares the quantiles of a dataset against the quantiles of a theoretical normal distribution. Data is mapped along a y=x trendline. Deviations of the data from the trendline indicate non normality. An “S” shaped bend suggests data with heavy or light tails. A convex or concave bend suggests skewness in the distribution.\n- *Histogram*: Plot that displayed data frequencies of values within specified intervals known as bins. Histograms are used to visualize the shape and spread of a distribution.\n- *Welch Two Sample t-test*: This type of hypothesis test measures the statistical significance of the difference in mean of the two samples. Unlike the Student’s  two sample t-test, the Welch two-sample t-test is used in cases where the groups being compared have unequal variances. A Welch two sample t-test includes the following:\n\t- *t-Statistic (t)*: Difference between sample means relative to variance of samples. Larger t-statistics indicate larger differences between means.\n\t- *Degrees of Freedom (df)*: Amount of information available to estimate variance of sample means.\n\t- *p-Value*: The probability of observing the sample data or something more extreme if the null hypothesis is true. A small p-value (< 0.05) suggests the observed difference is statistically significant.\n\t- *95 Percent Confidence Interval*: Range in which the true difference in means is 95% likely to lie within.\n\n## Machine Learning\nMachine learning is done in scikit-learn, an open source ML library built in Python. It is built on top of other common Python libraries such as NumPy, Pandas, and Matplotlib. The following tools are used:\n\n- *One Hot Encoder*: Transforms categorical data into a binary matrix. Each category is represented as a vector where one element is tagged with a 1 and all others are tagged as 0. This is done for certain machine learning algorithms that require all discrete data.\n- *Standard Scaler*: Used to normalize or standardize numerical data. Certain machine learning algorithms are affected by unscaled data and therefore require normalized data.\n- *Transformer*: Can be used to change multiple variables in one step in methods such as One Hot Encoder and Standard Scaler.\n- *Pipeline*: Allows multiple functions in a series of steps that can include transformers and models. Incorporates chaining to supply the output of one step as the input of the next step.\n- *Feature Selection*: Chooses a subset of most relevant features, with the ability to specify how many features.\n- *Hyperparameter Optimization*: Selects the best set of hyperparameters in a model. These hyperparameters are set before training and control various aspects of the training process and model behavior. The optimization method used is a Randomized search. This evaluates a fixed number of random combinations from a specified distribution. This is far more efficient than a Grid search which systematically checks every single combination of the specified hyperparameter distribution.\n- *Cohen Kappa Score*: A statistical measure used to assess agreement between two classifiers when they categorize items into classes. In ML specifically, the Cohen Kappa Score is used to evaluate agreement between predicted and actual labels in classification algorithms. It is measured on a scale from -1 to 1, where 1 represents perfect agreement in classifiers, 0 represents agreement being no better or worse than random chance, and -1 represents perfect disagreement.\n- *Random Forest Model*: An ensemble model used in prediction tasks. It combines multiple decision trees and aggregates their predictions to improve performance and reduce overfitting.\n- *Confusion Matrix*: Measures and visualizes the accuracy of a classification model. It breaks down raw numbers of correctly and incorrectly classified values.\n- *Classification Report*: A detailed evaluation of the prediction model. Includes: \n    - *Precision*: The ratio of correctly predicted positive observations to the total predicted positives\n    - *Recall*: The ratio of correctly predicted positive observations to all observations\n    - *F1 score*: Mean of precision and recall\n    - *Support*: Number of observations\n\nReference Machine Learning Metrics Table in Appendix for additional information.\n\n\n# Data\nThe data for this project was initially scattered across multiple sources and required significant organization and compilation. The focus of this project is on the air quality in Portland, Oregon, so various data sources were aggregated and processed to compare a variety of air quality indicators. There is a significant amount of missing data due to incomplete collection which will be addressed via filling in and row dropping.\n\n### Air Quality Data\nAir quality data, specifically AQI values, were obtained from the United States Environmental Protection Agency (EPA) pre generated data files. The AQI values are calculated daily, based on a variety of factors including criteria gasses and measured pollutant concentrations, and measures how harmful breathing the air is. AQI is classified into one of six categories from ‘good’ to ‘hazardous’, each having long term health effects associated with it. The files were given daily on a county wide basis, separated into different files by year. After stacking year outputs together in R, columns regarding date, location (state, county), AQI, and AQI category were brought into the database.\n\n### Meteorological Data\nHistorical weather data was also sourced from the EPA database, measured by thousands of weather stations across the country. Measurements tracked include temperature, wind speed, air pressure, and humidity. Temperature is measured in degrees fahrenheit. Wind speed is measured in knots, which are defined as one nautical mile per hour (equivalent to approximately 1.15mph). Wind speed is important in air quality as winds can blow different pollutants around and move and spread wildfires. Pressure is measured in millibars, where 1013.25 millibars is the standard atmospheric pressure (Earth’s pressure at mean sea level). Finally, humidity is measured in percent relative humidity. This is the amount of water vapor in the air as a percentage of the maximum amount of water vapor possible at a given temperature. Humidity can make it more difficult to breathe and sweat, make the air feel hotter than it is, and prevent air pollutants from dispersing as easily. This data was given daily by city, separated into different files by year. Measurements were taken hourly, but pre-aggregated in the source database, giving an average value over the twenty four hours and a maximum value. After stacking years in R, columns regarding date, location (state, city), weather observation average and maximum, and observation unit were brought into the database.\n\n### Pollution Source Data\nPollution data was again sourced from the EPA database, separated by criteria gasses (CO, NO2, O3, SO2), Toxins (lead), and particulate matter (PM2.5 and PM10). Criteria gas Carbon Monoxide (CO) is measured in parts per million, and is especially dangerous as it is both colorless and odorless. CO binds to hemoglobin in the blood, making the transportation of oxygen around the body more difficult. Nitrogen Dioxide (NO2)  is dangerous to breathe in at high levels. It can cause swelling in the throat, burning, reduced oxygenation of body tissues, and fluid build up in the lungs. It is released in many common combustion reactions including in cars, coal plants, and cigarettes. It is measured in parts per billion. Ozone (O3) can harm our ability to breathe, especially in older people, children, and people with asthma. It is measured in parts per million. Sulfur Dioxide (SO2), measured in parts per billion, can irritate the eyes, mucous membranes, skin, and respiratory tract. Lead is a toxin which can increase the risk of high blood pressure, cardiovascular problems, and complications during pregnancy. While exposure has gone down significantly in the recent decades after use in gasoline, it still remains a dangerous toxin to breathe in. It is measured in micrograms per cubic meter. PM2.5 and PM10 are particulate matter, small inhalable particles with diameters of 2.5 microns or smaller, and 10 microns or smaller respectively. PM2.5 includes all sorts of common particles, metals, and organic compounds. PM10 includes dust, pollen, molds, and other larger (but still very small) particles. Due to the variability of particles included in the PM classification, there are a wide range of negative health impacts that come from breathing in these particles. PM2.5 and PM10 are measured in micrograms per cubic meter.\n\nThis data was given daily by city, separated into different files by year. They are sourced from thousands of individual sources, which measure various selections of these pollution sources. Because of the variety of different pollutants being measured, there was a significant amount of missing data, especially from small towns. Measurements were taken hourly, pre-compiled into a daily average and maximum. After stacking years in R, columns regarding date, location (state, city), pollutant observation average and maximum, and observation unit were brought into the database.\n\n### Public Transit Data\nInformation on motor buses taken from the National Transit Database, produced by the Federal Transit Administration. Includes information of bus systems and ridership by city, separated by year. Data is recorded yearly, encompassing annual totals for information such as number of buses, total revenue, passengers, and miles driven for the respective city transit systems. Information was given in yearly CSVs, separated by the city transit system. For cities with multiple systems, data was combined. Only motorbus data was compiled, which may not be reflective of cities with other large methods of public transportation, such as the New York subway system. Only public transit information was able to be collected. Accessible data on cars and trucks could not be found. This will be further discussed in the limitations section of the conclusion. After stacking years in R, columns regarding date, location (state, city), transport mode, number of buses, passenger trips in hours and miles, and bus operations in hours and miles were brought into the database.\n\n### Land Area Data \nCity and county area data was collected from the 2020 U.S. Census, collected by the U.S. Census Bureau. It is measured in km^2^. City, county, state, city area, and county area columns brought into the database.\n\n### Park Area Data\nPark areas data is sourced from the Trust for Public Land’s 2024 annual City Park Survey. This information is collected via survey from a variety of park agencies including Individual Parks and Recreation agencies, the National Park Service, Bureau of Land Management, Regional Park authorities, Private Conservancy, Watershed Management Agencies, private park services, and more. Totals are compiled by the Trust for Public Land, and measured in acres. Acreage is initially given in integers. Only location (city, state) and park area columns are brought into the database. \n\n### Livestock Data\nInformation on livestock numbers collected on a county wide basis from the 2017 United States Census of Agriculture by the National Agricultural Statistics Service within the United States Department of Agriculture. Cattle include cows and bulls raised for meat consumption, cows for milk production, and calves. Hogs includes all pigs, adult and adolescent. Although there are colloquial differences for the animals called hogs and pigs, they refer to the same species, though ‘hogs’ generally refers to the larger members of the species. Sheep includes sheep raised for wool production and lambs. Numbers may have slight inaccuracies for areas with low numbers to prevent disclosing identifying information and are marked with a ‘D’. All of these data points will be replaced with zero. Location (county, state) and livestock varieties (cattle and calves, hogs, sheep and lambs) columns are collected and added to the database.\n\n### Population Data\nData on population and population density was sourced from the Simplemaps United States Cities database, which is built from multiple sources including the U.S. Geological Survey and the U.S. Census Bureau. Data was last updated on May 6, 2024, reflecting very up to date information. \n\n## Data Organization\nGiven the raw data available, the table structure was simplified compared to the original data sources. Data was organized around the air_quality table. This table tracks AQI, pollutant, weather and toxin data daily for each location. It includes all 1438 locations with a line for each of the 2922 days in the eight year time period, reaching a total of over 4.2 million rows. Location is split into a separate table to reduce repeated data. This table lists cities, labeled with their city name, county, and state. It includes metropolitan area population data given in raw numbers and as a density. Additionally, this table includes the city area in square kilometers and park area in acres. The aqi_category table is a short list of AQI value categories (Good, Unhealthy, Hazardous, etc.) with their respective AQI value range as minimum and maximum values. The yearly_transit table is connected to the location table and gives the information for the transit system of the respective city during the specified year. Finally, the livestock table, also connected via locations, includes counts for cattle, hogs, and sheep. \n\nThe central table has a compound primary key composed of location_id and date. Each other table has a serialized primary key, which are used to connect to each other. Several additional indexes are included on columns that will be queried often. Finally, constraints have been added to limit unusual or impossible data. For example, an AQI value less than 0 or greater than 500 would be impossible and thus would be caught by the constraint.\n\nTracking these identifiers independently allows for accurate analysis of changes over time and across different areas, and allows adding new information should we need to update the database. Figure 1 illustrates the resulting ERD diagram using drawSQL.\n\n![Figure 1: ERD diagram](https://github.com/wu-msds-capstones/Air-Quality-Index/blob/main/images/erd_diagram_final_extended.png?raw=true)\n\n\n# Prophet AQI Trend Forecasting and Statistical Testing\n\nTo gain an understanding of how Portland's AQI differs from other large cities, we can start by running a hypothesis test to determine the significance.\n\nInitially we can run a two sample t-test to show that Portland's AQI average is statistically greater than the average AQI of all large metropolitan areas within the US. We compare the sample of Portland AQI datapoints in the time period with the sample of all metropolitan areas with a population greater than one million.\n\n**Null Hypothesis**: The Portland AQI is greater than or equal to the AQI of all large metro cities in the US.\n\n**Alternate Hypothesis**: The Portland AQI is less than the AQI of all large metro cities in the US.\n\n**Assumptions**:\n\n1.  Simple Random Sample: Data is a simple random sample. We have selected 10% of values from each population set.\n\n2.  Independence: AQI in Portland does not affect AQI in the rest of the country. However, the dataset for the large metro areas does include Portland, so Portland AQI will be repeated within both population groups. Both groups are largely independent, though this should be noted.\n\n3.  Normal Distribution:\n\n![Figure 2: PDX Vs Large Metro Areas Distribution](https://github.com/wu-msds-capstones/Air-Quality-Index/blob/main/images/normal_distribution_1_pdx_vs_lma.png?raw=true)\n\nFrom the QQ plots and histograms, we can see both datasets are clearly not normally distributed. They have long tails to the right. However, since the tails have such low frequencies and the samples are very large, this likely will not impact the results.\n\nThe partial violations of the assumptions in the t-test in our analysis suggest that the conclusions should be considered with a degree of caution.\n\n**Two-Sample t-Test Portland AQI vs Large Metro Areas AQI**\n\n![Figure 3: Two-Sample t-Test](https://github.com/wu-msds-capstones/Air-Quality-Index/blob/main/images/hypothesis_test_results_1_pdx_vs_lma.png?raw=true)\n\nBased on the low P-value of 6.862\\*10^-4^, we can safely reject the null hypothesis. We conclude that Portland's AQI mean is not greater than or equal to the AQI of all large metropolitan areas. This agrees with our initial observations on the greater AQI outcomes of Portland, and specifies the significance of this statistically.\n\n## Data Forecasting with Prophet\n\nProphet by Meta is used as time series prediction to estimate and map trends based on our data. We use this to see how AQI trends vary by day, month, and year. It is also able to give us a forecast for a given period after the end of our data which we can analyze and use to anticipate future AQI values.\n\nTo use the package, data must be in the format of a two column graph, with the first column being the date data, and the second being the variable being mapped and predicted. In this case, this predicted variable is AQI.\n\nThe package allows a future period to be generated, which can be specified and added to the end of the time data. It can then predict future AQI values for the new data period.\n\nThe graph below (figure 4324), shows the supplied data with the future prediction over the future period. The actual values are shown with the black datapoints, and the blue line represents the prediction. The upper and lower bounds of the error are represented with the transparent blue area. Each year, the data spikes during the late summer to early fall. Even more significant is the large spike in September 2020. What caused it? How significant was it?\n\n![Figure 4: Prophet Prediction](https://github.com/wu-msds-capstones/Air-Quality-Index/blob/main/images/prophet_pdx_trend_and_prediction.png?raw=true)\n\n## 2020 Wildfires\n\nIn September 2020, a wildfire ravaged the state of Oregon, as well as many other areas of the United States and Canada. The fires burned more than one million acres of land, destroying thousands of homes, and killing 11 people. 500,000 Oregonians were on evacuation alert, and 40,000 were actually forced to leave (Oregon Department of Emergency Management). Anyone around during that time will recall the orange skies, thick atmosphere, and strong smoke smell, but how unusual was this period actually?\n\nTo understand, we will conduct a two sample t-test to see whether or not this month had greater than usual AQI.\n\n**Null Hypothesis**: September 2020 AQI less than or equal to AQI of entire period in Portland\n\n**Alternate Hypothesis**: September 2020 AQI greater AQI of entire period in Portland\n\n**Assumptions**:\n\n1.  Simple Random Sample: Data is not a simple random sample. Since there are so few datapoints for the September 2020 population (30 datapoints), taking a 10% sample may not be suitable to accurately capture the variance of this month. Thus, it was decided to use the entire population as the sample. A 10% sample will be taken of the entire Portland data population.\n\n2.  Independence: AQI in September 2020 does not affect AQI in the rest of the timeframe.\n\n3.  Normal Distribution:\n\n![Figure 5: Wildfire Distribution](https://github.com/wu-msds-capstones/Air-Quality-Index/blob/main/images/normal_distribution_2_wildfires.png?raw=true)\n\n\nFrom the QQ plots and histograms, we can see both datasets are clearly not normally distributed. They have long tails to the right, and the September 2020 dataset is oddly shaped due to lack of data.\n\nThe partial violations of the assumptions in the t test in our analysis suggest that the conclusions should be considered with a degree of caution.\n\n**Two-Sample t-Test  September 2020 vs Full Period of Portland AQI**\n\n![Figure 6: Two-Sample t-Test](https://github.com/wu-msds-capstones/Air-Quality-Index/blob/main/images/hypothesis_test_results_2_wildfires.png?raw=true)\n\nBased on the low p value of 1.85\\*10^-3^, we reject the null. We conclude that the September AQI in Portland is not less than or equal to the AQI for the entire period. The wildfire had a significant effect on the air quality, making it much more difficult to breathe. This aligns with the observation of the large spike during this period. We must do more to address and combat the wildfires that not only harm the air we breathe, but cause long lasting damage to the local environment.\n\n## AQI Trends\n\nProphet's plot component function allows us to see specific trends including the total (entire eight years), weekly, and yearly trends in figure 21111. \n\n![Figure 7: Prophet Component Trend Aggregations](https://github.com/wu-msds-capstones/Air-Quality-Index/blob/main/images/prophet_components_plot_aqi.png?raw=true)\n\nThis allows us to see how AQI changes by day. In the top full time span graph, it shows the potential spread of data for the predicted period with the transparent blue area. We can also see that day of the week tends to have very little impact on the trend (it may look significant but it is only moving up and down less than 1.5 AQI between days). Finally, from the yearly graph we can see the consistent increase during the late summer to mid fall each year.\n\n## Cross Validation\n\nHow accurate are these predictions? A cross validation predicts over the period from the cutoff date up to specified date in the ds column date.\n\nCross validating the predictions allows us to create many estimates from a starting date up to an end date within out timeframe. In this instance, the tool predicts using start dates every half a year. It will predict AQI for that date to every day up to a year after the start date, giving us 365 estimates per start date. We then compare all estimations seeing how accurate the prediction is for a number of days after the start date.\n\nThe tool allows us to measure the difference in predicted y and actual y with a variety of different measurements. In figure 559955 below, we have selected mean absolute percent error, to show how if the error on average increased as the prediction got further from the starting point.\n\n![Figure 8: Prophet Error on Cross Validated Estimates](https://github.com/wu-msds-capstones/Air-Quality-Index/blob/main/images/prophet_cross_val_aqi.png?raw=true)\n\nThe light grey datapoints represent the mean absolute percent error. A datapoint with a x value 200 and y value 1 means it was predicted for a period of 200 days after the cutoff date, and was 1% off the actual value. We can see that most predictions are under 1%, making this a pretty decent estimation. The fact that they do not increase over time allows us to have a certain degree of confidence in the prediction even a year out. The blue line shows the mean of these datapoints.\n\n## Portland's Transit System\n\nAs shown in the graphs and tests above, Portland has greater than normal AQI outcomes when compared with other cities of high populations. The AQI follows certain yearly trends, with the notable exception in September 2020 due to the large wildfires. Using Prophet, we are able to predict AQI up to a year out of the final datapoint in the time period. What exactly is the reason for these outcomes in this city?\n\nOne hypothesis for Portland's better air quality outcomes is due to the increased focus on public transportation. Portland has placed high emphasis on utilizing public transit, with rates comparable to larger cities and higher than most other cities of its size. We will run a two sample t test to see how Portland's rate of ridership compares with other large cites.\n\nWe have standardized rates by passenger miles ridden per person. This is the total amount of miles ridden in a given year divided by the population. This allows us to properly compare cities with different population sizes.\n\n**Null Hypothesis**: Transit ridership in Portland is less than or equal to transit ridership across the country (large metro areas only).\n\n**Alternate Hypothesis**: Transit ridership in Portland is greater than transit ridership across the country (large metro areas only).\n\n**Assumptions**:\n\n1.  Simple Random Sample: Data is not a simple random sample. Since there are so few datapoints for the Portland transit ridership population (8 datapoints), taking a 10% sample may not be suitable to accurately capture the variance of this month. Thus, it was decided to use the entire population as the sample. A 10% sample will be taken of the large cities transit population.\n\n2.  Independence: Transit ridership in Portland does not affect transit ridership in the rest of the country.\n\n3.  Normal Distribution:\n\n![Figure 9: Transit Distribution](https://github.com/wu-msds-capstones/Air-Quality-Index/blob/main/images/normal_distribution_3_pdx_transit.png?raw=true)\n\nFrom the QQ plots and histograms, we can see both datasets are clearly not normally distributed. The Portland data has so few datapoints that it is hard to tell if it has a normal distribution or not. The large city transit data seems normal with the exception of one datapoint.\n\nThe partial violations of the assumptions in the t test in our analysis suggest that the conclusions should be considered with a degree of caution.\n\n**Two-Sample t-Test  Portland Transit Ridership vs Large Metro Area Ridership**\n\n![Figure 10: Two-Sample t-Test](https://github.com/wu-msds-capstones/Air-Quality-Index/blob/main/images/hypothesis_test_results_3_transit.png?raw=true)\n\nBased on the high p value of 0.2469, we fail to reject the null. We cannot conclude that Portland's transit ridership is different from the average transit ridership of other large metro areas across the country. Transit ridership may have some impact on AQI but not enough to make a statistical difference by itself. Likely, this is a situation of correlated variables. Cities that invest more in public infrastructure are more likely to make a concerned effort into being environmentally conscious.\n\nIt should also be noted that some cities have higher public transit numbers not reflected in the data. For example, in New York City, subway ridership is almost double that of its motor bus numbers. In this data only motor bus numbers were included which may contribute to the lack of evidence for transit numbers influence on AQI. We will explore which features have a greater effect on AQI in the upcoming Machine Learning section. \n\n\n# Results Machine Learning Scikit-Learn\nUltimately, we want to see which variables have the greatest impact on AQI. To do this we perform a machine learning analysis and create a prediction algorithm. As the AQI is defined by the four criteria gasses and particulate matter (PM10 and PM2.5), those should not be included in the algorithm. Thus we start with all the other variables.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfter data is cleaned, we are left with a total of eighteen cities across the country with a total metropolitan area population of greater than one million. To perform the ML prediction algorithm, AQI will be predicted. We will use existing AQI cateogories as classifiers. A feature selector is run on the set of all variables except for the six that define AQI (CO, NO2, O3, SO2, PM10, PM2.5). This chooses the best predictors of the dependent variable AQI.\n\n\n\n\n\n\nFeatures Selected in Initial Model:\n\n- City\n- Month\n- Population\n- City Area\n- Park Area\n- Temperature\n- Humidity\n- Cattle\n\n\n\n\n\nIn pre testing, it was found that a Random Forest Model performed the best on this dataset. Therefore, this model type is used in all models.\n\n\nAn initial Random Forest Model run with the selected features returns the following Cohen Kappa score and accuracy:\n\n::: {#cks-accuracy .cell execution_count=23}\n\n::: {.cell-output .cell-output-stdout}\n```\nCohen Kappa Score:  0.44492288879204367\nAccuracy:  0.7218290691344583\n```\n:::\n:::\n\n\n\n![Figure 11: Confusion Matrix For Bin Size 1](https://github.com/wu-msds-capstones/Air-Quality-Index/blob/main/images/confusion_matrix_1.png?raw=true)\n\nLooking only at Cohen Kappa score and accuracy, this seems like a good prediction model. However, the confusion matrix shows the data's skew, centered around the 0-100 range. Therefore, more bins and bin size combinations are tested in order to provide a more meaningful prediction.\n\n\n\n\n\n\n\nAfter further testing the following bins were decided on:\n\n- 0-25\n- 26-50\n- 51-75\n- 76-100\n- 101-200\n- 201-500\n\nAs bins are made smaller, predictions become far less accurate. This bin size serves as a good balance between having enough bins to generate conclusions and maintaining decent accuracy. Different bin sizes also lead to different features being selected. The following features will be present in the final model:\n\n- City\n- Population\n- City Area\n- Park Area\n- Temperature\n- Humidity\n- Cattle\n\n\n\nHyperparameter optimization will be done to further improve the model. A randomized search is run with 100 iterations. The following hyperparameters are optimized:\n\n- Max Categories\n- Min Frequency\n- Max Depth\n- Max Features\n- Min Samples Leaf\n- Min Samples Split\n- Num Estimators\n- Bootstrap\n\n\n\nTable 1 below shows the selected hyperparameters.\n\n::: {#cell-randsearch-get-params .cell execution_count=34}\n\n::: {#randsearch-get-params .cell-output .cell-output-display}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Parameter</th>\n      <th>Value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>RF_model__bootstrap</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>RF_model__max_depth</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RF_model__max_features</td>\n      <td>log2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RF_model__min_samples_leaf</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RF_model__min_samples_split</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>RF_model__n_estimators</td>\n      <td>177</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>aqi_transformer__categories__max_categories</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>aqi_transformer__categories__min_frequency</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nTable 2 below shows the selected hyperparameters having hyperparamenter optimization\n\nUsing these hyperparameters, we reach an accuracy of over 70%.\n\n::: {#predict-x_test-final .cell execution_count=35}\n\n::: {.cell-output .cell-output-stdout}\n```\nCohen Kappa Score:  0.457560636753082\nAccuracy:  0.7158410451823626\n```\n:::\n:::\n\n\n\n\n![Figure 12: Final Model Confusion Matrix](https://github.com/wu-msds-capstones/Air-Quality-Index/blob/main/images/confusion_matrix_final.png?raw=true)\n\nWe can use this model for the prediction of AQI, exploring the features that predict it, and use that to generate conclusions for what variables or systems should be addressed.\n\nBelow, the table 3 shows a classification report of the model. Support represents the amount of data points total in that bin. We can see that AQI groups with more data tend to be more accurate (higher f1-score). This makes sense as the model has more of this data to train on. To make the model more accurate, more data from AQI values outside this 26-200 range will need to be collected.\n\n::: {#cell-classification-report .cell execution_count=37}\n\n::: {#classification-report .cell-output .cell-output-display}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1-score</th>\n      <th>support</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0-25</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>26-50</th>\n      <td>0.778702</td>\n      <td>0.885525</td>\n      <td>0.828685</td>\n      <td>1057.0</td>\n    </tr>\n    <tr>\n      <th>51-75</th>\n      <td>0.616514</td>\n      <td>0.558140</td>\n      <td>0.585876</td>\n      <td>602.0</td>\n    </tr>\n    <tr>\n      <th>76-100</th>\n      <td>0.396552</td>\n      <td>0.212963</td>\n      <td>0.277108</td>\n      <td>108.0</td>\n    </tr>\n    <tr>\n      <th>101-200</th>\n      <td>0.625000</td>\n      <td>0.333333</td>\n      <td>0.434783</td>\n      <td>60.0</td>\n    </tr>\n    <tr>\n      <th>201-500</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nTable 3: Final Model Classification Report)\n\nWe can also take a look at which features end up being most influential in the model. Below figure 13 shows Temperature and Humidity being by far the most influential variables in the model. However, temperature and humidity are not variables we can directly impact easily, and therefore, the four other variables are where we should put our efforts.\n\n::: {#cell-feature-importance .cell execution_count=38}\n\n::: {.cell-output .cell-output-display}\n![](capstone_files/figure-html/feature-importance-output-1.png){#feature-importance width=663 height=505}\n:::\n:::\n\n\nFigure 13: Feature Importance of Selected Variables in Final Model\n\n\n# Machine Learning SARIMAX\nA time series is a sequence of data points collected at regular intervals over a period of time. These intervals are typically uniform, such as hourly, daily, or quarterly measurements. This orderly arrangement allows for the analysis of trends, patterns, and behaviors over time. Common examples of time series data include stock market closing prices, household electricity consumption readings, and weather measurements. In the context of our capstone project, we're focusing on air quality index measurements as our time series data. This sequential record of air quality provides insights into pollution trends and can be used to forecast future air quality conditions.\n\n\n\n\n\n\n\nAny time series is composed of three things:\n\n- *Trend*: Trend tells you how things are overall changing  \n- *Seasonality*: Seasonality shows you how things change within a given period (e.g. year,month, week, day)  \n- *Residual*: The Error/residual/irregular activity are the anomalies which cannot be explained by the trend or the seasonal value\n\n## Statsmodel\nUsing the statsmodel package, we can map the seasonal pattern and trends using seasonal_decompose method. It requires as inputs a dataframe with two columns date data and the AQI. This will help us to understand the seasonality and trend clearly and allowing us to make more sense of the data for the forecast.\nIn a additive time series, the components add together to make the time series. If you have an increasing trend, you still see roughly the same size peaks and troughs throughout the time series.\n\n## Components Of A Time Series\nTime series decomposition is a statistical technique that separates data into three key components: trend, seasonality, and residuals. \nThe trend shows the long-term direction, seasonality reveals recurring patterns, and residuals represent unexplained variations.\nVisualizing these components individually provides insights that may not be evident in the raw data. This process helps analysts identify underlying patterns, recognize cyclical behaviors, and detect anomalies. \n\nBy understanding these elements separately, we can gain deeper insights into the factors driving the time series, leading to more accurate analysis and forecasting.\nDecomposition is particularly useful when the complexity of a time series makes it challenging to discern important patterns from simple observation of the dataset.\n\n::: {#cell-seasonal-decompose .cell execution_count=42}\n\n::: {.cell-output .cell-output-display}\n![](capstone_files/figure-html/seasonal-decompose-output-1.png){#seasonal-decompose width=760 height=614}\n:::\n:::\n\n\nFigure 14: Seasonal, Trend, and Residual Decomposition of Portland AQI Time Series\n\nThe uppermost graph, labeled *Observed*, presents the raw time series data as originally recorded. Its y-axis quantifies the daily air quality measurements, while the x-axis represents the passage of time. This graph is a composite representation, effectively combining the three underlying components: trend, seasonality, and residuals.\nA notable anomaly is evident in the data: a significant spike in air quality measurements occurring in September 2020. This outlier corresponds to the severe wildfires that ravaged Oregon during that period. The dramatic increase in air pollution levels during this time underscores the profound impact of extreme environmental events on air quality.\n\nThe *Seasonal* component graph illustrates the cyclical patterns in air quality that repeat annually. This visualization reveals a distinctive yearly pattern in Air Quality Index (AQI) fluctuations.\nThe cycle begins with relatively low AQI values, indicating better air quality. As the year progresses, the AQI rises to a peak, signifying a period of poorer air quality. This is followed by an improvement (decrease in AQI), another deterioration (increase), and a final improvement towards the year's end.\nThese recurring variations likely reflect the influence of seasonal factors such as changing weather patterns, temperature inversions, and seasonal human activities. For instance, winter months might see higher AQI due to increased heating emissions, while spring could bring lower AQI with more favorable dispersion conditions. \n\nThe graph includes a highlighted box that demarcates the seasonal period. This visual element clearly illustrates the duration and boundaries of one complete seasonal cycle in the air quality data.\nUnderstanding these seasonal trends is crucial for accurately interpreting air quality data and making informed predictions. It allows environmental agencies and policymakers to anticipate periods of potentially compromised air quality and plan interventions accordingly.\n\nLastly, the final row displays the *Residuals*, which represent the portion of the data not explained by the trend or the seasonal component. We can interpret the residuals as the difference between the sum of the Trend and Seasonal components and the Observed values at each point in time. \nEssentially, the Residuals indicate the amount that needs to be added to the Trend and Seasonal components to align the result with the Observed values.\nResiduals are typically attributed to random errors, often referred to as white noise, which we will explore further. These residuals embody the unpredictable elements of the data that cannot be captured or forecasted by the model, as they are inherently random.\n\n## Finding the Best Forecasting Model with Grid Search\nFor this project, we used an extended version of *ARIMA* model knows as *SARIMAX* model as we have explained in the methods section.\nWe use a tuning technique called grid search method that attempts to compute the optimum values of hyperparameters. We are trying to find the right p,d,q values that would be given as an input to the SARIMAX time series model.\nThis process helps us find the best settings for a forecasting model called SARIMAX by testing various options to find the best fit for our data. Here’s an easy-to-understand explanation of how this works:\n\n### Step 1: Getting Everything Ready\nWe start by setting up all the tools we need for our analysis.\n\n### Step 2: Setting Up Our Options\nWe define different settings that the SARIMAX model can use to predict future values. These include the p, d, and q parameters, which help the model decide how much weight to give to past values, trends, and patterns. We then create a list of all possible combinations of these settings.\n\n### Step 3: Adding Seasonal Flavors\nWe know that some data has seasonal patterns, like sales going up during the holidays. We include options for these seasonal changes.\n\n### Step 4: Trying Out Different Combinations\nWe go through each combination of settings to see how well each one works. For each main setting, we also try different seasonal settings to find the perfect combination.\n\n### Step 5: Checking the Results\nFor each set of settings, we create a forecasting model and test it on our data. We measure how well each model works using a score called the Akaike Information Criterion (AIC). This score tells us how well the model predicts the data, with lower scores being better. If something goes wrong with a particular set of settings, we catch the error and move on to the next set without stopping the whole process.\n\n\n\nWe have to find the lowest AIC values which would have the best corresponding p,d,q values to have the best forecast of AQI values.  \n\n## SARIMAX Model Results\n\n::: {#mod-fit .cell execution_count=44}\n\n::: {.cell-output .cell-output-stdout}\n```\n                                     SARIMAX Results                                      \n==========================================================================================\nDep. Variable:                                aqi   No. Observations:                   96\nModel:             SARIMAX(1, 1, 1)x(0, 1, 1, 12)   Log Likelihood                -276.765\nDate:                            Wed, 14 Aug 2024   AIC                            561.530\nTime:                                    17:04:02   BIC                            570.467\nSample:                                01-31-2015   HQIC                           565.076\n                                     - 12-31-2022                                         \nCovariance Type:                              opg                                         \n==========================================================================================\n==============================================================================\n                 coef    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nar.L1          0.0483      0.306      0.158      0.875      -0.551       0.648\nma.L1         -1.0000    924.523     -0.001      0.999   -1813.031    1811.031\nma.S.L12      -1.0000   2355.498     -0.000      1.000   -4617.692    4615.692\nsigma2       134.1503   3.35e+05      0.000      1.000   -6.57e+05    6.57e+05\n==============================================================================\n```\n:::\n:::\n\n\nThis summary presents a concise overview of the SARIMAX model’s performance and fit. The SARIMAX(1, 1, 1)x(0, 1, 1, 12) model integrates both non-seasonal and seasonal components, effectively capturing both immediate and periodic influences on the Air Quality Index (AQI). The model utilizes 96 observations, providing a robust dataset for accurate model fitting.\nKey metrics such as the log-likelihood, AIC, BIC, and HQIC are used to assess the model's effectiveness, with lower values typically indicating a better fit that balances complexity and accuracy. The summary also includes the date and time of model execution, the timeframe of the data, and the type of covariance used, which aids in understanding how the model accounts for uncertainties in parameter estimates.\n\n### Autoregressive Term (ar.L1)\nCoefficient: 0.0483  Suggests a slight positive influence of the previous observation on the current value.\nStandard Error: 0.306 Indicates significant variability in the coefficient estimate.\nZ-Value: 0.158 Low value, indicating the coefficient is not statistically significant.\nP-Value: 0.875 Not significant (p-value > 0.05).\nConfidence Interval: [-0.551, 0.648]\nIncludes zero, reinforcing the lack of significance.\n\n### Moving Average Term (ma.L1)\nCoefficient: -1.0000 Implies the model tries to correct nearly all errors from the previous period.\nStandard Error: 924.523 Extremely large, pointing to high uncertainty in the estimate.\nZ-Value: -0.001 Near zero, indicating no statistical significance.\nP-Value: 0.999  Not significant.\nConfidence Interval: [-1813.031, 1811.031] Very wide and includes zero, confirming lack of significance.\n\n### Seasonal Moving Average Term (ma.S.L12)\nCoefficient: -1.0000 Attempts to correct errors regarding data seasonality.\nStandard Error: 2355.498 Very large, indicating substantial uncertainty.\nZ-Value: -0.000 Near zero, suggesting no significance.\nP-Value: 1.000 Not significant.\nConfidence Interval: [-4617.692, 4615.692] Wide interval, includes zero, further indicating no significance.\n\n### Variance of the Residuals (sigma2)\nCoefficient: 134.1503 Represents the variance of the residuals or errors.\nStandard Error: 335000 Extremely high, showing great uncertainty.\nZ-Value: 0.000 Indicates no statistical significance.\nP-Value: 1.000 Not significant.\nConfidence Interval: [-657000, 657000] Very wide, includes zero, highlighting lack of significance.\n\n##Overall Summary\nNone of the coefficients in the SARIMAX model are statistically significant, as indicated by the high p-values and z-values close to zero. This means that the parameters do not effectively predict the AQI data. The large standard errors and wide confidence intervals point to a high degree of uncertainty in the parameter estimates. This suggests the model may not be well-suited for capturing the dynamics of the AQI data, and re-evaluation of the model or data is recommended.\n\n## Fit SARIMAX model\n\n::: {#extract-aic-value-plot .cell execution_count=45}\n\n::: {.cell-output .cell-output-stdout}\n```\nThe AIC value is: 561.5301944999834\n```\n:::\n:::\n\n\nExplain what is the value AIC tells us, and how to interpret the plot. Look at the method\n\n\n\nOnce the model is created, predicted values are generated using the .get_prediction() method, with datetime as input.\n\n\n\n\n\nTo facilitate comparison of true and predicted test values, we will create a separate DataFrame. \nMean Error Estimation will be used for analysis.\n\n\n\nTo evaluate model performance, we calculate the MSE.\n\n::: {#calculate-mse .cell execution_count=50}\n\n::: {.cell-output .cell-output-stdout}\n```\nThe Mean Squared Error of our forecasts is 1.41\n```\n:::\n:::\n\n\n## Forecasting Future Values\n\nAs we conclude our modeling process, we generate predictions for the next 30 data points:\n\n1. **Model Information**: The `result` variable contains our fitted model's details.\n\n2. **Forecasting Method**: We use the `.get_forecast()` method on our model results.\n\n3. **Prediction Generation**: This method analyzes observed patterns in our data to project future values.\n\n4. **Output**: We obtain forecasts for the next 30 time points, representing predicted air quality levels.\n\nThis step transforms our analytical work into actionable insights for air quality management.\n\n\n\n\n\n## Visualizing Our Results\nThe final and crucial step of our project is the creation of a comprehensive plot that encapsulates our complex analysis. This visualization serves as the key to understanding and interpreting our findings.\n\n### Interpreting the Forecast Plot\nOur plot consists of several key elements:\n\n1. **Observed Values (Blue Line)**\n   - Represents the actual, historical air quality measurements\n   - Provides a baseline for comparing our predictions\n\n2. **Forecasted Values (Orange Line)**\n   - Depicts the future air quality levels predicted by our SARIMAX Time Series Model\n   - Allows us to visualize potential trends and patterns in air quality\n\n3. **Confidence Interval (Shaded Region)**\n   - The shaded area around the forecast line represents the 95% Confidence Interval (CI)\n   - Indicates the range within which we can be 95% confident that the true future values will fall\n   - Wider intervals suggest greater uncertainty in the prediction\n\nThis visual representation not only summarizes our extensive data analysis but also provides a powerful tool for understanding potential future air quality trends. It bridges the gap between complex statistical models and actionable insights, making our findings accessible and meaningful to a broader audience.\n\n::: {#cell-plot-forecast .cell execution_count=53}\n\n::: {.cell-output .cell-output-display}\n![](capstone_files/figure-html/plot-forecast-output-1.png){#plot-forecast width=1118 height=583}\n:::\n:::\n\n\n# Conclusion\n\nAfter conducting our thorough research, we have landed on these specific recommendations. We found there are high seasonal trends where late summer/early fall tends to have the worst air quality. These numbers consistently show up each year, exasperated by the dry heat and lack of rainfall. As climate change raises temperatures and water sources dry up, wildfire season will continue to get worse over time. We must be aware of the nature of air quality and how it differs at different parts of the year. We should understand how the AQI works, and avoid being outside for too long when it reaches more dangerous levels.\n\nAir quality is significantly affected by various natural and unpredictable elements, including:\n\n- Weather conditions\n- Wind speed and direction\n- Temperature fluctuations\n- Humidity levels\n- Atmospheric pressure\n- Solar radiation intensity\n\nWith multiple factors we have no control over, it is important to do what we can for those factors we can impact.\n\nWe must focus on the variables that have the greatest impact on the AQI. These are city, temperature, humidity, CO, NO2, O3, PM10, and PM2.5. City, temperature, and humidity for the most part are out of our control. That leaves us with three criteria gasses and all particulate matter. The largest source of carbon monoxide, nitrogen dioxide, and ozone is the cars, trucks, and other vehicles we use daily (Environmental Protection Agency). We can lower our reliance on personal vehicles by utilizing public transportation, carpooling, walking, biking, increasing work from home to lower commutes when available, and overall be more considerate about if driving a car is necessary. We often drive unnecessarily, out of convenience or impatience. \n\nFor many Americans, personal vehicles are required. Many urban and suburban areas lack proper public transportation, or existing public transportation systems are inadequate, unreliable, and infrequent. Many towns and cities in the United States were designed for cars instead of for people. Fixing this will require a substantial overhaul, necessitating millions or billions of dollars in spending. This is not to say that we shouldn’t bother---any investment that increases the public transportation system’s usage decreases the amount of cars on the road. A small change is the first step in addressing the personal vehicle issue.\n\nIndustrial manufacturing processes and agriculture are significant polluters of the environment. We should invest in the research of more environmentally friendly manufacturing methods, working with materials that require less combustion, or are recyclable. Agricultural reduction starts with less of a reliance on red meat and the dairy industry, mainstays of the American diet. This will be a huge shift, taking combined efforts of the citizens, government, and food industry. As red meat and dairy consumption goes down, possibly due to the replacement with artificial or lab grown meat, less livestock will need to be kept, and less feeding crops will need to be grown (Congressional Budget Office). It will be a difficult transition but a necessary one.\n\nWildfires not only increase the particle matter in the air, but burn forests, causing long term damage to the soil. Particulate matter in the air makes it more difficult to breathe, which is reflected by the increased AQI levels. Not all forest fires are started by man made sources, but many are. Therefore, when in the woods, one should always obey fire restrictions, especially in the middle of the summer when it’s most dry. If fires are allowed, they should always be watched and never left unattended. They must always be properly extinguished and all embers must be cool to the touch before leaving. Campsites should be properly cleaned, and all tools used correctly. One should also stay on marked trails, avoiding trampling vegetation which can increase the risk of wildfire spreading (Oregon Wildfire Response and Recovery).\n\nOne of the largest limitations is Algorithm Dependence. This is the reliability of forecasts which are inherently tied to the chosen predictive algorithms. Different models may yield varying results, emphasizing the importance of algorithm selection and validation.\n\nWe must also be wary of geographical considerations. Our data analysis couldn't fully quantify the unique geographical features of Portland and the broader Willamette Valley region. In further analysis we should seek to understand: \n\n- The protective influence of surrounding mountain ranges\n- The impact on wind patterns and air circulation\n- The potential effects of wildfires on air quality\n\nThese geographical factors play a significant role in local air quality dynamics but were beyond the scope of our current data set. The impact of the geological features can be seen in the image below illustrates how the surrounding mountains create a basin effect, trapping pollutants and contributing to higher air pollution levels. \nThe concentrated red and orange areas, particularly on right side of the Willamette Valley.Do the mountains in the image seem to create barriers to air flow, potentially trapping pollutants in certain areas?\n![AirNow Interactive Map](https://github.com/wu-msds-capstones/Air-Quality-Index/blob/main/images/AirNow-Map.png?raw=true) \n\nBy recognizing these limitations, we can better interpret and apply our forecasting results, while also identifying areas for future research and data collection to enhance prediction accuracy.\n\nUltimately, we have a responsibility to take care of our planet and combat climate change. The worse climate conditions get, the more wildfires will spread, and the worse the air quality will become. As time goes on, with worsening air conditions, more people will catch and even die from preventable conditions sparked by poor air quality.  Water, pollution, food, and financial problems will get worse. One should look at what they can do to make a difference, support those who vouch to make larger changes, and encourage people they know to do the same. While the situation may seem dire, there is hope for progress through concerted and informed efforts.\n\n\n# Appendix\n## Bibliography\n1. Airly. (n.d.). *How does humidity affect air quality? All you need to know*. [airly.org/en/how-does-humidity-affect-air-quality-all-you-need-to-know/](https://airly.org/en/how-does-humidity-affect-air-quality-all-you-need-to-know/)\n\n2. AirNow. (n.d.). *Using air quality index*. [www.airnow.gov/aqi/aqi-basics/using-air-quality-index](https://www.airnow.gov/aqi/aqi-basics/using-air-quality-index)\n\n3. American Lung Association. (n.d.). *Key findings: State of the air*. [www.lung.org/research/sota/key-findings](https://www.lung.org/research/sota/key-findings)\n\n4. Broadbent, P., Grantz, D. A., & Leigh, A. (2023). Air quality in cities: Complexities and progress in mitigation. *Frontiers in Sustainable Cities*, *5*. [www.ncbi.nlm.nih.gov/pmc/articles/PMC10068020/](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10068020/)\n\n5. California Air Resources Board. (n.d.). *Carbon monoxide & health*. [ww2.arb.ca.gov/resources/carbon-monoxide-and-health](https://ww2.arb.ca.gov/resources/carbon-monoxide-and-health)\n\n6. Centers for Disease Control and Prevention, Agency for Toxic Substances and Disease Registry. (2014, October 21). *Medical management guidelines for sulfur dioxide*. [wwwn.cdc.gov/TSP/MMG/MMGDetails.aspx?mmgid=249&toxid=46](https://wwwn.cdc.gov/TSP/MMG/MMGDetails.aspx?mmgid=249&toxid=46)\n\n7. Centers for Disease Control and Prevention, Agency for Toxic Substances and Disease Registry. (2023, April 12). *Toxic substances portal - Nitrogen oxides*. [wwwn.cdc.gov/TSP/ToxFAQs/ToxFAQsDetails.aspx?faqid=396&toxid=69](https://wwwn.cdc.gov/TSP/ToxFAQs/ToxFAQsDetails.aspx?faqid=396&toxid=69)\n\n8. Climate & Clean Air Commission. (n.d.). Methane. Retrieved August 14, 2024, from https://www.ccacoalition.org/short-lived-climate-pollutants/methane\n\n9. Congressional Budget Office. (2023, May). *Reducing emissions from transportation*. [www.cbo.gov/publication/60030](https://www.cbo.gov/publication/60030)\n\n10. Environmental Protection Agency. (n.d.-a). *Evolution of the Clean Air Act*. [www.epa.gov/clean-air-act-overview/evolution-clean-air-act](https://www.epa.gov/clean-air-act-overview/evolution-clean-air-act)\n\n11. Environmental Protection Agency. (n.d.). Agriculture and aquaculture: Food for thought. Retrieved August 14, 2024, from https://www.epa.gov/snep/agriculture-and-aquaculture-food-thought\n\n12. Environmental Protection Agency. (n.d.-b). *Health effects of ozone pollution*. [www.epa.gov/ground-level-ozone-pollution/health-effects-ozone-pollution](https://www.epa.gov/ground-level-ozone-pollution/health-effects-ozone-pollution)\n\n13. Environmental Protection Agency. (n.d.-c). *Particulate matter (PM) basics*. [www.epa.gov/pm-pollution/particulate-matter-pm-basics](https://www.epa.gov/pm-pollution/particulate-matter-pm-basics)\n\n14. Federal Transit Administration. (n.d.). *NTD data tables*. American Public Transportation Association. [www.apta.com/research-technical-resources/transit-statistics/ntd-data-tables/](https://www.apta.com/research-technical-resources/transit-statistics/ntd-data-tables/)\n\n15. Fuller, R., Landrigan, P. J., Balakrishnan, K., Bathan, G., Bose-O'Reilly, S., Brauer, M., Caravanos, J., Chiles, T., Cohen, A., Corra, L., Cropper, M., Ferraro, G., Hanna, J., Hanrahan, D., Hu, H., Hunter, D., Janata, G., Kupka, R., Lanphear, B., . . . Yadama, G. N. (2022). Pollution and health: A progress update. *The Lancet Planetary Health*, *6*(6), e535-e547. [www.thelancet.com/journals/lanplh/article/PIIS2542-5196(22)00090-0/fulltext](https://www.thelancet.com/journals/lanplh/article/PIIS2542-5196(22)00090-0/fulltext)\n\n16. Hog Wild Preserve. (n.d.). *Pig, boar, or hog: What's the difference?* [www.hogwildok.com/blog/336-pig,-boar,-or-hog-what-s-the-difference.html](https://www.hogwildok.com/blog/336-pig,-boar,-or-hog-what-s-the-difference.html)\n\n17. Jacobs, E. T., Burgess, J. L., & Abbott, M. B. (2018). The Donora smog revisited: 70 years after the event that inspired the clean air act. *American Journal of Public Health*, *108*(S2), S85-S88. [www.ncbi.nlm.nih.gov/pmc/articles/PMC5922205/](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5922205/)\n\n18. Manisalidis, I., Stavropoulou, E., Stavropoulos, A., & Bezirtzoglou, E. (2020). Environmental and health impacts of air pollution: A review. *Frontiers in Public Health*, *8*, 14. [www.ncbi.nlm.nih.gov/pmc/articles/PMC7044178/](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7044178/)\n\n19. National Agricultural Statistics Service. (2017). *2017 Census of Agriculture*. United States Department of Agriculture. [www.nass.usda.gov/Publications/AgCensus/2017/Full_Report/Volume_1,_Chapter_1_US/](https://www.nass.usda.gov/Publications/AgCensus/2017/Full_Report/Volume_1,_Chapter_1_US/)\n\n20. National Oceanic and Atmospheric Administration. (n.d.). *What are a nautical mile and a knot?* [oceanservice.noaa.gov/facts/nautical-mile-knot.html](https://oceanservice.noaa.gov/facts/nautical-mile-knot.html)\n\n21. National Weather Service. (n.d.). *Pressure and winds*. [www.weather.gov/source/zhu/ZHU_Training_Page/winds/pressure_winds/Pressure.htm](https://www.weather.gov/source/zhu/ZHU_Training_Page/winds/pressure_winds/Pressure.htm)\n\n22. Oregon Encyclopedia. (n.d.). *Interstate 5 in Oregon*. [www.oregonencyclopedia.org/articles/interstate_5_in_oregon/](https://www.oregonencyclopedia.org/articles/interstate_5_in_oregon/)\n\n23. Oregon Wildfire Response and Recovery. (n.d.). *Wildfire prevention*. [wildfire.oregon.gov/prevention](https://wildfire.oregon.gov/prevention)\n\n24. Portland.gov. (n.d.). *City of Portland Charter, Chapter 1*. [www.portland.gov/charter/1/2](https://www.portland.gov/charter/1/2)\n\n25. Shandas, V., & George, L. (2009). Neighborhood, neighborhood, neighborhood: Spatial patterns of air toxins and implications for metroscape residents and urban planners. *Metroscape*, Winter 2009. [pdxscholar.library.pdx.edu/cgi/viewcontent.cgi?article=1033&context=usp_fac](https://pdxscholar.library.pdx.edu/cgi/viewcontent.cgi?article=1033&context=usp_fac)\n\n26. Trust for Public Land. (n.d.). *Park data downloads*. [www.tpl.org/park-data-downloads](https://www.tpl.org/park-data-downloads)\n\n27. United States Census Bureau. (n.d.). *Home page*. [www.census.gov/en.html](https://www.census.gov/en.html)\n\n28. World Health Organization. (2014, March 25). *7 million premature deaths annually linked to air pollution*. [www.who.int/news/item/25-03-2014-7-million-premature-deaths-annually-linked-to-air-pollution](https://www.who.int/news/item/25-03-2014-7-million-premature-deaths-annually-linked-to-air-pollution)\n\n29. World Health Organization. (2022, October 31). *Lead poisoning and health*. [www.who.int/news-room/fact-sheets/detail/lead-poisoning-and-health](https://www.who.int/news-room/fact-sheets/detail/lead-poisoning-and-health)\n\n30. Zhang, Y., Cooper, O. R., Gaudel, A., Thompson, A. M., Nédélec, P., Ogino, S. Y., & West, J. J. (2018). Tropospheric ozone change from 1980 to 2010 dominated by equatorward redistribution of emissions. *Nature Geoscience*, *11*, 637-644. [acp.copernicus.org/articles/18/15003/2018/](https://acp.copernicus.org/articles/18/15003/2018/)\n\n\n## Additional Resources - EDA\n\n\n\n### Exploratory Data Analysis\nWe have new dataset metro_1mil.csv. This file was generated using a SQL statement that joins all relevant tables, filtering for metropolitan areas with populations less than or equal to 1 million. This approach limits our EDA to mid-sized metropolitan cities, such as Portland, Oregon.\n\n\n\nLet's plot the AQI data distribution\n\n\n\n\n\nThe DataFrame contains 147039 rows and 44 columns.\n\n\n\nBy filtering our Dataframe for Oregon state, our DataFrame contains 2922 rows.\n\n### Features Engineering\n\n\n\n\n\n\n\nDate Column Preprocessing:\n\n- Converted the date column to DateTime objects for easier manipulation and analysis.\n- Extracted additional time-based features: year, month, day of week, and quarter.\n\nFeature Selection:\n\n- Removed irrelevant columns to focus the analysis on pertinent variables.\n- Retained features: pollutant, aqi, wind\n\nMissing Value Treatment:\n\n- Identified columns with missing values: most all of them\n- Applied mean() imputation method for numerical columns.\n- For categorical columns: n/a\n\nData Types and Memory Usage:\n\n- Optimized data types to reduce memory usage (e.g., using categories for low-cardinality strings, int8/int16 for small integers).\n\nBasic Statistics:\n\n- Generated summary statistics for numerical columns using df.describe().\n- Calculated frequency distributions for categorical variables.\n\nDistribution Analysis:\n\n- Plotted histograms and kernel density estimates for main numerical features.\n\nTime Series Components:\n\n- Decomposed time series data into trend, seasonality, and residual components for relevant variables.\n\n### Sweetviz Data Report\n\n\n\nWe have generated Sweetviz statistical report confirming the quality of EDA steps.\n\n### Advanced Data Analysis\nWe have also employed the ydata-profiling package, a powerful Time Series Analysis EDA package that offers more detailed analysis.\n\nWe have unlocked time series-specific features using ydata-profiling:\nWe ensure our DataFrame is sorted or specify the sortby parameter, setting tsmode=True when creating the ProfileReport to allow Time Series Feature Identification\n\nThe ydata-profiling identifies time-dependent features using autocorrelation analysis.  \nFor recognized time series features, the histograms are replaced with line plots and feature details include new autocorrelation and partial autocorrelation plots.\n\nTo handle Multi-Entity Time Series Data, In our case, with category_id, each pollutants represents a distinct time series.\nFor optimal analysis, we filter and profile each pollutant separately\n\n\n\n\n\n\n\nTo conclude our exploratory data analysis (EDA) process consisted of two complementary approaches:\n\n- *Manual Investigation*: We conducted an in-depth, hands-on examination of the dataset.\n- *Automated Analysis*: We leveraged two powerful EDA packages: Sweetviz For quick, visual data summaries, ydata-profiling for more detailed, customizable reports  \n\nThese methods allowed us to thoroughly evaluate key data quality aspects, including:\n\n- Class balance in categorical variables\n- Presence and distribution of missing values (NaN)\n- Feature distributions and correlations\n- Potential time-series characteristics\n\nThis multi-faceted approach ensures a robust understanding of our dataset's structure, quality, and potential challenges before proceeding with further analysis.\n\n\n\n### Time Series Visualization in Portland\n#### Carbon Monoxyde (CO), Wind and Air Quality Index (AQI)\nCO pollutant refers to carbon monoxide, which is a colorless, odorless, and tasteless gas that can be harmful to human health and the environment. Here's some key information about CO as a pollutant:\n\nPrimarily produced by incomplete combustion of carbon-containing fuels\nMajor sources include vehicle exhaust, industrial processes, and some natural sources like volcanoes\n\n- Slightly less dense than air\n- Highly flammable\n\n::: {#ts-wind-co-aqi .cell execution_count=67}\n\n::: {#ts-wind-co-aqi-1 .cell-output .cell-output-display}\n```\n<Figure size 960x1728 with 0 Axes>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](capstone_files/figure-html/ts-wind-co-aqi-output-2.png){#ts-wind-co-aqi-2 width=3542 height=1130}\n:::\n:::\n\n\n#### Nitrogen Dioxide (NO2), Sulfur Dioxyde (SO2) and Ozone (O₃)\nNO2 (nitrogen dioxide) is an important air pollutant.\n- Reddish-brown gas with a pungent odor\n- Part of a group of pollutants known as nitrogen oxides (NOx)\n\nSO2 (sulfur dioxide) is an important air pollutant.\n- Colorless gas with a sharp, pungent odor\n- Highly soluble in water\n\nOzone (O₃) as a pollutant is a complex topic, as it can be both beneficial and harmful depending on its location in the atmosphere. \n- Colorless to pale blue gas with a distinctive smell\n- Highly reactive molecule composed of three oxygen atoms\n\n::: {#ts-so2-no2-ozone .cell execution_count=68}\n\n::: {#ts-so2-no2-ozone-1 .cell-output .cell-output-display}\n```\n<Figure size 1440x1920 with 0 Axes>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](capstone_files/figure-html/ts-so2-no2-ozone-output-2.png){#ts-so2-no2-ozone-2 width=3542 height=1695}\n:::\n:::\n\n\n## Additional Resources - Machine Learning Metrics Table\n| Technique/Metric | Description | Purpose/Formula | Scenario: Cancer prediction |\n|------------------|-------------|-----------------|-------------------|\n| 1. Train-Test Split | Split the dataset into training and testing subsets | Assess model performance on unseen data to detect overfitting and ensure generalizability | Always used; crucial for unbiased evaluation of model performance |\n| 2. Cross-Validation | Divide data into k subsets and train the model k times, using a different subset as test set each time | Provides robust estimate of model performance by averaging results over multiple splits | Useful for smaller datasets or when data collection is expensive (e.g., rare cancer types) |\n| 3. Confusion Matrix | Table comparing predicted and actual values in classification | Metrics: True Positives (TP), True Negatives (TN), False Positives (FP), False Negatives (FN) | Fundamental for understanding model performance in classification tasks, like cancer detection |\n| 4. Accuracy | Ratio of correctly predicted instances to total instances | $\\frac{TP + TN}{TP + TN + FP + FN}$ | Used when classes are balanced; less suitable for rare cancer detection due to class imbalance |\n| 5a. Precision | Ratio of correctly predicted positive observations to total predicted positives | $\\frac{TP}{TP + FP}$ | Important when false positives are costly (e.g., unnecessary biopsies or treatments) |\n| 5b. Recall (Sensitivity) | Ratio of correctly predicted positive observations to all actual positive observations | $\\frac{TP}{TP + FN}$ | Critical in cancer detection to minimize false negatives (missed cancer cases) |\n| 5c. F1-Score | Harmonic mean of Precision and Recall | $2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}$ | Balances precision and recall; useful when seeking a compromise between false positives and false negatives |\n| 6. ROC Curve and AUC | ROC: Graph of true positive rate vs false positive rate at various thresholds. AUC: Area under ROC curve | Higher AUC indicates better model performance | Useful for comparing models and choosing optimal threshold, especially in diagnostic tests |\n| 7. Mean Absolute Error (MAE) | Average of absolute differences between predicted and actual values | $\\frac{1}{n} \\sum_{i=1}^{n} \\|y_i - \\hat{y}_i\\|$ | Used in regression tasks, e.g., predicting survival time; less sensitive to outliers than MSE |\n| 8a. Mean Squared Error (MSE) | Average of squared differences between predicted and actual values | $\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$ | Used in regression; penalizes large errors more, suitable when large errors are particularly undesirable |\n| 8b. Root Mean Squared Error (RMSE) | Square root of MSE | $\\sqrt{\\text{MSE}}$ | Same as MSE, but in the original unit of the target variable, making it more interpretable |\n| 9. R-squared | Proportion of variance in dependent variable predictable from independent variables | $1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}$ | Used in regression to assess overall fit; indicates how well the model explains the variance in the data |\n| 10a. Akaike Information Criterion (AIC) | Measures relative quality of statistical model for given data | $2k - 2\\ln(L)$ where $k$ is number of parameters and $L$ is likelihood | Used for model selection; helps prevent overfitting by penalizing complex models |\n| 10b. Bayesian Information Criterion (BIC) | Similar to AIC but with stronger penalty term for number of parameters | $k\\ln(n) - 2\\ln(L)$ where $n$ is number of observations | Also used for model selection; tends to favor simpler models compared to AIC |\n\n",
    "supporting": [
      "capstone_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}