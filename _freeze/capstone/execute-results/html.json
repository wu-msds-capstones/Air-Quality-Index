{
  "hash": "9610c305d2cec5738b378200d81c4e80",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Unveiling the Drivers of Clean Air\"\nsubtitle: \"Analysis of Portland Air Quality (AQI)\"\n\n---\n\n---\n\ntitle: \"Introduction\"\nformat: html\nexecute:\n  echo: true\n  output: true\n\n---\nOn October 30, 1948, the Donora High School Football team pushed through a dense smog to complete the game with hundreds of fans in the audience, despite very poor visibility. The team, backed by a sense of resilience, took pride in playing through poor conditions, a testament to the high spirit of the small town. Soon after, calls to the town’s medical offices began rushing in, complaining of difficulty breathing and respiratory issues. Donora, Pennsylvania, was a town of metalworks, built by the American Steel and Wire company and the Donora Zinc Works company, which made up the largest parts of the town’s economy. The heavy smog and pollution clouds that covered the sky were a sign of prosperity. Only twelve hours later, seventeen people would be dead, 1440 seriously affected, and 4470 with mild to moderate conditions, almost half the town’s working population (Jacobs, Burgess, Abbott). This event, the Donora Smog of 1948, would lead the country into taking a close look at the negative impacts of air pollution. Widespread debate surrounding the event would lead to the first legislation regarding the regulation of the air within the United States, ushering in a new era of tracking, combatting, and reversing ill effects of poor air quality. \n\nThe quality of air we breathe has direct impacts on our health. We must understand the factors that contribute to poor air quality and how we personally and collectively contribute to the changes. Until we are able to visualize the impact we have on our atmosphere, we will continue behavior that negatively impacts the air around us. \n\nIn this project, we will be focusing on the key factors contributing to Portland, Oregon’s air quality. We aim to shed light on the complex interplay between various environmental and human-made factors that contribute to high air pollution levels. Initially, we were surprised to learn that Portland, the city we reside in, has some of the best air quality for a city of its size within the United States. This ultimately led us to narrow our focus on the factors that impact and lead to these outcomes within this city. \n\nThis project aims to develop and validate machine learning models for use in analysis of the various factors that influence air quality. \nBy focusing on Portland in comparison to other large US cities, we hope to find things Portland does that lead to the greater AQI outcomes. \nOur approach will consider a range of variables, including meteorological conditions, pollution sources, and transit systems. \nThrough this analysis, we aim to provide actionable insights and recommendations for sustaining and enhancing air quality. \nBy examining both the contributors to clean air and the potential causes of pollution, we can understand air quality factors more accurately and develop comprehensive strategies for improvement.\n\n\n---\n\ntitle: \"Background\"\nformat: html\nexecute:\n  echo: true\n  output: true\n\n---\nFederal regulation of air quality in the United States began in 1955 with the Air Pollution Control Act. This new piece of legislation provided the funds for initial research in air quality and pollution in the US. Using this and privately funded research, congress passed the Clean Air Act of 1963, putting into law the first federal regulation regarding control of air pollution. This established a new federal program within the US Public Health Service, dedicated to the monitoring and control of air quality. In 1967, congress passed the Air Quality Act, giving more federal oversight and enforcement policies. With this act, the government conducted extensive monitoring on interstate air pollution. This all led to the passing of the 1970 Clean Air Act, meant to restrict and regulate emissions, measure and reduce pollutant particles, and address upcoming pollution threats (Environmental Protection Agency).\n\nAlso created in 1970, the Environmental Protection Agency (EPA) implemented and monitored the requirements established by these rulings. These would affect not just federal lands and roads, but all companies operating within the United States. Enforcement authority was expanded to allow upholding these established standards, and prevent companies from circumventing the law.  Much of the turnaround in the quality of air in the US over the past fifty years can be attributed to these regulations. In 1990, when deaths due to air quality were first measured, an estimated 135,000 Americans died. By 2010 that number had dropped to 71,000 (Zhang et al.). Despite the significant decreases led by the federal guidelines of the late 70s, nearly four in ten Americans still live in places where they are exposed to unhealthy air (American Lung Association).\n\nThe EPA developed the Air Quality Index (AQI) in 1999, creating an easily understood measurement for the quality of the air we breathe. The AQI measures the level of air pollution on a scale from 0 to 500. It is divided into six categories, with 0 to 50 representing good air quality which poses little or no risk to those breathing it in. On the other hand, a score above 300 signifies emergency conditions, an extremely high risk which impacts everyone. This measurement is mainly derived from five major pollutants: Ozone, Particle pollution (2.5μm and 10μm),  Carbon Monoxide, Nitrogen Dioxide, and Sulphur Dioxide (Airnow.gov). Poor air quality has been linked to a variety of diseases including respiratory infections, stroke, heart disease, lung cancer, and chronic obstructive pulmonary disease among others (World Health Organization). An estimated seven million premature deaths annually can be attributed to air pollution, or a global mean loss of life expectancy of 2.9 years, quantifying it as the largest environmental risk factor for disease and premature death (Fuller, Landrigan, Balakrishnan, et. al.). Thus, it is important to understand factors that contribute to poor air quality, and outcomes that can be attributed to the state of the AQI.\n\n\n\n---\n\ntitle: \"Methods\"\nformat: html\njupyter: python3\nexecute:\n  echo: true\n  output: true\n---\n\n# Tools Deployed\nPython will be the primary programming language used to conduct this analysis. We will also use R language in statistical applications where necessary.\n\nTo perform our analysis, we will employ NumPy and Pandas for data manipulation. Matplotlib and Seaborn for visualization, and Time Series forecasting algorithms such as Prophet and SARIMAX.\n\nWe will address data inconsistencies, missing values and ensure that data is in a tidy format.\n\nWe may need to normalize or standardize data if necessary and create new features through aggregation to enhance the model’s performance.\n\n## What is Prophet?\n\nProphet is an open-source forecasting tool developed by Meta, designed for forecasting time series data. It is suited for datasets with strong seasonal, monthly, weekly, or daily patterns, and it handles missing data and outliers well. We utilized prophet to gain a quick understanding of our AQI patterns, seeking to understand basic trends before conducting a more thorough analysis.\n\nKey features of Prophet include seasonality detection and holiday incorporation, while providing easy use and understanding for users. \nWe can use this software to get complex understanding from simple applications.\n\nTo conduct this analysis, we prepare data into a two column table, date and AQI. Prophet uses the trends of past data to highlight similarities over days of the year, weeks, months, and seasons. From this, prophet is able to generate its predictions, cross validate, and give performance metrics such as mean absolute percentage error to quantify the accuracy of the results.\n\n## What is SARIMAX algorithm?​​​​​​​​​​​​​​​\nThe most common method used in time series forecasting is known as the ARIMA model. We will use an extended version called SARIMAX (*Seasonal Auto Regressive Integrated Moving Averages with exogenous factor*)\n\n- The SARIMAX model is used when the data sets have seasonal cycles. \n- In the dataset concerning the air quality/AQI there is a seasonal pattern which we have explained in the above section.\n- SARIMAX is a model that can be fitted to time series data in order to better understand or predict future points in the time series\n- SARIMAX is particularly useful for forecasting time series data that exhibits both trends and seasonality.\n\nHere's a breakdown of its components:\n\nThere are three distinct integers (p,d,q) that are used to parametrize SARIMAX models. Because of that, ARIMA models are denoted with the notation SARIMAX(p,d,q).\n\nTogether these three parameters account for seasonality, trend, and noise in datasets:\n\n1. *Seasonality (S)*: Accounts for recurring patterns or cycles in the data.\n2. *AutoRegressive (AR)*: Uses past values to predict future values.\n3. *Integrated (I)*: Applies differencing to make the time series stationary.\n4. *Moving Average (MA)*: Uses past forecast errors in the prediction.\n5. *eXogenous factors (X)*: Incorporates external variables that may influence the forecast.\n\nWe are trying to find the right p, d, q hyperparameters to correctly forecast and predict the AQI values.\n\n# Common Techniques to Evaluate the Performance of Machine Model\n\n## 1. Train-Test Split \n\n- **Description**: Split the dataset into training and testing subsets.\n- **Purpose**: Assess the model's performance on unseen data to detect overfitting and ensure generalizability.\n\n## 2. Cross-Validation \n\n- **Description**: Divide the data into k subsets and train the model k times, each time using a different subset as the test set and the remaining as the training set.\n- **Purpose**: Provides a more robust estimate of model performance by averaging results over multiple splits.\n\n## 3. Confusion Matrix \n\n- **Description**: A table used to describe the performance of a classification model by comparing predicted and actual values.\n- **Metrics**: True Positives (TP), True Negatives (TN), False Positives (FP), False Negatives (FN).\n\n## 4. Accuracy \n\n- **Description**: The ratio of correctly predicted instances to the total instances.\n- **Formula**: $\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}$\n\n## 5. Precision, Recall, and F1-Score \n\n### Precision\n- **Description**: The ratio of correctly predicted positive observations to the total predicted positives.\n- **Formula**: $\\text{Precision} = \\frac{TP}{TP + FP}$\n\n### Recall (Sensitivity)\n- **Description**: The ratio of correctly predicted positive observations to all observations in the actual class.\n- **Formula**: $\\text{Recall} = \\frac{TP}{TP + FN}$\n\n### F1-Score\n- **Description**: The harmonic mean of Precision and Recall.\n- **Formula**: $\\text{F1-Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}$\n\n## 6. ROC Curve and AUC (Area Under the Curve) \n\n- **ROC Curve**: A graphical representation of the true positive rate vs. false positive rate at various threshold settings.\n- **AUC**: Measures the entire two-dimensional area underneath the ROC curve. Higher AUC indicates better model performance.\n\n## 7. Mean Absolute Error (MAE)\n\n- **Description**: The average of the absolute differences between predicted and actual values.\n- **Formula**: $\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$\n\n## 8. Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) \n\n### MSE\n- **Description**: The average of the squared differences between predicted and actual values.\n- **Formula**: $\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$\n\n### RMSE\n- **Description**: The square root of MSE.\n- **Formula**: $\\text{RMSE} = \\sqrt{\\text{MSE}}$\n\n## 9. R-squared (Coefficient of Determination) \n\n- **Description**: The proportion of the variance in the dependent variable that is predictable from the independent variables.\n- **Formula**: $R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}$\n\n## 10. Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC) \n\n### AIC\n- **Description**: Measures the relative quality of a statistical model for a given set of data.\n- **Formula**: $\\text{AIC} = 2k - 2\\ln(L)$ where $k$ is the number of parameters and $L$ is the likelihood.\n\n### BIC\n- **Description**: Similar to AIC but includes a penalty term for the number of parameters.\n- **Formula**: $\\text{BIC} = k\\ln(n) - 2\\ln(L)$ where $n$ is the number of observations.\n\n# Machine Learning AQI Time Series\n## How can we use Akaike Information Criteria (AIC)?\nUsed to measure of a statistical model, it quantifies:\n\n- The goodness of fit\n- The simplicity of the model into a single statistic\n- When comparing two models, the one with the lower AIC is generally \"better\"\n\nThe Akaike Information Criterion (AIC) is a measure used to compare different statistical models. It helps in model selection by balancing the goodness of fit and the complexity of the model. Here's how to interpret the AIC value:\n\n- *Lower AIC is Better*: A lower AIC value indicates a better-fitting model. It means the model has a good balance between accuracy and complexity.\n- *Comparative Measure*: AIC is most useful when comparing multiple models. The model with the lowest AIC among a set of candidate models is generally preferred.\n- *Penalty for Complexity*: AIC includes a penalty for the number of parameters in the model. This discourages overfitting by penalizing models that use more parameters without a corresponding improvement in fit.\n\n---\ntitle: \"Result Machine Learning\"\nformat: html\njupyter: python3\nexecute:\n  echo: true\n  output: true\n---\n\n# Machine Learning using SKlearn\nUltimately, we want to see which variables have the greatest impact on AQI. To do this we must perform a machine learning analysis and create a prediction algorithm. \n\n::: {#import-packages .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import tree\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import randint\n```\n:::\n\n\nStarting by looking at the head to see all of our columns. Immediately, we can some missing data, which must be addressed before any machine learning algorithms can be conducted.\n\n## Import the Data\n\n::: {#read-csv .cell execution_count=2}\n``` {.python .cell-code}\ndf = pd.read_csv('https://raw.githubusercontent.com/wu-msds-capstones/Air-Quality-Index/main/data/metro_1mil.csv')\n```\n:::\n\n\n::: {#65008979 .cell execution_count=3}\n``` {.python .cell-code}\nlen(df)\n```\n\n::: {.cell-output .cell-output-display execution_count=32}\n```\n147039\n```\n:::\n:::\n\n\nHere we can see all the missing data in each column. There are some very large numbers we must address. The entire dataset is only 147039 rows long. Some columnshave more than half the data missing.\n\n::: {#4259b660 .cell execution_count=4}\n``` {.python .cell-code}\n#Check out missing data\ndf.isna().sum()\n```\n\n::: {.cell-output .cell-output-display execution_count=33}\n```\nyearly_transit_id                            5114\ncategory_id                                  3068\nlocation_id                                     0\ndate_id                                         0\nid                                              0\naqi                                          3068\nmean_temperature_fahrenheit                 61895\nmax_temperature_fahrenheit                  61895\nmean_pressure_millibars                     91859\nmax_pressure_millibars                      91859\nmean_humidity_percent_relative_humidity     76818\nmax_humidity_percent_relative_humidity      76818\nmean_wind_knots                             58488\nmax_wind_knots                              58488\nmean_co_ppm                                 32615\nmax_co_ppm                                  32615\nmean_no2_ppb                                27747\nmax_no2_ppb                                 27747\nmean_ozone_ppm                              33163\nmax_ozone_ppm                               33163\nmean_so2_ppb                                49291\nmax_so2_ppb                                 49291\nmean_pm100_micrograms_per_cubic_meter       77281\nmax_pm100_micrograms_per_cubic_meter        77281\nmean_pm25_micrograms_per_cubic_meter        37443\nmax_pm25_micrograms_per_cubic_meter         37443\nmean_lead_micrograms_per_cubic_meter       138816\nmax_lead_micrograms_per_cubic_meter        138816\ndate                                            0\nstate                                           0\nst_abbv                                         0\ncounty                                          0\ncity                                            0\npopulation                                      0\ndensity                                         0\ncategory                                     3068\naqi_range                                    3068\nnum_busses                                   5114\nrevenue                                      5844\noperating_expense                            5114\npassenger_trips                              5114\noperating_hours                              5114\npassenger_miles                              5114\noperating_miles                              5114\ndtype: int64\n```\n:::\n:::\n\n\nThe first steps to addressing the missing data will be to drop the columns that will definitely not be needed. This includes the id columns used for joining within the SQL database, as well as the maximum columns as we already have the mean data. We also rename the columns to make it easier to understand and reference.\n\n::: {#met-dataframe .cell execution_count=5}\n``` {.python .cell-code}\nmet = df[[\n    'date',\n    'state',\n    'county',\n    'city',\n    'population',\n    'density',\n    'aqi',\n    'category',\n    'mean_temperature_fahrenheit',\n    'mean_pressure_millibars',\n    'mean_humidity_percent_relative_humidity',\n    'mean_wind_knots',\n    'mean_co_ppm',\n    'mean_no2_ppb',\n    'mean_ozone_ppm',\n    'mean_so2_ppb',\n    'mean_pm100_micrograms_per_cubic_meter',\n    'mean_pm25_micrograms_per_cubic_meter',\n    'mean_lead_micrograms_per_cubic_meter',\n    'num_busses',\n    'revenue',\n    'operating_expense',\n    'passenger_trips',\n    'operating_hours',\n    'passenger_miles',\n    'operating_miles'\n    ]]\n\nmet = met.rename(columns={'mean_temperature_fahrenheit': 'temp', \n                          'mean_pressure_millibars': 'pressure', \n                          'mean_humidity_percent_relative_humidity': 'humidity',\n                          'mean_wind_knots': 'wind_speed', \n                          'mean_co_ppm': 'co', \n                          'mean_no2_ppb': 'no2',\n                          'mean_ozone_ppm': 'o3', \n                          'mean_so2_ppb': 'so2', \n                          'mean_pm100_micrograms_per_cubic_meter': 'pm100',\n                          'mean_pm25_micrograms_per_cubic_meter': 'pm25', \n                          'mean_lead_micrograms_per_cubic_meter': 'lead'})\n```\n:::\n\n\nNow the missing data looks like this, it is a little better, but we can still do so much more.\n\n::: {#cell-check-NaN .cell execution_count=6}\n``` {.python .cell-code}\nmet.isna().sum()\n```\n\n::: {#check-nan .cell-output .cell-output-display execution_count=35}\n```\ndate                      0\nstate                     0\ncounty                    0\ncity                      0\npopulation                0\ndensity                   0\naqi                    3068\ncategory               3068\ntemp                  61895\npressure              91859\nhumidity              76818\nwind_speed            58488\nco                    32615\nno2                   27747\no3                    33163\nso2                   49291\npm100                 77281\npm25                  37443\nlead                 138816\nnum_busses             5114\nrevenue                5844\noperating_expense      5114\npassenger_trips        5114\noperating_hours        5114\npassenger_miles        5114\noperating_miles        5114\ndtype: int64\n```\n:::\n:::\n\n\nWe will group data by week. This will take an average count for the entire week for each variable for each city. This will eliminate any missing data that was not captured everyday, but only some days. For example, the pollutants (PM10 and PM2.5) were captured once every three days. \n\n::: {#set-indexts .cell execution_count=7}\n``` {.python .cell-code}\nmet['date'] = pd.to_datetime(met['date'])\nmet.set_index('date', inplace=True)\n#group by week, drop lead for too much missing data\nmet = met.groupby([pd.Grouper(freq='W'), 'state', 'county', 'city']).agg({\n    'population': 'first',\n    'density': 'first',\n    'aqi': 'mean',\n    'temp': 'mean',\n    'pressure': 'mean',\n    'humidity': 'mean',\n    'wind_speed': 'mean',\n    'co': 'mean',\n    'no2': 'mean',\n    'o3': 'mean',\n    'so2': 'mean',\n    'pm100': 'mean',\n    'pm25': 'mean',\n    'num_busses': 'mean',\n    'revenue': 'mean',\n    'operating_expense': 'mean',\n    'passenger_trips': 'mean',\n    'operating_hours': 'mean',\n    'passenger_miles': 'mean',\n    'operating_miles': 'mean'\n}).reset_index()\n```\n:::\n\n\nWe can also see that the city Virginia Beach has almost no data, so it will be easiest to drop that city. \n\n::: {#drop-missnan-col .cell execution_count=8}\n``` {.python .cell-code}\nmet = met[met['city'] != 'Virginia Beach']\n```\n:::\n\n\nNext, since we will be measuring and predicting AQI, we will drop all rows missing AQI data.\n\n::: {#drop-null-aqi .cell execution_count=9}\n``` {.python .cell-code}\nmet = met.dropna(subset=['aqi'])\n```\n:::\n\n\nMissing data is better, but there is still work to do.\n\n::: {#cell-check-NaN-again .cell execution_count=10}\n``` {.python .cell-code}\nmet.isna().sum()\n```\n\n::: {#check-nan-again .cell-output .cell-output-display execution_count=39}\n```\ndate                     0\nstate                    0\ncounty                   0\ncity                     0\npopulation               0\ndensity                  0\naqi                      0\ntemp                  8199\npressure             12387\nhumidity             10318\nwind_speed            7679\nco                    3900\nno2                   3250\no3                    3964\nso2                   6315\npm100                 4835\npm25                  2055\nnum_busses             312\nrevenue                416\noperating_expense      312\npassenger_trips        312\noperating_hours        312\npassenger_miles        312\noperating_miles        312\ndtype: int64\n```\n:::\n:::\n\n\nThe data collected has separate information for the city of New York City. NYC is divided into five borroughs, each within its own county. We will group and average out these values to make NYC have the same amount of datapoints as every other city. This will also address data present in some New York borroughs but not others. \n\n::: {#5413c3f9 .cell execution_count=11}\n``` {.python .cell-code}\n#group nyc together into one city, ignoring county\nnyc = met[met['city'] == 'New York']\ncolumns = ['date', 'aqi', 'temp', 'pressure','humidity',\n           'wind_speed','co','no2','o3',\n           'so2','pm100','pm25', 'num_busses',\n           'revenue', 'operating_expense', \n           'passenger_trips', 'operating_hours', \n           'passenger_miles', 'operating_miles']\n\nnyc = nyc[columns].groupby('date').mean().reset_index()\n#Add data that was dropped\nnyc['state'] = 'New York'\nnyc['county'] = 'Multiple'\nnyc['city'] = 'New York City'\nnyc['population'] = 18908608\nnyc['density'] = 11080.3\n\nnyc = nyc[['date', 'state', 'county', 'city', 'population', \n     'density', 'aqi', 'temp', 'pressure','humidity',\n     'wind_speed','co','no2','o3', 'so2','pm100',\n     'pm25', 'num_busses', 'revenue', 'operating_expense', \n     'passenger_trips', 'operating_hours', \n     'passenger_miles', 'operating_miles']]\n\nprint(nyc)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          date     state    county           city  population  density  \\\n0   2015-01-04  New York  Multiple  New York City    18908608  11080.3   \n1   2015-01-11  New York  Multiple  New York City    18908608  11080.3   \n2   2015-01-18  New York  Multiple  New York City    18908608  11080.3   \n3   2015-01-25  New York  Multiple  New York City    18908608  11080.3   \n4   2015-02-01  New York  Multiple  New York City    18908608  11080.3   \n..         ...       ...       ...            ...         ...      ...   \n413 2022-12-04  New York  Multiple  New York City    18908608  11080.3   \n414 2022-12-11  New York  Multiple  New York City    18908608  11080.3   \n415 2022-12-18  New York  Multiple  New York City    18908608  11080.3   \n416 2022-12-25  New York  Multiple  New York City    18908608  11080.3   \n417 2023-01-01  New York  Multiple  New York City    18908608  11080.3   \n\n           aqi       temp     pressure   humidity  ...       so2      pm100  \\\n0    49.450000  38.984375  1015.694425  63.076739  ...  2.011285        NaN   \n1    47.514286  23.241072  1019.509891  50.699404  ...  3.337455        NaN   \n2    56.000000  29.508929  1017.454363  65.954221  ...  3.034949        NaN   \n3    49.800000  34.836310  1008.855166  60.536141  ...  2.267468        NaN   \n4    44.342857  25.562500  1010.873006  63.099378  ...  2.640521        NaN   \n..         ...        ...          ...        ...  ...       ...        ...   \n413  29.657143        NaN          NaN        NaN  ...  0.437256   5.333334   \n414  34.742857        NaN          NaN        NaN  ...  0.517050  11.666667   \n415  27.600000        NaN          NaN        NaN  ...  0.507095   9.333333   \n416  38.000000        NaN          NaN        NaN  ...  0.837313   8.000000   \n417  59.566667        NaN          NaN        NaN  ...  1.217373  22.666666   \n\n          pm25  num_busses       revenue  operating_expense  passenger_trips  \\\n0     7.781642     22195.0  5.427129e+09       1.656689e+10     4.350768e+09   \n1     8.393517     22195.0  5.427129e+09       1.656689e+10     4.350768e+09   \n2    13.683131     22195.0  5.427129e+09       1.656689e+10     4.350768e+09   \n3    10.417719     22195.0  5.427129e+09       1.656689e+10     4.350768e+09   \n4     7.102983     22195.0  5.427129e+09       1.656689e+10     4.350768e+09   \n..         ...         ...           ...                ...              ...   \n413   4.959028      5735.0  8.183201e+08       3.981827e+09     5.032214e+08   \n414   7.456925      5735.0  8.183201e+08       3.981827e+09     5.032214e+08   \n415   4.837290      5735.0  8.183201e+08       3.981827e+09     5.032214e+08   \n416   7.295255      5735.0  8.183201e+08       3.981827e+09     5.032214e+08   \n417  17.720097      5735.0  8.183201e+08       3.981827e+09     5.032214e+08   \n\n     operating_hours  passenger_miles  operating_miles  \n0         77805045.0     9.676463e+09      577333420.0  \n1         77805045.0     9.676463e+09      577333420.0  \n2         77805045.0     9.676463e+09      577333420.0  \n3         77805045.0     9.676463e+09      577333420.0  \n4         77805045.0     9.676463e+09      577333420.0  \n..               ...              ...              ...  \n413       16852360.0     1.446845e+09      130602200.0  \n414       16852360.0     1.446845e+09      130602200.0  \n415       16852360.0     1.446845e+09      130602200.0  \n416       16852360.0     1.446845e+09      130602200.0  \n417       16852360.0     1.446845e+09      130602200.0  \n\n[418 rows x 24 columns]\n```\n:::\n:::\n\n\n::: {#92d05053 .cell execution_count=12}\n``` {.python .cell-code}\n#replace existing nyc data in met dataframe\nmet = met[met['city'] != 'New York']\nmet = pd.concat([met, nyc], ignore_index=True)\n```\n:::\n\n\nAdditionally, Kansas City is located in two states, and thus in two counties. We will do the same thing to contract and standardize the data.\n\n::: {#0bb93711 .cell execution_count=13}\n``` {.python .cell-code}\n#Do same with Kansas City\nkc = met[met['city'] == 'Kansas City']\ncolumns = ['date', 'aqi', 'temp', 'pressure','humidity',\n           'wind_speed','co','no2','o3',\n           'so2','pm100','pm25', 'num_busses',\n           'revenue', 'operating_expense', \n           'passenger_trips', 'operating_hours', \n           'passenger_miles', 'operating_miles']\n\nkc = kc[columns].groupby('date').mean().reset_index()\n\ncolumns = ['temp', 'pressure','humidity',\n           'wind_speed','co','no2','o3',\n           'so2','pm100','pm25', 'num_busses',\n           'revenue', 'operating_expense', \n           'passenger_trips', 'operating_hours', \n           'passenger_miles', 'operating_miles']\nmet[columns] = met[columns].fillna(met.groupby('city')[columns].transform('mean'))\n\nkc['state'] = 'Missouri'\nkc['county'] = 'Multiple'\nkc['city'] = 'Kansas City'\nkc['population'] = 1689556\nkc['density'] = 620.7\n\nkc = kc[['date', 'state', 'county', 'city', 'population', \n     'density', 'aqi', 'temp', 'pressure','humidity',\n     'wind_speed','co','no2','o3', 'so2','pm100',\n     'pm25', 'num_busses', 'revenue', 'operating_expense', \n     'passenger_trips', 'operating_hours', \n     'passenger_miles', 'operating_miles']]\n\nmet = met[met['city'] != 'Kansas City']\nmet = pd.concat([met, kc], ignore_index=True)\n```\n:::\n\n\nAfter doing this, we drop the rest of the rows with missing data, leaving us with a total of 17 cities with metropolitan area populations greater than one million.\n\n::: {#dec33214 .cell execution_count=14}\n``` {.python .cell-code}\n#count cities after dropping na rows, left with 17 cities\nds = met.dropna()\n\nds.groupby('city').size().reset_index(name='count')\n```\n\n::: {.cell-output .cell-output-display execution_count=43}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>city</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Boston</td>\n      <td>418</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Charlotte</td>\n      <td>418</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Cincinnati</td>\n      <td>418</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Cleveland</td>\n      <td>418</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Dallas</td>\n      <td>418</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Detroit</td>\n      <td>418</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Houston</td>\n      <td>418</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Kansas City</td>\n      <td>241</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Los Angeles</td>\n      <td>418</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Memphis</td>\n      <td>418</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>New York City</td>\n      <td>418</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Phoenix</td>\n      <td>418</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Pittsburgh</td>\n      <td>418</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Portland</td>\n      <td>418</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Raleigh</td>\n      <td>418</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Seattle</td>\n      <td>418</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>St. Louis</td>\n      <td>418</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Washington</td>\n      <td>418</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nTo perform a ML prediction algorithm, the predicted variable (AQI) must be discrete. To achieve this, we bin AQI data into discrete groups. Initially, we thought to bin them based on the existing AQI categories, but found that most of the data is grouped in the sub 100 range. Therefore, we expanded the bins, focusing the prediction on outcomes in the double digits. The bins chosen are shown below:\n\n::: {#90c606df .cell execution_count=15}\n``` {.python .cell-code}\n#bin AQI data for ML\nbins = [0, 30, 40, 50, 60, 70, 80, 90, 100, 150, 500]\n\nlabels = ['0-30', '31-40', '41-50', '51-60', '61-70', '71-80', '81-90', '91-100', '101-150', '151+']\nds.loc[:,'aqi_discrete'] = pd.cut(ds['aqi'], bins=bins, labels=labels, right=True)\n\nds.head()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nC:\\Users\\Steve\\AppData\\Local\\Temp\\ipykernel_50704\\1254269955.py:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  ds.loc[:,'aqi_discrete'] = pd.cut(ds['aqi'], bins=bins, labels=labels, right=True)\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=44}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>state</th>\n      <th>county</th>\n      <th>city</th>\n      <th>population</th>\n      <th>density</th>\n      <th>aqi</th>\n      <th>temp</th>\n      <th>pressure</th>\n      <th>humidity</th>\n      <th>...</th>\n      <th>pm100</th>\n      <th>pm25</th>\n      <th>num_busses</th>\n      <th>revenue</th>\n      <th>operating_expense</th>\n      <th>passenger_trips</th>\n      <th>operating_hours</th>\n      <th>passenger_miles</th>\n      <th>operating_miles</th>\n      <th>aqi_discrete</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2015-01-04</td>\n      <td>Arizona</td>\n      <td>Maricopa</td>\n      <td>Phoenix</td>\n      <td>4064275</td>\n      <td>1198.9</td>\n      <td>86.50</td>\n      <td>41.458333</td>\n      <td>972.860814</td>\n      <td>60.739583</td>\n      <td>...</td>\n      <td>20.709822</td>\n      <td>20.505426</td>\n      <td>729.0</td>\n      <td>47024975.0</td>\n      <td>2.256208e+08</td>\n      <td>55497019.0</td>\n      <td>2228182.0</td>\n      <td>2.190928e+08</td>\n      <td>28371107.0</td>\n      <td>81-90</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2015-01-04</td>\n      <td>California</td>\n      <td>Los Angeles</td>\n      <td>Los Angeles</td>\n      <td>11922389</td>\n      <td>3184.7</td>\n      <td>118.50</td>\n      <td>50.281250</td>\n      <td>1010.666650</td>\n      <td>58.177084</td>\n      <td>...</td>\n      <td>24.954331</td>\n      <td>21.400000</td>\n      <td>2259.0</td>\n      <td>273158938.0</td>\n      <td>1.056348e+09</td>\n      <td>367104774.0</td>\n      <td>7938548.0</td>\n      <td>1.448619e+09</td>\n      <td>84041668.0</td>\n      <td>101-150</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2015-01-04</td>\n      <td>District Of Columbia</td>\n      <td>District of Columbia</td>\n      <td>Washington</td>\n      <td>5116378</td>\n      <td>4235.7</td>\n      <td>45.25</td>\n      <td>41.149479</td>\n      <td>1015.388525</td>\n      <td>61.075000</td>\n      <td>...</td>\n      <td>13.750000</td>\n      <td>11.088055</td>\n      <td>1394.0</td>\n      <td>149657899.0</td>\n      <td>6.453259e+08</td>\n      <td>139353079.0</td>\n      <td>4115200.0</td>\n      <td>4.293390e+08</td>\n      <td>39643319.0</td>\n      <td>41-50</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>2015-01-04</td>\n      <td>Massachusetts</td>\n      <td>Suffolk</td>\n      <td>Boston</td>\n      <td>4328315</td>\n      <td>5319.0</td>\n      <td>42.75</td>\n      <td>33.458332</td>\n      <td>1018.536500</td>\n      <td>58.234375</td>\n      <td>...</td>\n      <td>6.000000</td>\n      <td>7.244791</td>\n      <td>800.0</td>\n      <td>96572664.0</td>\n      <td>4.080501e+08</td>\n      <td>122496729.0</td>\n      <td>2231562.0</td>\n      <td>3.162285e+08</td>\n      <td>22115804.0</td>\n      <td>41-50</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>2015-01-04</td>\n      <td>Michigan</td>\n      <td>Wayne</td>\n      <td>Detroit</td>\n      <td>3725908</td>\n      <td>1772.2</td>\n      <td>49.25</td>\n      <td>30.203125</td>\n      <td>994.260400</td>\n      <td>72.671876</td>\n      <td>...</td>\n      <td>18.250000</td>\n      <td>9.394618</td>\n      <td>432.0</td>\n      <td>31303313.0</td>\n      <td>1.729056e+08</td>\n      <td>33078462.0</td>\n      <td>1225079.0</td>\n      <td>1.696881e+08</td>\n      <td>17705665.0</td>\n      <td>41-50</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 25 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {#526dac9a .cell execution_count=16}\n``` {.python .cell-code}\nlabels = ['0-30', '31-40', '41-50', '51-60', '61-70', '71-80', '81-90', '91-100', '101-150', '151+']\nds.loc[:,'aqi_discrete'] = pd.cut(ds['aqi'], bins=bins, labels=labels, right=True)\n\nds.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=45}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>state</th>\n      <th>county</th>\n      <th>city</th>\n      <th>population</th>\n      <th>density</th>\n      <th>aqi</th>\n      <th>temp</th>\n      <th>pressure</th>\n      <th>humidity</th>\n      <th>...</th>\n      <th>pm100</th>\n      <th>pm25</th>\n      <th>num_busses</th>\n      <th>revenue</th>\n      <th>operating_expense</th>\n      <th>passenger_trips</th>\n      <th>operating_hours</th>\n      <th>passenger_miles</th>\n      <th>operating_miles</th>\n      <th>aqi_discrete</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2015-01-04</td>\n      <td>Arizona</td>\n      <td>Maricopa</td>\n      <td>Phoenix</td>\n      <td>4064275</td>\n      <td>1198.9</td>\n      <td>86.50</td>\n      <td>41.458333</td>\n      <td>972.860814</td>\n      <td>60.739583</td>\n      <td>...</td>\n      <td>20.709822</td>\n      <td>20.505426</td>\n      <td>729.0</td>\n      <td>47024975.0</td>\n      <td>2.256208e+08</td>\n      <td>55497019.0</td>\n      <td>2228182.0</td>\n      <td>2.190928e+08</td>\n      <td>28371107.0</td>\n      <td>81-90</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2015-01-04</td>\n      <td>California</td>\n      <td>Los Angeles</td>\n      <td>Los Angeles</td>\n      <td>11922389</td>\n      <td>3184.7</td>\n      <td>118.50</td>\n      <td>50.281250</td>\n      <td>1010.666650</td>\n      <td>58.177084</td>\n      <td>...</td>\n      <td>24.954331</td>\n      <td>21.400000</td>\n      <td>2259.0</td>\n      <td>273158938.0</td>\n      <td>1.056348e+09</td>\n      <td>367104774.0</td>\n      <td>7938548.0</td>\n      <td>1.448619e+09</td>\n      <td>84041668.0</td>\n      <td>101-150</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2015-01-04</td>\n      <td>District Of Columbia</td>\n      <td>District of Columbia</td>\n      <td>Washington</td>\n      <td>5116378</td>\n      <td>4235.7</td>\n      <td>45.25</td>\n      <td>41.149479</td>\n      <td>1015.388525</td>\n      <td>61.075000</td>\n      <td>...</td>\n      <td>13.750000</td>\n      <td>11.088055</td>\n      <td>1394.0</td>\n      <td>149657899.0</td>\n      <td>6.453259e+08</td>\n      <td>139353079.0</td>\n      <td>4115200.0</td>\n      <td>4.293390e+08</td>\n      <td>39643319.0</td>\n      <td>41-50</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>2015-01-04</td>\n      <td>Massachusetts</td>\n      <td>Suffolk</td>\n      <td>Boston</td>\n      <td>4328315</td>\n      <td>5319.0</td>\n      <td>42.75</td>\n      <td>33.458332</td>\n      <td>1018.536500</td>\n      <td>58.234375</td>\n      <td>...</td>\n      <td>6.000000</td>\n      <td>7.244791</td>\n      <td>800.0</td>\n      <td>96572664.0</td>\n      <td>4.080501e+08</td>\n      <td>122496729.0</td>\n      <td>2231562.0</td>\n      <td>3.162285e+08</td>\n      <td>22115804.0</td>\n      <td>41-50</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>2015-01-04</td>\n      <td>Michigan</td>\n      <td>Wayne</td>\n      <td>Detroit</td>\n      <td>3725908</td>\n      <td>1772.2</td>\n      <td>49.25</td>\n      <td>30.203125</td>\n      <td>994.260400</td>\n      <td>72.671876</td>\n      <td>...</td>\n      <td>18.250000</td>\n      <td>9.394618</td>\n      <td>432.0</td>\n      <td>31303313.0</td>\n      <td>1.729056e+08</td>\n      <td>33078462.0</td>\n      <td>1225079.0</td>\n      <td>1.696881e+08</td>\n      <td>17705665.0</td>\n      <td>41-50</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 25 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {#2bc50767 .cell execution_count=17}\n``` {.python .cell-code}\nds.loc[:,'year'] = pd.to_datetime(ds['date']).dt.year\nds.loc[:,'month'] = pd.to_datetime(ds['date']).dt.month\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nC:\\Users\\Steve\\AppData\\Local\\Temp\\ipykernel_50704\\3789006578.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  ds.loc[:,'year'] = pd.to_datetime(ds['date']).dt.year\nC:\\Users\\Steve\\AppData\\Local\\Temp\\ipykernel_50704\\3789006578.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  ds.loc[:,'month'] = pd.to_datetime(ds['date']).dt.month\n```\n:::\n:::\n\n\nTo set up the ML prediction, we must specify the variable being predicted (aqi_discrete, the aqi separated into bins), and the independent prediction variables. We will use a feature selector to select the most accurate predictors to try to optimize the model. Therefore, we initially choose every other variable to be our independent variables.\n\n::: {#775658f5 .cell execution_count=18}\n``` {.python .cell-code}\n#dependent variable aqi, all others (except aqi category) as independent variables\ny = ds['aqi_discrete']\nX = ds[['city',\n        'population',\n        'density',\n        'temp',\n        'pressure',\n        'humidity',\n        'wind_speed',\n        'co',\n        'no2',\n        'o3',\n        'so2',\n        'pm100',\n        'pm25',\n        'num_busses', \n        'revenue', \n        'operating_expense', \n        'passenger_trips', \n        'operating_hours', \n        'passenger_miles', \n        'operating_miles',\n        'year',\n        'month'\n        ]]\n```\n:::\n\n\nWe must split the data into training and testing datasets. We also define an encoder to transform the discrete predictors into many binary variables for each category.\n\n::: {#f548e134 .cell execution_count=19}\n``` {.python .cell-code}\n#Split into train and test datasets, define model and encoder\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\nencoder = OneHotEncoder(sparse_output=False, min_frequency=5, handle_unknown='infrequent_if_exist')\n```\n:::\n\n\nA transformer is used to quickly transform variables into the necessary form for modeling.\n\n::: {#95d4f927 .cell execution_count=20}\n``` {.python .cell-code}\n#define transformer with encoder and standardscaler\n\ntransformer = ColumnTransformer(\n        [\n            ('categories', encoder, ['city','year','month']),\n            ('scaled_air_quality', StandardScaler(), [\n                'population',\n                'density',\n                'temp',\n                'pressure',\n                'humidity',\n                'wind_speed',\n                'co',\n                'no2',\n                'o3',\n                'so2',\n                'pm100',\n                'pm25',\n                'num_busses', \n                'revenue', \n                'operating_expense', \n                'passenger_trips', \n                'operating_hours', \n                'passenger_miles', \n                'operating_miles'\n                ]\n            )\n        ],\n        remainder='drop', verbose_feature_names_out=False)\n#fit transformer\ntransformer.fit(X_train, y_train)\n```\n\n::: {.cell-output .cell-output-display execution_count=49}\n```{=html}\n<style>#sk-container-id-3 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-3 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-3 pre {\n  padding: 0;\n}\n\n#sk-container-id-3 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-3 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-3 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-3 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-3 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-3 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-3 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-3 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-3 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-3 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-3 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-3 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-3 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-3 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-3 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-3 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n#sk-container-id-3 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-3 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-3 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-3 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-3 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-3 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-3 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-3 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-3 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-3 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;categories&#x27;,\n                                 OneHotEncoder(handle_unknown=&#x27;infrequent_if_exist&#x27;,\n                                               min_frequency=5,\n                                               sparse_output=False),\n                                 [&#x27;city&#x27;, &#x27;year&#x27;, &#x27;month&#x27;]),\n                                (&#x27;scaled_air_quality&#x27;, StandardScaler(),\n                                 [&#x27;population&#x27;, &#x27;density&#x27;, &#x27;temp&#x27;, &#x27;pressure&#x27;,\n                                  &#x27;humidity&#x27;, &#x27;wind_speed&#x27;, &#x27;co&#x27;, &#x27;no2&#x27;, &#x27;o3&#x27;,\n                                  &#x27;so2&#x27;, &#x27;pm100&#x27;, &#x27;pm25&#x27;, &#x27;num_busses&#x27;,\n                                  &#x27;revenue&#x27;, &#x27;operating_expense&#x27;,\n                                  &#x27;passenger_trips&#x27;, &#x27;operating_hours&#x27;,\n                                  &#x27;passenger_miles&#x27;, &#x27;operating_miles&#x27;])],\n                  verbose_feature_names_out=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for ColumnTransformer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;categories&#x27;,\n                                 OneHotEncoder(handle_unknown=&#x27;infrequent_if_exist&#x27;,\n                                               min_frequency=5,\n                                               sparse_output=False),\n                                 [&#x27;city&#x27;, &#x27;year&#x27;, &#x27;month&#x27;]),\n                                (&#x27;scaled_air_quality&#x27;, StandardScaler(),\n                                 [&#x27;population&#x27;, &#x27;density&#x27;, &#x27;temp&#x27;, &#x27;pressure&#x27;,\n                                  &#x27;humidity&#x27;, &#x27;wind_speed&#x27;, &#x27;co&#x27;, &#x27;no2&#x27;, &#x27;o3&#x27;,\n                                  &#x27;so2&#x27;, &#x27;pm100&#x27;, &#x27;pm25&#x27;, &#x27;num_busses&#x27;,\n                                  &#x27;revenue&#x27;, &#x27;operating_expense&#x27;,\n                                  &#x27;passenger_trips&#x27;, &#x27;operating_hours&#x27;,\n                                  &#x27;passenger_miles&#x27;, &#x27;operating_miles&#x27;])],\n                  verbose_feature_names_out=False)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">categories</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;city&#x27;, &#x27;year&#x27;, &#x27;month&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;infrequent_if_exist&#x27;, min_frequency=5,\n              sparse_output=False)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">scaled_air_quality</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;population&#x27;, &#x27;density&#x27;, &#x27;temp&#x27;, &#x27;pressure&#x27;, &#x27;humidity&#x27;, &#x27;wind_speed&#x27;, &#x27;co&#x27;, &#x27;no2&#x27;, &#x27;o3&#x27;, &#x27;so2&#x27;, &#x27;pm100&#x27;, &#x27;pm25&#x27;, &#x27;num_busses&#x27;, &#x27;revenue&#x27;, &#x27;operating_expense&#x27;, &#x27;passenger_trips&#x27;, &#x27;operating_hours&#x27;, &#x27;passenger_miles&#x27;, &#x27;operating_miles&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div></div></div></div></div>\n```\n:::\n:::\n\n\nFeature selection is done on the data. From this we are given the following variables: City, Temperature, Humidity, Carbon Monoxide, Nitrogen Dioxide, Ozone, PM10, and PM2.5.\n\n::: {#a1818088 .cell execution_count=21}\n``` {.python .cell-code}\n#feature selection\nfeature_selector = SelectKBest(k=10)\nX_train_trans = transformer.transform(X_train)\nX_train_trans_df = pd.DataFrame(\n    X_train_trans, \n    columns = transformer.get_feature_names_out(),\n    index = X_train.index)\nfeature_selector.fit(X_train_trans_df, y_train)\nfeature_selector.get_support()\nfeature_selector.scores_[feature_selector.get_support()]\nX_train_trans_df.columns[feature_selector.get_support()]\n```\n\n::: {.cell-output .cell-output-display execution_count=50}\n```\nIndex(['city_Los Angeles', 'city_Phoenix', 'city_Portland', 'temp', 'humidity',\n       'co', 'no2', 'o3', 'pm100', 'pm25'],\n      dtype='object')\n```\n:::\n:::\n\n\nUsing these selected features, we will run our models.\n\n::: {#fce18812 .cell execution_count=22}\n``` {.python .cell-code}\n#Use selected features\ny = ds['aqi_discrete']\nX = ds[[\n    'city', 'temp', 'humidity', 'co', 'no2', 'o3', 'pm100', 'pm25'\n    ]]\n#Create train/test data with selected features\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\nX_train_enc = pd.DataFrame(encoder.fit_transform(X_train[['city']]),\n                           columns = encoder.get_feature_names_out(), index = X_train.index)\nX_train_trans = X_train[[\n    'temp', 'humidity', 'co', 'no2','o3', 'pm100', 'pm25'\n    ]].merge(X_train_enc, left_index = True, right_index = True)\nX_test_enc = pd.DataFrame(encoder.fit_transform(X_test[['city']]),\n                           columns = encoder.get_feature_names_out(), index = X_test.index)\nX_test_trans = X_test[[\n    'temp', 'humidity', 'co', 'no2','o3', 'pm100', 'pm25'\n    ]].merge(X_test_enc, left_index = True, right_index = True)\n```\n:::\n\n\nWe will test various models with default parameters to see which is the most accurate at predicting AQI from this dataset. The five models selected are: K nearest neighbors, Tree model, Random Forest model, Logistic Regression, and Naive Bayes.Running the models shows us that the Random Forest model is the most accurate.\n\n::: {#cae2ba33 .cell execution_count=23}\n``` {.python .cell-code}\n#model selection\nmodel1 = KNeighborsClassifier(n_neighbors=5)\nmodel2 = tree.DecisionTreeClassifier()\nmodel3 = RandomForestClassifier(n_estimators=10, random_state=12)\nmodel4 = LogisticRegression()\nmodel5 = GaussianNB()\n\nfor model, label in zip([model1, model2, model3, model4, model5], ['KNN', 'Tree', 'Random Forest', 'Logistic', 'naive Bayes']):\n    model.fit(X_train_trans, y_train)\n    y_pred = model.predict(X_test_trans)\n    print(\"Model: \", label)\n    print(\"Cohen Kappa Score: \", cohen_kappa_score(y_test, y_pred))\n    print(\"Accuracy: \", sum(y_test == y_pred)/len(y_test))\n    print(\"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel:  KNN\nCohen Kappa Score:  0.27968217934165707\nAccuracy:  0.4518236254763201\n\n\nModel:  Tree\nCohen Kappa Score:  0.38979693946729765\nAccuracy:  0.5215024496461622\n\n\nModel:  Random Forest\nCohen Kappa Score:  0.4811754974115705\nAccuracy:  0.6020685900925422\n\n\nModel:  Logistic\nCohen Kappa Score:  0.31228619929444534\nAccuracy:  0.48557430593358736\n\n\nModel:  naive Bayes\nCohen Kappa Score:  0.003824544630551596\nAccuracy:  0.04899292324442025\n\n\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nC:\\Users\\Steve\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n```\n:::\n:::\n\n\nRunning a basic Random Forest model gives us the following cohen kappa score and accuracy. This will serve as the baseline to be compared to.\n\n::: {#8657fee5 .cell execution_count=24}\n``` {.python .cell-code}\n#Create model from most accurate, RandomForest\nmodel = RandomForestClassifier(n_estimators=10)\nmodel.fit(X_train_trans, y_train)\n\n#predict on test data\ny_pred = model.predict(X_test_trans)\n\n#Print results\nprint(\"cohen kappa score: \", cohen_kappa_score(y_test, y_pred))\nprint(\"accuracy: \", sum(y_test == y_pred)/len(y_test))\nConfusionMatrixDisplay(\n    confusion_matrix = confusion_matrix(\n        y_test, y_pred, \n        labels = ['0-30', '31-40', '41-50', '51-60', '61-70', '71-80', '81-90', '91-100', '101-150', '151+']\n        ), \n        display_labels = ['0-30', '31-40', '41-50', '51-60', '61-70', '71-80', '81-90', '91-100', '101-150', '151+']\n        ).plot(xticks_rotation='vertical')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ncohen kappa score:  0.48253162196073107\naccuracy:  0.6020685900925422\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](capstone_files/figure-html/cell-25-output-2.png){width=551 height=472}\n:::\n:::\n\n\nWe will further simplify this with a transformer to be used in a pipeline.\n\n::: {#1f910c29 .cell execution_count=25}\n``` {.python .cell-code}\n#redefined transformer\ntransformer = ColumnTransformer(\n        [\n            ('categories', encoder, ['city']),\n            ('scaled_air_quality', StandardScaler(), [\n                'temp',\n                'humidity',\n                'co',\n                'no2',\n                'o3',\n                'pm100',\n                'pm25'\n                ]\n            )\n        ],\n        remainder='drop', verbose_feature_names_out=False)\n#Pipeline for simplification\n\nclassification_pipeline = Pipeline([('aqi_transformer', transformer),\n                                    ('RF_model', RandomForestClassifier())\n                                    ])\nclassification_pipeline.fit(X_train, y_train)\n```\n\n::: {.cell-output .cell-output-display execution_count=54}\n```{=html}\n<style>#sk-container-id-4 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-4 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-4 pre {\n  padding: 0;\n}\n\n#sk-container-id-4 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-4 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-4 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-4 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-4 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-4 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-4 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-4 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-4 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-4 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-4 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-4 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-4 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-4 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-4 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-4 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n#sk-container-id-4 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-4 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-4 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-4 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-4 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-4 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-4 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-4 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-4 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-4 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;aqi_transformer&#x27;,\n                 ColumnTransformer(transformers=[(&#x27;categories&#x27;,\n                                                  OneHotEncoder(handle_unknown=&#x27;infrequent_if_exist&#x27;,\n                                                                min_frequency=5,\n                                                                sparse_output=False),\n                                                  [&#x27;city&#x27;]),\n                                                 (&#x27;scaled_air_quality&#x27;,\n                                                  StandardScaler(),\n                                                  [&#x27;temp&#x27;, &#x27;humidity&#x27;, &#x27;co&#x27;,\n                                                   &#x27;no2&#x27;, &#x27;o3&#x27;, &#x27;pm100&#x27;,\n                                                   &#x27;pm25&#x27;])],\n                                   verbose_feature_names_out=False)),\n                (&#x27;RF_model&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;aqi_transformer&#x27;,\n                 ColumnTransformer(transformers=[(&#x27;categories&#x27;,\n                                                  OneHotEncoder(handle_unknown=&#x27;infrequent_if_exist&#x27;,\n                                                                min_frequency=5,\n                                                                sparse_output=False),\n                                                  [&#x27;city&#x27;]),\n                                                 (&#x27;scaled_air_quality&#x27;,\n                                                  StandardScaler(),\n                                                  [&#x27;temp&#x27;, &#x27;humidity&#x27;, &#x27;co&#x27;,\n                                                   &#x27;no2&#x27;, &#x27;o3&#x27;, &#x27;pm100&#x27;,\n                                                   &#x27;pm25&#x27;])],\n                                   verbose_feature_names_out=False)),\n                (&#x27;RF_model&#x27;, RandomForestClassifier())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;aqi_transformer: ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for aqi_transformer: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;categories&#x27;,\n                                 OneHotEncoder(handle_unknown=&#x27;infrequent_if_exist&#x27;,\n                                               min_frequency=5,\n                                               sparse_output=False),\n                                 [&#x27;city&#x27;]),\n                                (&#x27;scaled_air_quality&#x27;, StandardScaler(),\n                                 [&#x27;temp&#x27;, &#x27;humidity&#x27;, &#x27;co&#x27;, &#x27;no2&#x27;, &#x27;o3&#x27;,\n                                  &#x27;pm100&#x27;, &#x27;pm25&#x27;])],\n                  verbose_feature_names_out=False)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">categories</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;city&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;infrequent_if_exist&#x27;, min_frequency=5,\n              sparse_output=False)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">scaled_air_quality</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;temp&#x27;, &#x27;humidity&#x27;, &#x27;co&#x27;, &#x27;no2&#x27;, &#x27;o3&#x27;, &#x27;pm100&#x27;, &#x27;pm25&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div></div></div></div></div>\n```\n:::\n:::\n\n\nNext we will optimize hyperparameters to make the model more accurate. \n\n::: {#20e95e49 .cell execution_count=26}\n``` {.python .cell-code}\n#hyperparameter optimization\nclassification_pipeline.get_params()\n```\n\n::: {.cell-output .cell-output-display execution_count=55}\n```\n{'memory': None,\n 'steps': [('aqi_transformer',\n   ColumnTransformer(transformers=[('categories',\n                                    OneHotEncoder(handle_unknown='infrequent_if_exist',\n                                                  min_frequency=5,\n                                                  sparse_output=False),\n                                    ['city']),\n                                   ('scaled_air_quality', StandardScaler(),\n                                    ['temp', 'humidity', 'co', 'no2', 'o3',\n                                     'pm100', 'pm25'])],\n                     verbose_feature_names_out=False)),\n  ('RF_model', RandomForestClassifier())],\n 'verbose': False,\n 'aqi_transformer': ColumnTransformer(transformers=[('categories',\n                                  OneHotEncoder(handle_unknown='infrequent_if_exist',\n                                                min_frequency=5,\n                                                sparse_output=False),\n                                  ['city']),\n                                 ('scaled_air_quality', StandardScaler(),\n                                  ['temp', 'humidity', 'co', 'no2', 'o3',\n                                   'pm100', 'pm25'])],\n                   verbose_feature_names_out=False),\n 'RF_model': RandomForestClassifier(),\n 'aqi_transformer__n_jobs': None,\n 'aqi_transformer__remainder': 'drop',\n 'aqi_transformer__sparse_threshold': 0.3,\n 'aqi_transformer__transformer_weights': None,\n 'aqi_transformer__transformers': [('categories',\n   OneHotEncoder(handle_unknown='infrequent_if_exist', min_frequency=5,\n                 sparse_output=False),\n   ['city']),\n  ('scaled_air_quality',\n   StandardScaler(),\n   ['temp', 'humidity', 'co', 'no2', 'o3', 'pm100', 'pm25'])],\n 'aqi_transformer__verbose': False,\n 'aqi_transformer__verbose_feature_names_out': False,\n 'aqi_transformer__categories': OneHotEncoder(handle_unknown='infrequent_if_exist', min_frequency=5,\n               sparse_output=False),\n 'aqi_transformer__scaled_air_quality': StandardScaler(),\n 'aqi_transformer__categories__categories': 'auto',\n 'aqi_transformer__categories__drop': None,\n 'aqi_transformer__categories__dtype': numpy.float64,\n 'aqi_transformer__categories__feature_name_combiner': 'concat',\n 'aqi_transformer__categories__handle_unknown': 'infrequent_if_exist',\n 'aqi_transformer__categories__max_categories': None,\n 'aqi_transformer__categories__min_frequency': 5,\n 'aqi_transformer__categories__sparse_output': False,\n 'aqi_transformer__scaled_air_quality__copy': True,\n 'aqi_transformer__scaled_air_quality__with_mean': True,\n 'aqi_transformer__scaled_air_quality__with_std': True,\n 'RF_model__bootstrap': True,\n 'RF_model__ccp_alpha': 0.0,\n 'RF_model__class_weight': None,\n 'RF_model__criterion': 'gini',\n 'RF_model__max_depth': None,\n 'RF_model__max_features': 'sqrt',\n 'RF_model__max_leaf_nodes': None,\n 'RF_model__max_samples': None,\n 'RF_model__min_impurity_decrease': 0.0,\n 'RF_model__min_samples_leaf': 1,\n 'RF_model__min_samples_split': 2,\n 'RF_model__min_weight_fraction_leaf': 0.0,\n 'RF_model__monotonic_cst': None,\n 'RF_model__n_estimators': 100,\n 'RF_model__n_jobs': None,\n 'RF_model__oob_score': False,\n 'RF_model__random_state': None,\n 'RF_model__verbose': 0,\n 'RF_model__warm_start': False}\n```\n:::\n:::\n\n\nThe following parameters are selected, each with a range of possible values. A large 100 iterations are run to find the highest score.\n\n::: {#e6863689 .cell execution_count=27}\n``` {.python .cell-code}\nparameters = {\n    'aqi_transformer__categories__max_categories': randint(3,30),\n    'aqi_transformer__categories__min_frequency': randint(2,20),\n    'RF_model__max_depth': randint(3, 30),\n    'RF_model__max_features': [None, 'sqrt', 'log2'],\n    'RF_model__min_samples_leaf': randint(2, 10),\n    'RF_model__min_samples_split': randint(2, 10),\n    'RF_model__n_estimators': randint(50, 200),\n    'RF_model__min_samples_split': randint(2, 10),\n    'RF_model__bootstrap': [True, False]\n}\nn_iter_search = 10 # be 100\nrandom_search = RandomizedSearchCV(classification_pipeline, param_distributions=parameters,\n                                   n_iter=n_iter_search, n_jobs=-1, cv=5)\nrandom_search.fit(X_train, y_train)\nprint(random_search.best_score_)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.6150635208711434\n```\n:::\n:::\n\n\nWe can see which hyperparameters are selected.\n\n::: {#713ff603 .cell execution_count=28}\n``` {.python .cell-code}\nrandom_search.best_estimator_.get_params()\n```\n\n::: {.cell-output .cell-output-display execution_count=57}\n```\n{'memory': None,\n 'steps': [('aqi_transformer',\n   ColumnTransformer(transformers=[('categories',\n                                    OneHotEncoder(handle_unknown='infrequent_if_exist',\n                                                  max_categories=17,\n                                                  min_frequency=18,\n                                                  sparse_output=False),\n                                    ['city']),\n                                   ('scaled_air_quality', StandardScaler(),\n                                    ['temp', 'humidity', 'co', 'no2', 'o3',\n                                     'pm100', 'pm25'])],\n                     verbose_feature_names_out=False)),\n  ('RF_model',\n   RandomForestClassifier(max_depth=27, min_samples_leaf=5, min_samples_split=9,\n                          n_estimators=171))],\n 'verbose': False,\n 'aqi_transformer': ColumnTransformer(transformers=[('categories',\n                                  OneHotEncoder(handle_unknown='infrequent_if_exist',\n                                                max_categories=17,\n                                                min_frequency=18,\n                                                sparse_output=False),\n                                  ['city']),\n                                 ('scaled_air_quality', StandardScaler(),\n                                  ['temp', 'humidity', 'co', 'no2', 'o3',\n                                   'pm100', 'pm25'])],\n                   verbose_feature_names_out=False),\n 'RF_model': RandomForestClassifier(max_depth=27, min_samples_leaf=5, min_samples_split=9,\n                        n_estimators=171),\n 'aqi_transformer__n_jobs': None,\n 'aqi_transformer__remainder': 'drop',\n 'aqi_transformer__sparse_threshold': 0.3,\n 'aqi_transformer__transformer_weights': None,\n 'aqi_transformer__transformers': [('categories',\n   OneHotEncoder(handle_unknown='infrequent_if_exist', max_categories=17,\n                 min_frequency=18, sparse_output=False),\n   ['city']),\n  ('scaled_air_quality',\n   StandardScaler(),\n   ['temp', 'humidity', 'co', 'no2', 'o3', 'pm100', 'pm25'])],\n 'aqi_transformer__verbose': False,\n 'aqi_transformer__verbose_feature_names_out': False,\n 'aqi_transformer__categories': OneHotEncoder(handle_unknown='infrequent_if_exist', max_categories=17,\n               min_frequency=18, sparse_output=False),\n 'aqi_transformer__scaled_air_quality': StandardScaler(),\n 'aqi_transformer__categories__categories': 'auto',\n 'aqi_transformer__categories__drop': None,\n 'aqi_transformer__categories__dtype': numpy.float64,\n 'aqi_transformer__categories__feature_name_combiner': 'concat',\n 'aqi_transformer__categories__handle_unknown': 'infrequent_if_exist',\n 'aqi_transformer__categories__max_categories': 17,\n 'aqi_transformer__categories__min_frequency': 18,\n 'aqi_transformer__categories__sparse_output': False,\n 'aqi_transformer__scaled_air_quality__copy': True,\n 'aqi_transformer__scaled_air_quality__with_mean': True,\n 'aqi_transformer__scaled_air_quality__with_std': True,\n 'RF_model__bootstrap': True,\n 'RF_model__ccp_alpha': 0.0,\n 'RF_model__class_weight': None,\n 'RF_model__criterion': 'gini',\n 'RF_model__max_depth': 27,\n 'RF_model__max_features': 'sqrt',\n 'RF_model__max_leaf_nodes': None,\n 'RF_model__max_samples': None,\n 'RF_model__min_impurity_decrease': 0.0,\n 'RF_model__min_samples_leaf': 5,\n 'RF_model__min_samples_split': 9,\n 'RF_model__min_weight_fraction_leaf': 0.0,\n 'RF_model__monotonic_cst': None,\n 'RF_model__n_estimators': 171,\n 'RF_model__n_jobs': None,\n 'RF_model__oob_score': False,\n 'RF_model__random_state': None,\n 'RF_model__verbose': 0,\n 'RF_model__warm_start': False}\n```\n:::\n:::\n\n\nUsing these hyperparameters, we reach an accuracy of about 63%.\n\n::: {#c3cbdfe2 .cell execution_count=29}\n``` {.python .cell-code}\ny_pred=random_search.predict(X_test)\nprint(\"cohen kappa score: \", cohen_kappa_score(y_test, y_pred))\nprint(\"accuracy: \", sum(y_pred == y_test)/len(y_test))\nConfusionMatrixDisplay(\n    confusion_matrix = confusion_matrix(\n        y_test, y_pred, \n        labels = ['0-30', '31-40', '41-50', '51-60', '61-70', '71-80', '81-90', '91-100', '101-150', '151+']\n        ), \n        display_labels = ['0-30', '31-40', '41-50', '51-60', '61-70', '71-80', '81-90', '91-100', '101-150', '151+']\n        ).plot(xticks_rotation='vertical')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ncohen kappa score:  0.4878374784893522\naccuracy:  0.6113228089275994\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](capstone_files/figure-html/cell-30-output-2.png){width=551 height=472}\n:::\n:::\n\n\nWe can use this model for the prediction of AQI, exploring the features that predict it, and use that to generate conclusions for what particles to reduce or systems to increase.\n\n---\ntitle: \"Conclusions\"\nformat: html\n---\n\n# Jake's conclusion\nAfter conducting our thorough research, we have landed on these specific recommendations. First, we found there are high seasonal trends where late summer/early fall tends to have the worst air quality. These numbers consistently show up each year, exasperated by the dry heat and lack of rainfall. As climate change raises temperatures and water sources dry up, wildfire season will continue to get worse over time. We must be aware of the nature of air quality and how it differs at different parts of the year. We should understand how the AQI works, and avoid being outside for too long when it reaches more dangerous levels.\n\nNext, we should focus on the variables that have the greatest impact on the AQI. These are city, temperature, humidity, CO, NO2, O3, PM10, and PM2.5. City, temperature, and humidity for the most part are out of our control. That leaves us with three criteria gasses and all particulate matter. The largest source of carbon monoxide, nitrogen dioxide, and ozone is the cars, trucks, and other vehicles we use daily (Environmental Protection Agency). We can lower our reliance on personal vehicles by utilizing public transportation, carpooling, walking, biking, increasing work from home to lower commutes when available, and overall be more considerate about if driving a car is necessary. We often drive unnecessarily, out of convenience or impatience. For many Americans, personal vehicles are required. Many urban and suburban areas lack proper public transportation, or existing public transportation systems are inadequate, unreliable, and infrequent. Many towns and cities in the United States were designed for cars instead of for people. Fixing this will require a substantial overhaul, necessitating millions or billions of dollars in spending. This is not to say that we shouldn’t bother, any investment that increases the public transportation system’s usage decreases the amount of cars on the road. A small step to start is better than not changing anything. \n\nIndustrial manufacturing processes, transport, and agriculture are significant polluters of the environment. We should decrease our reliance on these by purchasing more locally made products, lowering transportation distances. We should invest in the research of more environmentally friendly manufacturing methods, working with materials that require less combustion, or are recyclable. Agricultural reduction starts with less of a reliance on red meat and the dairy industry, mainstays of the American diet. This will be a huge shift, taking combined efforts of the citizens, government, and food industry. As red meat and dairy consumption goes down, possibly due to the replacement with artificial or lab grown meat, less livestock will need to be kept, and less feeding crops will need to be grown (Congressional Budget Office). It will be a difficult transition but a necessary one.\n\nWildfires not only increase the particle matter in the air, but burn forests, causing long term damage to the soil. Particulate matter in the air makes it more difficult to breathe, which is reflected by the increased AQI levels. Not all forest fires are started by man made sources, but many are. Therefore, when in the woods, one should always obey fire restrictions, especially in the middle of the summer when it’s most dry. If fires are allowed, they should always be watched and never left unattended. They must always be properly extinguished and all embers must be cool to the touch before leaving. Campsites should be properly cleaned, and all tools used correctly. One should also stay on marked trails, avoiding trampling vegetation which can increase the risk of wildfire spreading (Oregon Wildfire Response and Recovery).\n\nUltimately, we have a responsibility to take care of our planet and combat climate change. The worse climate conditions get, the more wildfires will spread, and the worse the air quality will become. As time goes on, with worsening air conditions, more people will catch and even die from preventable conditions sparked by poor air quality.  Water, pollution, food, and financial problems will get worse. One should look at what they can do to make a difference, support those who vouch to make larger changes, and encourage people they know to do the same. It can get much worse, but it can also get much better.\n\n# Stephane's conclusion\n\n\n## Insights and Limitations of Air Quality Forecasting\n\nOur capstone project has provided valuable experience in long-term air quality forecasting. However, it's crucial to acknowledge several key factors that influence the accuracy and reliability of these predictions:\n\n1. **Impact of Uncontrollable Environmental Factors**\n   - Air quality is significantly affected by various natural and unpredictable elements, including:\n     - Weather conditions\n     - Wind speed and direction\n     - Temperature fluctuations\n     - Humidity levels\n     - Atmospheric pressure\n     - Solar radiation intensity\n   \n   Our analysis revealed correlations between these variables, as illustrated in the following correlation matrix:\n\n   ![Correlation Matrix](https://github.com/wu-msds-capstones/Air-Quality-Index/blob/main/images/Correlation%20Matrix.png?raw=true)\n\n   Despite these complexities, our forecasts can provide a general trend of air quality fluctuations.\n\n2. **Algorithm Dependence**\n   - The reliability of forecasts is inherently tied to the chosen predictive algorithms.\n   - Different models may yield varying results, emphasizing the importance of algorithm selection and validation.\n\n3. **Geographical Considerations**\n   - Our data analysis couldn't fully quantify the unique geographical features of Portland and the broader Willamette Valley region:\n     - The protective influence of surrounding mountain ranges\n     - The impact on wind patterns and air circulation\n     - The potential effects of wildfires on air quality\n\n   These geographical factors play a significant role in local air quality dynamics but were beyond the scope of our current data set.\n     ![AirNow Map](https://github.com/wu-msds-capstones/Air-Quality-Index/blob/main/images/AirNow-Map.png?raw=true)\n\n\nBy recognizing these limitations, we can better interpret and apply our forecasting results, while also identifying areas for future research and data collection to enhance prediction accuracy.\n\n---\ntitle: \"Bibliography\"\nformat:\n  html:\n    anchor-sections: true\n    smooth-scroll: true\n--- \n\nAmerican Lung Association, https://www.lung.org/research/sota/key-findings  \n\nAirly, https://airly.org/en/how-does-humidity-affect-air-quality-all-you-need-to-know/  \n\nAirnow.gov, https://www.airnow.gov/aqi/aqi-basics/using-air-quality-index  \n\nCalifornia Air Resources Board, https://ww2.arb.ca.gov/resources/carbon-monoxide-and-health  \n\nCenters for Disease Control and Prevention, Agency for Toxic Substances and Disease Registry, https://wwwn.cdc.gov/TSP/ToxFAQs/ToxFAQsDetails.aspx?faqid=396&toxid=69  \n\nCenters for Disease Control and Prevention, Agency for Toxic Substances and Disease Registry, https://wwwn.cdc.gov/TSP/MMG/MMGDetails.aspx?mmgid=249&toxid=46 \n\nCongressional Budget Office, https://www.cbo.gov/publication/60030\n\nEnvironmental Protection Agency, https://www.epa.gov/pm-pollution/particulate-matter-pm-basics \n\nEnvironmental Protection Agency, https://www.epa.gov/ground-level-ozone-pollution/health-effects-ozone-pollution \n\nEnvironmental Protection Agency, https://www.epa.gov/clean-air-act-overview/evolution-clean-air-act \n\nFederal Transit Administration, https://www.apta.com/research-technical-resources/transit-statistics/ntd-data-tables/  \n\nFuller, Landrigan, Balakrishnan, et al., https://www.thelancet.com/journals/lanplh/article/PIIS2542-5196(22)00090-0/fulltext \n\nJacobs, Burgess, Abbott, https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5922205/  \n\nManisalidis, Stavropoulou, Stavropoulos, Bezirtzoglou, https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7044178/ \n\nNational Oceanic and Atmospheric Administration, https://oceanservice.noaa.gov/facts/nautical-mile-knot.html  \n\nNational Weather Service, https://www.weather.gov/source/zhu/ZHU_Training_Page/winds/pressure_winds/Pressure.htm \n\nOregon Wildfire Response and Recovery, https://wildfire.oregon.gov/prevention \n\nWorld Health Organization, https://www.who.int/news-room/fact-sheets/detail/lead-poisoning-and-health \n\nZhang Et. Al. https://acp.copernicus.org/articles/18/15003/2018/  \n\nWorld Health Organization, https://www.who.int/news/item/25-03-2014-7-million-premature-deaths-annually-linked-to-air-pollution\n\n",
    "supporting": [
      "capstone_files\\figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}