[
  {
    "objectID": "capstone.html",
    "href": "capstone.html",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "",
    "text": "On October 30, 1948, the Donora High School Football team played through a dense smog to complete the game with hundreds of fans in the audience, despite very poor visibility. The team, fueled by resilience, took pride in playing through poor conditions, a testament to the high spirit of the small town. Soon after, calls to the town’s medical offices began flooding in, complaining of difficulty breathing and respiratory issues. Donora, Pennsylvania, was a town of metalworks, built by the American Steel and Wire company and the Donora Zinc Works company, which made up major parts of the town’s economy. The heavy smog and pollution clouds that covered the sky had been viewed as a sign of prosperity, owing to the industrial might that powered their economy. Within just twelve hours, seventeen people would be dead, 1440 seriously affected, and 4470 with mild to moderate conditions—almost half the town’s working population (Jacobs, Burgess, Abbott).\nThis event, known as the Donora Smog of 1948, prompted the country into taking a closer look at the negative impacts of air pollution. Widespread debate surrounding the event led to the first legislation aimed at regulating the air quality within the United States, ushering in a new era of tracking, combatting, and reversing the ill effects of poor air quality. The quality of air we breathe has direct impacts on our health. We must understand the factors that contribute to poor air quality and how we individually and collectively contribute to these changes. Until we can visualize the impact we have on our atmosphere, we will continue behavior that negatively impacts the air around us.\nIn this project, we will focus on the key factors influencing air quality in Portland, Oregon. We aim to understand the complex interplay between various environmental and human-made factors that contribute to high air pollution levels. Initially, we were surprised to discover that Portland, the city we reside in, has some of the best air quality for a city of its size in the United States. This led us to narrow our focus to understanding the factors that contribute to these favorable outcomes in this city.\nOur project aims to develop and validate machine learning models to analyze the various factors influencing air quality. By focusing on Portland in comparison to other large US cities, we hope to find things Portland does that lead to the greater AQI outcomes. Our approach will consider a range of variables, including meteorological conditions, pollution sources, and transit systems. Through this analysis, we aim to provide actionable insights and recommendations for sustaining and improving air quality. By examining both the contributors to clean air and the sources of pollution, we can understand the factors affecting air quality and develop comprehensive strategies for enhancement."
  },
  {
    "objectID": "capstone.html#tools-deployed",
    "href": "capstone.html#tools-deployed",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "Tools Deployed",
    "text": "Tools Deployed\nPython will be the primary programming language used to conduct this analysis. We will also use R language in statistical applications where necessary.\nTo perform our analysis, we will employ NumPy and Pandas for data manipulation. Matplotlib and Seaborn for visualization, and Time Series forecasting algorithms such as Prophet and SARIMAX.\nWe will address data inconsistencies, missing values and ensure that data is in a tidy format. We may need to normalize or standardize data if necessary and create new features through aggregation to enhance the model’s performance.\n\nWhat is Prophet?\nProphet is an open-source forecasting tool developed by Meta, designed for forecasting time series data. It is suited for datasets with strong seasonal, monthly, weekly, or daily patterns, and it handles missing data and outliers well. We utilized prophet to gain a quick understanding of our AQI patterns, seeking to understand basic trends before conducting a more thorough analysis.\nKey features of Prophet include seasonality detection and holiday incorporation, while providing easy use and understanding for users. We can use this software to get complex understanding from simple applications.\nTo conduct this analysis, we prepare data into a two column table, date and AQI. Prophet uses the trends of past data to highlight similarities over days of the year, weeks, months, and seasons. From this, prophet is able to generate its predictions, cross validate, and give performance metrics such as mean absolute percentage error to quantify the accuracy of the results."
  },
  {
    "objectID": "capstone.html#what-is-sarimax",
    "href": "capstone.html#what-is-sarimax",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "What is SARIMAX?​​​​​​​​​​​​​​​",
    "text": "What is SARIMAX?​​​​​​​​​​​​​​​\nThe most common method used in time series forecasting is known as the ARIMA model. We will use an extended version called SARIMAX (Seasonal Auto Regressive Integrated Moving Averages with exogenous factor)\nHere’s a breakdown of its components: There are three distinct integers (p,d,q) that are used to parametrize SARIMAX models. Because of that, ARIMA models are denoted with the notation SARIMAX(p,d,q). Together these three parameters account for seasonality, trend, and noise in datasets:\n\nSeasonality (S): Accounts for recurring patterns or cycles in the data.\nAutoRegressive (AR): Uses past values to predict future values.\nIntegrated (I): Applies differencing to make the time series stationary.\nMoving Average (MA): Uses past forecast errors in the prediction.\neXogenous factors (X): Incorporates external variables that may influence the forecast.\n\nWe are trying to find the right p, d, q hyperparameters to correctly forecast and predict the AQI values.\nThe SARIMAX model is used when the data sets have seasonal cycles. In the dataset concerning the air quality/AQI there is a seasonal pattern which we have explained in the above section. SARIMAX is a model that can be fitted to time series data in order to better understand or predict future points. SARIMAX is particularly useful for forecasting time series data that exhibits both trends and seasonality."
  },
  {
    "objectID": "capstone.html#akaike-information-criteria-aic",
    "href": "capstone.html#akaike-information-criteria-aic",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "Akaike Information Criteria (AIC)?",
    "text": "Akaike Information Criteria (AIC)?\nThe Akaike Information Criterion (AIC) is a measure used to compare different statistical models. It helps in model selection by balancing the goodness of fit and the complexity of the model. Used to measure of a statistical model, the AiC quantifies the goodness of fit and its simplicity.When comparing two models, the one with the lower AIC is generally “better”.\nHere’s how to interpret the AIC value:\n\nAIC Value: A lower AIC value indicates a better-fitting model. It means the model has a good balance between accuracy and complexity.\nComparative Measure: AIC is most useful when comparing multiple models. The model with the lowest AIC among a set of candidate models is generally preferred.\nPenalty for Complexity: AIC includes a penalty for the number of parameters in the model. This discourages overfitting by penalizing models that use more parameters without a corresponding improvement in fit.\n\n\nTrain and Test\nRigorous validation is paramount to establishing the model’s reliability and practical application. To ensure the model’s generalizability, we will employ a train-test split. This approach safeguards against overfitting by exposing the model to unseen data, allowing for a more accurate assessment of its predictive capabilities.\nBy partitioning the dataset, we can:\n\nEvaluate performance: Measure the model’s accuracy on unseen data.\nDetect overfitting: Identify discrepancies between training and testing performance.\nAssess generalization: Determine the model’s ability to handle new data.\nQuantify reliability: Calculate confidence intervals for prediction accuracy.\nIteratively improve: Use insights to refine the model.\n\nThis rigorous process underpins the credibility and utility of our research findings. To split the data, we follow the recommended 70:30 ratio, 70% of the data is the training data, and 30% of the data is the testing data."
  },
  {
    "objectID": "capstone.html#data-organization",
    "href": "capstone.html#data-organization",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "Data Organization",
    "text": "Data Organization\nGiven the raw data available, the table structure was simplified compared to the original data sources. Data was organized in a star schema centered on the air_quality fact table. This table tracks AQI, pollutant, weather and toxin data daily for each location. It was necessary to split location and dates into separate dimension tables to reduce repeated data. The fact table includes all 1438 locations with a line for each of the 2922 days in the eight year time period, reaching a total of over 4.2 million rows. The first dimension table is the dates table, a serialized list of dates from January 1st, 2015 to December 31st, 2022. Next, we have a locations dimension table, a serialized list of over 1400 cities and towns from around the country. These are labeled by the state, county, and city name, as well as the population and population density, allowing connection to information based on what is given. The aqi_category dimension table is a short list of AQI value categories (Good, Unhealthy, Hazardous, etc.) with their respective AQI value range as minimum and maximum values. Finally, the yearly_transit dimension table gives the information for the transit system of the respective city during the specified year attached in the fact table. This table seems counterproductive to not include the location or year of the specified line or even a reference id, but in keeping with star schema, it was decided that this was the best way to reference this information. Understanding the context of a specified line requires joining the table back to the fact table, and joining the location and date tables to that as well.\nEach table has a unique serialized primary key, and all dimension tables are connected via foreign key. Several additional indexes are included on columns that will be queried often. Finally, constraints have been added to limit unusual or impossible data. For example, an AQI value less than 0 or greater than 500 would be impossible and thus would be caught by the constraint.\nTracking these identifiers independently allows for accurate analysis of changes over time and across different areas, and allows adding new information should we need to update the database. Figure 1 illustrates the resulting ERD structure using drawSQL.\n\n\n\nERD diagram, structure of database"
  },
  {
    "objectID": "capstone.html#initial-exploratory-data-analysis-eda",
    "href": "capstone.html#initial-exploratory-data-analysis-eda",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "Initial Exploratory Data Analysis (EDA)",
    "text": "Initial Exploratory Data Analysis (EDA)\nWe have a new dataset named metro_1mil.csv. This file was created using a SQL statement that joins all relevant tables, filtering for metropolitan areas with populations less than or equal to 1 million. This approach limits our EDA to mid-sized metropolitan cities, such as Portland, Oregon."
  },
  {
    "objectID": "capstone.html#visualization-aqi-distribution",
    "href": "capstone.html#visualization-aqi-distribution",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "Visualization AQI Distribution",
    "text": "Visualization AQI Distribution\nLet’s plot the AQI data distribution"
  },
  {
    "objectID": "capstone.html#dataframe-shape",
    "href": "capstone.html#dataframe-shape",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "Dataframe Shape",
    "text": "Dataframe Shape\nThe DataFrame contains 147039 rows and 44 columns."
  },
  {
    "objectID": "capstone.html#time-series-prediction",
    "href": "capstone.html#time-series-prediction",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "Time Series Prediction",
    "text": "Time Series Prediction\nFor this project, we have used an extended version of ARIMA model knows as SARIMAX model as we have explained in the methods section. The SARIMAX model is used when the data sets have seasonal cycles. In our dataset concerning air quality/AQI there is a seasonal pattern which we can see in the above visualization.\nWe need to find the right p,d and q parameters to correctly forecast and predict the AQI value.\n\np is the auto-regressive part of the model. It allows us to incorporate the effect of past values into our model.\nd is the integrated part of the model. This includes terms in the model that incorporate the amount of diferencing (the number of past time points to subtract from the current value) to apply the time series.\nq is the moving average part of the model. This allows us to set the error of our model as a linear combination of the error values observed at previous time points in the past.\n\nWe use a tuning technique called grid search method that attempts to compute the optimum values of hyperparameters. We are trying to find the right p,d,q values that would be given as an input to the SARIMAX time series model.\nWe have to find the lowest AIC values which would have the best corresponding p,d,q values to have the best forecast of AQI values."
  },
  {
    "objectID": "capstone.html#print-the-summary-which-includes-aic",
    "href": "capstone.html#print-the-summary-which-includes-aic",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "Print the summary which includes AIC",
    "text": "Print the summary which includes AIC\n\n\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nar.L1          0.0483      0.306      0.158      0.875      -0.551       0.648\nma.L1         -1.0000    924.523     -0.001      0.999   -1813.031    1811.031\nma.S.L12      -1.0000   2355.498     -0.000      1.000   -4617.692    4615.692\nsigma2       134.1503   3.35e+05      0.000      1.000   -6.57e+05    6.57e+05\n=============================================================================="
  },
  {
    "objectID": "capstone.html#forecasting-future-values",
    "href": "capstone.html#forecasting-future-values",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "Forecasting Future Values",
    "text": "Forecasting Future Values\nAs we conclude our modeling process, we generate predictions for the next 30 data points:\n\nModel Information: The result variable contains our fitted model’s details.\nForecasting Method: We use the .get_forecast() method on our model results.\nPrediction Generation: This method analyzes observed patterns in our data to project future values.\nOutput: We obtain forecasts for the next 30 time points, representing predicted air quality levels.\n\nThis step transforms our analytical work into actionable insights for air quality management."
  },
  {
    "objectID": "capstone.html#visualizing-our-results-the-culmination-of-our-analysis",
    "href": "capstone.html#visualizing-our-results-the-culmination-of-our-analysis",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "Visualizing Our Results: The Culmination of Our Analysis",
    "text": "Visualizing Our Results: The Culmination of Our Analysis\nThe final and crucial step of our project is the creation of a comprehensive plot that encapsulates our complex analysis. This visualization serves as the key to understanding and interpreting our findings.\n\nInterpreting the Forecast Plot\nOur plot consists of several key elements:\n\nObserved Values (Blue Line)\n\nRepresents the actual, historical air quality measurements\nProvides a baseline for comparing our predictions\n\nForecasted Values (Orange Line)\n\nDepicts the future air quality levels predicted by our SARIMAX Time Series Model\nAllows us to visualize potential trends and patterns in air quality\n\nConfidence Interval (Shaded Region)\n\nThe shaded area around the forecast line represents the 95% Confidence Interval (CI)\nIndicates the range within which we can be 95% confident that the true future values will fall\nWider intervals suggest greater uncertainty in the prediction\n\n\nThis visual representation not only summarizes our extensive data analysis but also provides a powerful tool for understanding potential future air quality trends. It bridges the gap between complex statistical models and actionable insights, making our findings accessible and meaningful to a broader audience."
  },
  {
    "objectID": "capstone.html#metrics-to-evaluate-machine-model-performance",
    "href": "capstone.html#metrics-to-evaluate-machine-model-performance",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "Metrics to Evaluate Machine Model Performance",
    "text": "Metrics to Evaluate Machine Model Performance\n\n\n\n\n\n\n\n\n\nTechnique/Metric\nDescription\nPurpose/Formula\nScenario: Cancer prediction\n\n\n\n\n1. Train-Test Split\nSplit the dataset into training and testing subsets\nAssess model performance on unseen data to detect overfitting and ensure generalizability\nAlways used; crucial for unbiased evaluation of model performance\n\n\n2. Cross-Validation\nDivide data into k subsets and train the model k times, using a different subset as test set each time\nProvides robust estimate of model performance by averaging results over multiple splits\nUseful for smaller datasets or when data collection is expensive (e.g., rare cancer types)\n\n\n3. Confusion Matrix\nTable comparing predicted and actual values in classification\nMetrics: True Positives (TP), True Negatives (TN), False Positives (FP), False Negatives (FN)\nFundamental for understanding model performance in classification tasks, like cancer detection\n\n\n4. Accuracy\nRatio of correctly predicted instances to total instances\n\\(\\frac{TP + TN}{TP + TN + FP + FN}\\)\nUsed when classes are balanced; less suitable for rare cancer detection due to class imbalance\n\n\n5a. Precision\nRatio of correctly predicted positive observations to total predicted positives\n\\(\\frac{TP}{TP + FP}\\)\nImportant when false positives are costly (e.g., unnecessary biopsies or treatments)\n\n\n5b. Recall (Sensitivity)\nRatio of correctly predicted positive observations to all actual positive observations\n\\(\\frac{TP}{TP + FN}\\)\nCritical in cancer detection to minimize false negatives (missed cancer cases)\n\n\n5c. F1-Score\nHarmonic mean of Precision and Recall\n\\(2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\\)\nBalances precision and recall; useful when seeking a compromise between false positives and false negatives\n\n\n6. ROC Curve and AUC\nROC: Graph of true positive rate vs false positive rate at various thresholds. AUC: Area under ROC curve\nHigher AUC indicates better model performance\nUseful for comparing models and choosing optimal threshold, especially in diagnostic tests\n\n\n7. Mean Absolute Error (MAE)\nAverage of absolute differences between predicted and actual values\n\\(\\frac{1}{n} \\sum_{i=1}^{n} \\|y_i - \\hat{y}_i\\|\\)\nUsed in regression tasks, e.g., predicting survival time; less sensitive to outliers than MSE\n\n\n8a. Mean Squared Error (MSE)\nAverage of squared differences between predicted and actual values\n\\(\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\\)\nUsed in regression; penalizes large errors more, suitable when large errors are particularly undesirable\n\n\n8b. Root Mean Squared Error (RMSE)\nSquare root of MSE\n\\(\\sqrt{\\text{MSE}}\\)\nSame as MSE, but in the original unit of the target variable, making it more interpretable\n\n\n9. R-squared\nProportion of variance in dependent variable predictable from independent variables\n\\(1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}\\)\nUsed in regression to assess overall fit; indicates how well the model explains the variance in the data\n\n\n10a. Akaike Information Criterion (AIC)\nMeasures relative quality of statistical model for given data\n\\(2k - 2\\ln(L)\\) where \\(k\\) is number of parameters and \\(L\\) is likelihood\nUsed for model selection; helps prevent overfitting by penalizing complex models\n\n\n10b. Bayesian Information Criterion (BIC)\nSimilar to AIC but with stronger penalty term for number of parameters\n\\(k\\ln(n) - 2\\ln(L)\\) where \\(n\\) is number of observations\nAlso used for model selection; tends to favor simpler models compared to AIC"
  }
]