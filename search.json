[
  {
    "objectID": "capstone.html",
    "href": "capstone.html",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "",
    "text": "In their journal article published in The American Journal of Public Health, Jacobs, Burgess, and Abbott tell the story of the Donora Pennsylvania Smog crisis. On October 30, 1948, the Donora High School Football team played through a dense smog to complete the game with hundreds of fans in the audience, despite very poor visibility. The team, fueled by resilience, took pride in playing through poor conditions, a testament to the high spirit of the small town. Soon after, calls to the town’s medical offices began flooding in, complaining of difficulty breathing and respiratory issues. Donora, Pennsylvania, was a town of metalworks, built by the American Steel and Wire company and the Donora Zinc Works company, which made up major parts of the town’s economy. The heavy smog and pollution clouds that covered the sky had been viewed as a sign of prosperity, owing to the industrial might that powered their economy. Within just twelve hours, seventeen people would be dead, 1440 seriously affected, and 4470 with mild to moderate conditions—almost half the town’s working population (Jacobs, Burgess, Abbott).\nThis event, known as the Donora Smog of 1948, prompted the country into taking a closer look at the negative impacts of air pollution. Widespread debate surrounding the event led to the first legislation aimed at regulating the air quality within the United States, ushering in a new era of tracking, combatting, and reversing the ill effects of poor air quality. The quality of air we breathe has direct impacts on our health. We must understand the factors that contribute to poor air quality and how we individually and collectively contribute to these changes. Until we can visualize the impact we have on our atmosphere, we will continue behavior that negatively impacts the air around us.\nIn this project, we will focus on the key factors influencing air quality in Portland, Oregon. We aim to understand the complex interplay between various environmental and human-made factors that contribute to high air pollution levels. Initially, we were surprised to discover that Portland, the city we reside in, has some of the best air quality for a city of its size in the United States. This led us to narrow our focus to understanding the factors that contribute to these favorable outcomes in this city.\nOur project aims to develop and validate machine learning models to analyze the various factors influencing air quality. By focusing on Portland in comparison to other large US cities, we hope to find things Portland does that lead to the greater AQI outcomes. Our approach will consider a range of variables, including meteorological conditions, pollution sources, transit systems, park land, and livestock. Through this analysis, we aim to provide actionable insights and recommendations for sustaining and improving air quality. By examining both the contributors to clean air and the sources of pollution, we can understand the factors affecting air quality and develop comprehensive strategies for enhancement."
  },
  {
    "objectID": "capstone.html#data-ethics",
    "href": "capstone.html#data-ethics",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "Data Ethics",
    "text": "Data Ethics\nThe ethical implications of conducting this analysis should always be considered and addressed. Air quality has historically impacted lower income communities significantly more. Marginalized communities may be built near major pollution sources such as factories or highways. In Portland, for example, Interstate 5 completed construction in 1966. It was part of an Oregon State Highway Department (OSHD) development, a project run by the state as a part of the Federal Aid Highway Act. The highway was built on the existing Minnesota Avenue, cutting North Portland, the heart of Portland’s African American community in half. It was decided to avoid affecting the higher income downtown properties. In fact, the OSHD contracted work on the Minnesota Ave portion of the highway to private contractors, in an effort to avoid a political battle (Oregon Encyclopedia). Today, the neighborhoods surrounding the large highway have worse AQI outcomes than those further away, all other factors equal (Shandas and George). Any recommendations given by this analysis should properly consider the ramifications of those impacted.\nAnother important ethical issue to be aware of is data transparency. Data can be used to push a specific narrative without faking or editing the specific data points. By leaving out important information, pushing correlated data as causation to push an agenda, or by purposely misconstruing what the data mean, one can create a narrative that can misinform or deceive readers. All analysis methodology must be openly discussed to ensure full understanding by audiences. This leads to credibility, reproducibility, and trust in the methods and conclusions of any piece of data analysis. All data is sourced from credible online sources that are open about their collection methods. Data privacy is addressed and no personalized information is given. Limitations are also addressed allowing readers to understand where any uncertainty may be."
  },
  {
    "objectID": "capstone.html#prophet",
    "href": "capstone.html#prophet",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "Prophet",
    "text": "Prophet\nProphet is an open-source forecasting tool developed by Meta, designed for forecasting time series data. It is suited for datasets with strong seasonal, monthly, weekly, or daily patterns, and it handles missing data and outliers well. We utilized prophet to gain a quick understanding of our AQI patterns, seeking to understand basic trends before conducting a more thorough analysis.\nKey features of Prophet include seasonality detection and holiday incorporation, while providing easy use and understanding for users. We can use this software to get complex understanding from simple applications.\nTo conduct this analysis, we prepare data into a two column table, date and AQI. Prophet uses the trends of past data to highlight similarities over days of the year, weeks, months, and seasons. From this, prophet is able to generate its predictions, cross validate, and give performance metrics such as mean absolute percentage error to quantify the accuracy of the results"
  },
  {
    "objectID": "capstone.html#sarimax",
    "href": "capstone.html#sarimax",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "SARIMAX​​",
    "text": "SARIMAX​​\nThe most common method used in time series forecasting is known as the ARIMA model. We will use an extended version called SARIMAX (Seasonal Auto Regressive Integrated Moving Averages with exogenous factor)\n\n(S) Seasonality: Accounts for recurring patterns or cycles in the data.\n(AR) AutoRegressive: Uses past values to predict future values.\n(I) Integrated: Applies differencing to make the time series stationary.\n(MA) Moving Average: Uses past forecast errors in the prediction.\n(X) eXogenous factors: Incorporates external variables that may influence the forecast.\n\nThe SARIMAX model is used when the data sets have seasonal cycles. In the dataset concerning the air quality/AQI there is a seasonal pattern. SARIMAX is a model that can be fitted to time series data in order to better understand or predict future points. SARIMAX is particularly useful for forecasting time series data that exhibits both trends and seasonality. There are three distinct integers (p,d,q) that are used to parametrize SARIMAX models. Because of that, SARIMAX models are denoted with the notation SARIMAX(p,d,q). Together these three parameters account for seasonality, trend, and noise in datasets:\n\np is the auto-regressive part of the model. It allows us to incorporate the effect of past values into our model.\nd is the integrated part of the model. This includes terms in the model that incorporate the amount of differencing (the number of past time points to subtract from the current value) to apply the time series.\nq is the moving average part of the model. This allows us to set the error of our model as a linear combination of the error values observed at previous time points in the past.\n\nWe use a tuning technique called grid search method that attempts to compute the optimum values of the hyperparameters. We are trying to find the right p,d,q values that would be given as an input to the SARIMAX time series model."
  },
  {
    "objectID": "capstone.html#akaike-information-criteria-aic",
    "href": "capstone.html#akaike-information-criteria-aic",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "Akaike Information Criteria (AIC)",
    "text": "Akaike Information Criteria (AIC)\nThe Akaike Information Criterion (AIC) is a measure used to compare different statistical models. It helps in model selection by balancing the goodness of fit and the complexity of the model. When comparing two models, the one with the lower AIC is generally “better”.\nHere’s how to interpret the AIC value:\n\nAIC Value: A lower AIC value indicates a better-fitting model. It means the model has a good balance between accuracy and complexity.\nComparative Measure: AIC is most useful when comparing multiple models. The model with the lowest AIC among a set of candidate models is generally preferred.\nPenalty for Complexity: AIC includes a penalty for the number of parameters in the model. This discourages overfitting by penalizing models that use more parameters without a corresponding improvement in fit."
  },
  {
    "objectID": "capstone.html#train-test-split",
    "href": "capstone.html#train-test-split",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "Train-Test-Split",
    "text": "Train-Test-Split\nRigorous validation is paramount to establishing the model’s reliability and practical application. To ensure the model’s generalizability, we will employ a train-test split. This approach safeguards against overfitting by exposing the model to unseen data, allowing for a more accurate assessment of its predictive capabilities.\nBy partitioning the dataset, we can:\n\nEvaluate performance: Measure the model’s accuracy on unseen data.\nDetect overfitting: Identify discrepancies between training and testing performance.\nAssess generalization: Determine the model’s ability to handle new data.\nQuantify reliability: Calculate confidence intervals for prediction accuracy.\nIteratively improve: Use insights to refine the model.\n\nThis rigorous process underpins the credibility and utility of our research findings. To split the data, we follow the recommended 70:30 ratio, 70% of the data is the training data, and 30% of the data is the testing data."
  },
  {
    "objectID": "capstone.html#hypothesis-testing",
    "href": "capstone.html#hypothesis-testing",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "Hypothesis Testing",
    "text": "Hypothesis Testing\nHypothesis tests for significance are conducted to understand the significance of differences in datasets. Statistics are done in R using a variety of statistical methods and measurements:\n\nNull Hypothesis: This serves as the baseline of a hypothesis test. It represents the idea that there is no effect, difference, or relationship between tested variables. Any observed differences are due to random chance.\nAlternate Hypothesis: On the other hand, the alternative hypothesis suggests a potential effect, difference, or relationship between tested variables exists. It reflects what is hoped to be found by the data.\nIndependence: The idea that data in one sample or population has no impact on the data in another sample or population.\nNormal Distribution: A continuous probability distribution symmetric around the mean. It is characterized by mean and standard deviation.\nNormal QQ Plot: A plot to measure the normality of a distribution. It compares the quantiles of a dataset against the quantiles of a theoretical normal distribution. Data is mapped along a y=x trendline. Deviations of the data from the trendline indicate non normality. An “S” shaped bend suggests data with heavy or light tails. A convex or concave bend suggests skewness in the distribution.\nHistogram: Plot that displayed data frequencies of values within specified intervals known as bins. Histograms are used to visualize the shape and spread of a distribution.\nWelch Two Sample t-test: This type of hypothesis test measures the statistical significance of the difference in mean of the two samples. Unlike the Student’s two sample t-test, the Welch two-sample t-test is used in cases where the groups being compared have unequal variances. A Welch two sample t-test includes the following:\n\nt-Statistic (t): Difference between sample means relative to variance of samples. Larger t-statistics indicate larger differences between means.\nDegrees of Freedom (df): Amount of information available to estimate variance of sample means.\np-Value: The probability of observing the sample data or something more extreme if the null hypothesis is true. A small p-value (&lt; 0.05) suggests the observed difference is statistically significant.\n95 Percent Confidence Interval: Range in which the true difference in means is 95% likely to lie within."
  },
  {
    "objectID": "capstone.html#machine-learning",
    "href": "capstone.html#machine-learning",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "Machine Learning",
    "text": "Machine Learning\nMachine learning is done in scikit-learn, an open source ML library built in Python. It is built on top of other common Python libraries such as NumPy, Pandas, and Matplotlib. The following tools are used:\n\nOne Hot Encoder: Transforms categorical data into a binary matrix. Each category is represented as a vector where one element is tagged with a 1 and all others are tagged as 0. This is done for certain machine learning algorithms that require all discrete data.\nStandard Scaler: Used to normalize or standardize numerical data. Certain machine learning algorithms are affected by unscaled data and therefore require normalized data.\nTransformer: Can be used to change multiple variables in one step in methods such as One Hot Encoder and Standard Scaler.\nPipeline: Allows multiple functions in a series of steps that can include transformers and models. Incorporates chaining to supply the output of one step as the input of the next step.\nFeature Selection: Chooses a subset of most relevant features, with the ability to specify how many features.\nHyperparameter Optimization: Selects the best set of hyperparameters in a model. These hyperparameters are set before training and control various aspects of the training process and model behavior. The optimization method used is a Randomized search. This evaluates a fixed number of random combinations from a specified distribution. This is far more efficient than a Grid search which systematically checks every single combination of the specified hyperparameter distribution.\nCohen Kappa Score: A statistical measure used to assess agreement between two classifiers when they categorize items into classes. In ML specifically, the Cohen Kappa Score is used to evaluate agreement between predicted and actual labels in classification algorithms. It is measured on a scale from -1 to 1, where 1 represents perfect agreement in classifiers, 0 represents agreement being no better or worse than random chance, and -1 represents perfect disagreement.\nRandom Forest Model: An ensemble model used in prediction tasks. It combines multiple decision trees and aggregates their predictions to improve performance and reduce overfitting.\nConfusion Matrix: Measures and visualizes the accuracy of a classification model. It breaks down raw numbers of correctly and incorrectly classified values.\nClassification Report: A detailed evaluation of the prediction model. Includes:\n\nPrecision: The ratio of correctly predicted positive observations to the total predicted positives\nRecall: The ratio of correctly predicted positive observations to all observations\nF1 score: Mean of precision and recall\nSupport: Number of observations\n\n\nReference Machine Learning Metrics Table in Appendix for additional information."
  },
  {
    "objectID": "capstone.html#data-organization",
    "href": "capstone.html#data-organization",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "Data Organization",
    "text": "Data Organization\nGiven the raw data available, the table structure was simplified compared to the original data sources. Data was organized around the air_quality table. This table tracks AQI, pollutant, weather and toxin data daily for each location. It includes all 1438 locations with a line for each of the 2922 days in the eight year time period, reaching a total of over 4.2 million rows. Location is split into a separate table to reduce repeated data. This table lists cities, labeled with their city name, county, and state. It includes metropolitan area population data given in raw numbers and as a density. Additionally, this table includes the city area in square kilometers and park area in acres. The aqi_category table is a short list of AQI value categories (Good, Unhealthy, Hazardous, etc.) with their respective AQI value range as minimum and maximum values. The yearly_transit table is connected to the location table and gives the information for the transit system of the respective city during the specified year. Finally, the livestock table, also connected via locations, includes counts for cattle, hogs, and sheep.\nThe central table has a compound primary key composed of location_id and date. Each other table has a serialized primary key, which are used to connect to each other. Several additional indexes are included on columns that will be queried often. Finally, constraints have been added to limit unusual or impossible data. For example, an AQI value less than 0 or greater than 500 would be impossible and thus would be caught by the constraint.\nTracking these identifiers independently allows for accurate analysis of changes over time and across different areas, and allows adding new information should we need to update the database. Figure 1 illustrates the resulting ERD structure using drawSQL.\n\n\n\nFigure 1: ERD diagram, structure of database"
  },
  {
    "objectID": "capstone.html#data-forecasting-with-prophet",
    "href": "capstone.html#data-forecasting-with-prophet",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "Data Forecasting with Prophet",
    "text": "Data Forecasting with Prophet\nProphet by Meta is used as time series prediction to estimate and map trends based on our data. We use this to see how AQI trends vary by day, month, and year. It is also able to give us a forecast for a given period after the end of our data which we can analyze and use to anticipate future AQI values.\nTo use the package, data must be in the format of a two column graph, with the first column being the date data, and the second being the variable being mapped and predicted. In this case, this predicted variable is AQI.\nThe package allows a future period to be generated, which can be specified and added to the end of the time data. It can then predict future AQI values for the new data period.\nThe graph below (figure 4324), shows the supplied data with the future prediction over the future period. The actual values are shown with the black datapoints, and the blue line represents the prediction. The upper and lower bounds of the error are represented with the transparent blue area. Each year, the data spikes during the late summer to early fall. Even more significant is the large spike in September 2020. What caused it? How significant was it?\n\n\n\nFigure 4324: Prophet Prediction"
  },
  {
    "objectID": "capstone.html#wildfires",
    "href": "capstone.html#wildfires",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "2020 Wildfires",
    "text": "2020 Wildfires\nIn September 2020, a wildfire ravaged the state of Oregon, as well as many other areas of the United States and Canada. The fires burned more than one million acres of land, destroying thousands of homes, and killing 11 people. 500,000 Oregonians were on evacuation alert, and 40,000 were actually forced to leave (Oregon Department of Emergency Management). Anyone around during that time will recall the orange skies, thick atmosphere, and strong smoke smell, but how unusual was this period actually?\nTo understand, we will conduct a two sample t-test to see whether or not this month had greater than usual AQI.\nNull Hypothesis: September 2020 AQI less than or equal to AQI of entire period in Portland\nAlternate Hypothesis: September 2020 AQI greater AQI of entire period in Portland\nAssumptions:\n\nSimple Random Sample: Data is not a simple random sample. Since there are so few datapoints for the September 2020 population (30 datapoints), taking a 10% sample may not be suitable to accurately capture the variance of this month. Thus, it was decided to use the entire population as the sample. A 10% sample will be taken of the entire Portland data population.\nIndependence: AQI in September 2020 does not affect AQI in the rest of the timeframe.\nNormal Distribution:\n\n\n\n\nFigure 4444: Wildfire Distribution\n\n\nFrom the QQ plots and histograms, we can see both datasets are clearly not normally distributed. They have long tails to the right, and the September 2020 dataset is oddly shaped due to lack of data.\nThe partial violations of the assumptions in the t test in our analysis suggest that the conclusions should be considered with a degree of caution.\nTwo Sample T Test September 2020 vs Full Period of Portland AQI\n\nBased on the low p value of 1.85*10-3, we reject the null. We conclude that the September AQI in Portland is not less than or equal to the AQI for the entire period. The wildfire had a significant effect on the air quality, making it much more difficult to breathe. This aligns with the observation of the large spike during this period. We must do more to address and combat the wildfires that not only harm the air we breathe, but cause long lasting damage to the local environment."
  },
  {
    "objectID": "capstone.html#aqi-trends",
    "href": "capstone.html#aqi-trends",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "AQI Trends",
    "text": "AQI Trends\nProphet’s plot component function allows us to see specific trends including the total (entire eight years), weekly, and yearly trends in figure 21111.\n\n\n\nFigure 21111: Prophet Component Trend Aggregations\n\n\nThis allows us to see how AQI changes by day. In the top full time span graph, it shows the potential spread of data for the predicted period with the transparent blue area. We can also see that day of the week tends to have very little impact on the trend (it may look significant but it is only moving up and down less than 1.5 AQI between days). Finally, from the yearly graph we can see the consistent increase during the late summer to mid fall each year."
  },
  {
    "objectID": "capstone.html#cross-validation",
    "href": "capstone.html#cross-validation",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "Cross Validation",
    "text": "Cross Validation\nHow accurate are these predictions? A cross validation predicts over the period from the cutoff date up to specified date in the ds column date.\nCross validating the predictions allows us to create many estimates from a starting date up to an end date within out timeframe. In this instance, the tool predicts using start dates every half a year. It will predict AQI for that date to every day up to a year after the start date, giving us 365 estimates per start date. We then compare all estimations seeing how accurate the prediction is for a number of days after the start date.\nThe tool allows us to measure the difference in predicted y and actual y with a variety of different measurements. In figure 559955 below, we have selected mean absolute percent error, to show how if the error on average increased as the prediction got further from the starting point.\n\n\n\nFigure 559955: Prophet Error on Cross Validated Estimates\n\n\nThe light grey datapoints represent the mean absolute percent error. A datapoint with a x value 200 and y value 1 means it was predicted for a period of 200 days after the cutoff date, and was 1% off the actual value. We can see that most predictions are under 1%, making this a pretty decent estimation. The fact that they do not increase over time allows us to have a certain degree of confidence in the prediction even a year out. The blue line shows the mean of these datapoints."
  },
  {
    "objectID": "capstone.html#portlands-transit-system",
    "href": "capstone.html#portlands-transit-system",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "Portland’s Transit System",
    "text": "Portland’s Transit System\nAs shown in the graphs and tests above, Portland has greater than normal AQI outcomes when compared with other cities of high populations. The AQI follows certain yearly trends, with the notable exception in September 2020 due to the large wildfires. Using Prophet, we are able to predict AQI up to a year out of the final datapoint in the time period. What exactly is the reason for these outcomes in this city?\nOne hypothesis for Portland’s better air quality outcomes is due to the increased focus on public transportation. Portland has placed high emphasis on utilizing public transit, with rates comparable to larger cities and higher than most other cities of its size. We will run a two sample t test to see how Portland’s rate of ridership compares with other large cites.\nWe have standardized rates by passenger miles ridden per person. This is the total amount of miles ridden in a given year divided by the population. This allows us to properly compare cities with different population sizes.\nNull Hypothesis: Transit ridership in Portland is less than or equal to transit ridership across the country (large metro areas only).\nAlternate Hypothesis: Transit ridership in Portland is greater than transit ridership across the country (large metro areas only).\nAssumptions:\n\nSimple Random Sample: Data is not a simple random sample. Since there are so few datapoints for the Portland transit ridership population (8 datapoints), taking a 10% sample may not be suitable to accurately capture the variance of this month. Thus, it was decided to use the entire population as the sample. A 10% sample will be taken of the large cities transit population.\nIndependence: Transit ridership in Portland does not affect transit ridership in the rest of the country.\nNormal Distribution:\n\n\n\n\nFigure 300000: Transit Distribution\n\n\nFrom the QQ plots and histograms, we can see both datasets are clearly not normally distributed. The Portland data has so few datapoints that it is hard to tell if it has a normal distribution or not. The large city transit data seems normal with the exception of one datapoint.\nThe partial violations of the assumptions in the t test in our analysis suggest that the conclusions should be considered with a degree of caution.\nTwo Sample T Test Portland Transit Ridership vs Large Metro Area Ridership\n\nBased on the high p value of 0.2469, we fail to reject the null. We cannot conclude that Portland’s transit ridership is different from the average transit ridership of other large metro areas across the country. Transit ridership may have some impact on AQI but not enough to make a statistical difference by itself. Likely, this is a situation of correlated variables. Cities that invest more in public infrastructure are more likely to make a concerned effort into being environmentally conscious.\nIt should also be noted that some cities have higher public transit numbers not reflected in the data. For example, in New York City, subway ridership is almost double that of its motor bus numbers. In this data only motor bus numbers were included which may contribute to the lack of evidence for transit numbers influence on AQI. We will explore which features have a greater effect on AQI in the upcoming Machine Learning section."
  },
  {
    "objectID": "capstone.html#statsmodel",
    "href": "capstone.html#statsmodel",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "Statsmodel",
    "text": "Statsmodel\nUsing the statsmodel package, we can map the seasonal pattern and trends using seasonal_decompose method. It requires as inputs a dataframe with two columns date data and the AQI. This will help us to understand the seasonality and trend clearly and allowing us to make more sense of the data for the forecast. In a additive time series, the components add together to make the time series. If you have an increasing trend, you still see roughly the same size peaks and troughs throughout the time series."
  },
  {
    "objectID": "capstone.html#components-of-a-time-series",
    "href": "capstone.html#components-of-a-time-series",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "Components Of A Time Series",
    "text": "Components Of A Time Series\nTime series decomposition is a statistical technique that separates data into three key components: trend, seasonality, and residuals. The trend shows the long-term direction, seasonality reveals recurring patterns, and residuals represent unexplained variations. Visualizing these components individually provides insights that may not be evident in the raw data. This process helps analysts identify underlying patterns, recognize cyclical behaviors, and detect anomalies.\nBy understanding these elements separately, we can gain deeper insights into the factors driving the time series, leading to more accurate analysis and forecasting. Decomposition is particularly useful when the complexity of a time series makes it challenging to discern important patterns from simple observation of the dataset.\n\n\n\n\n\n\n\n\n\nFigure 20: Seasonal, Trend, and Residual Decomposition of Portland AQI Time Series\nThe uppermost graph, labeled Observed, presents the raw time series data as originally recorded. Its y-axis quantifies the daily air quality measurements, while the x-axis represents the passage of time. This graph is a composite representation, effectively combining the three underlying components: trend, seasonality, and residuals. A notable anomaly is evident in the data: a significant spike in air quality measurements occurring in September 2020. This outlier corresponds to the severe wildfires that ravaged Oregon during that period. The dramatic increase in air pollution levels during this time underscores the profound impact of extreme environmental events on air quality.\nThe Seasonal component graph illustrates the cyclical patterns in air quality that repeat annually. This visualization reveals a distinctive yearly pattern in Air Quality Index (AQI) fluctuations. The cycle begins with relatively low AQI values, indicating better air quality. As the year progresses, the AQI rises to a peak, signifying a period of poorer air quality. This is followed by an improvement (decrease in AQI), another deterioration (increase), and a final improvement towards the year’s end. These recurring variations likely reflect the influence of seasonal factors such as changing weather patterns, temperature inversions, and seasonal human activities. For instance, winter months might see higher AQI due to increased heating emissions, while spring could bring lower AQI with more favorable dispersion conditions.\nThe graph includes a highlighted box that demarcates the seasonal period. This visual element clearly illustrates the duration and boundaries of one complete seasonal cycle in the air quality data. Understanding these seasonal trends is crucial for accurately interpreting air quality data and making informed predictions. It allows environmental agencies and policymakers to anticipate periods of potentially compromised air quality and plan interventions accordingly.\nLastly, the final row displays the Residuals, which represent the portion of the data not explained by the trend or the seasonal component. We can interpret the residuals as the difference between the sum of the Trend and Seasonal components and the Observed values at each point in time. Essentially, the Residuals indicate the amount that needs to be added to the Trend and Seasonal components to align the result with the Observed values. Residuals are typically attributed to random errors, often referred to as white noise, which we will explore further. These residuals embody the unpredictable elements of the data that cannot be captured or forecasted by the model, as they are inherently random."
  },
  {
    "objectID": "capstone.html#finding-the-best-forecasting-model-with-grid-search",
    "href": "capstone.html#finding-the-best-forecasting-model-with-grid-search",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "Finding the Best Forecasting Model with Grid Search",
    "text": "Finding the Best Forecasting Model with Grid Search\nFor this project, we used an extended version of ARIMA model knows as SARIMAX model as we have explained in the methods section. We use a tuning technique called grid search method that attempts to compute the optimum values of hyperparameters. We are trying to find the right p,d,q values that would be given as an input to the SARIMAX time series model. This process helps us find the best settings for a forecasting model called SARIMAX by testing various options to find the best fit for our data. Here’s an easy-to-understand explanation of how this works:\n\nStep 1: Getting Everything Ready\nWe start by setting up all the tools we need for our analysis.\n\n\nStep 2: Setting Up Our Options\nWe define different settings that the SARIMAX model can use to predict future values. These include the p, d, and q parameters, which help the model decide how much weight to give to past values, trends, and patterns. We then create a list of all possible combinations of these settings.\n\n\nStep 3: Adding Seasonal Flavors\nWe know that some data has seasonal patterns, like sales going up during the holidays. We include options for these seasonal changes.\n\n\nStep 4: Trying Out Different Combinations\nWe go through each combination of settings to see how well each one works. For each main setting, we also try different seasonal settings to find the perfect combination.\n\n\nStep 5: Checking the Results\nFor each set of settings, we create a forecasting model and test it on our data. We measure how well each model works using a score called the Akaike Information Criterion (AIC). This score tells us how well the model predicts the data, with lower scores being better. If something goes wrong with a particular set of settings, we catch the error and move on to the next set without stopping the whole process.\nWe have to find the lowest AIC values which would have the best corresponding p,d,q values to have the best forecast of AQI values."
  },
  {
    "objectID": "capstone.html#sarimax-model-results",
    "href": "capstone.html#sarimax-model-results",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "SARIMAX Model Results",
    "text": "SARIMAX Model Results\n\n\n                                     SARIMAX Results                                      \n==========================================================================================\nDep. Variable:                                aqi   No. Observations:                   96\nModel:             SARIMAX(1, 1, 1)x(0, 1, 1, 12)   Log Likelihood                -276.765\nDate:                            Tue, 13 Aug 2024   AIC                            561.530\nTime:                                    15:13:32   BIC                            570.467\nSample:                                01-31-2015   HQIC                           565.076\n                                     - 12-31-2022                                         \nCovariance Type:                              opg                                         \n==========================================================================================\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nar.L1          0.0483      0.306      0.158      0.875      -0.551       0.648\nma.L1         -1.0000    924.523     -0.001      0.999   -1813.031    1811.031\nma.S.L12      -1.0000   2355.498     -0.000      1.000   -4617.692    4615.692\nsigma2       134.1503   3.35e+05      0.000      1.000   -6.57e+05    6.57e+05\n==============================================================================\n\n\nThis summary presents a concise overview of the SARIMAX model’s performance and fit. The SARIMAX(1, 1, 1)x(0, 1, 1, 12) model integrates both non-seasonal and seasonal components, effectively capturing both immediate and periodic influences on the Air Quality Index (AQI). The model utilizes 96 observations, providing a robust dataset for accurate model fitting. Key metrics such as the log-likelihood, AIC, BIC, and HQIC are used to assess the model’s effectiveness, with lower values typically indicating a better fit that balances complexity and accuracy. The summary also includes the date and time of model execution, the timeframe of the data, and the type of covariance used, which aids in understanding how the model accounts for uncertainties in parameter estimates.\n\nAutoregressive Term (ar.L1)\nCoefficient: 0.0483 Suggests a slight positive influence of the previous observation on the current value. Standard Error: 0.306 Indicates significant variability in the coefficient estimate. Z-Value: 0.158 Low value, indicating the coefficient is not statistically significant. P-Value: 0.875 Not significant (p-value &gt; 0.05). Confidence Interval: [-0.551, 0.648] Includes zero, reinforcing the lack of significance.\n\n\nMoving Average Term (ma.L1)\nCoefficient: -1.0000 Implies the model tries to correct nearly all errors from the previous period. Standard Error: 924.523 Extremely large, pointing to high uncertainty in the estimate. Z-Value: -0.001 Near zero, indicating no statistical significance. P-Value: 0.999 Not significant. Confidence Interval: [-1813.031, 1811.031] Very wide and includes zero, confirming lack of significance.\n\n\nSeasonal Moving Average Term (ma.S.L12)\nCoefficient: -1.0000 Attempts to correct errors regarding data seasonality. Standard Error: 2355.498 Very large, indicating substantial uncertainty. Z-Value: -0.000 Near zero, suggesting no significance. P-Value: 1.000 Not significant. Confidence Interval: [-4617.692, 4615.692] Wide interval, includes zero, further indicating no significance.\n\n\nVariance of the Residuals (sigma2)\nCoefficient: 134.1503 Represents the variance of the residuals or errors. Standard Error: 335000 Extremely high, showing great uncertainty. Z-Value: 0.000 Indicates no statistical significance. P-Value: 1.000 Not significant. Confidence Interval: [-657000, 657000] Very wide, includes zero, highlighting lack of significance.\n##Overall Summary None of the coefficients in the SARIMAX model are statistically significant, as indicated by the high p-values and z-values close to zero. This means that the parameters do not effectively predict the AQI data. The large standard errors and wide confidence intervals point to a high degree of uncertainty in the parameter estimates. This suggests the model may not be well-suited for capturing the dynamics of the AQI data, and re-evaluation of the model or data is recommended."
  },
  {
    "objectID": "capstone.html#fit-sarimax-model",
    "href": "capstone.html#fit-sarimax-model",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "Fit SARIMAX model",
    "text": "Fit SARIMAX model\n\n\nThe AIC value is: 561.5301944999834\n\n\nExplain what is the value AIC tells us, and how to interpret the plot. Look at the method\nOnce the model is created, predicted values are generated using the .get_prediction() method, with datetime as input.\nTo facilitate comparison of true and predicted test values, we will create a separate DataFrame. Mean Error Estimation will be used for analysis.\nTo evaluate model performance, we calculate the MSE.\n\n\nThe Mean Squared Error of our forecasts is 1.41"
  },
  {
    "objectID": "capstone.html#forecasting-future-values",
    "href": "capstone.html#forecasting-future-values",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "Forecasting Future Values",
    "text": "Forecasting Future Values\nAs we conclude our modeling process, we generate predictions for the next 30 data points:\n\nModel Information: The result variable contains our fitted model’s details.\nForecasting Method: We use the .get_forecast() method on our model results.\nPrediction Generation: This method analyzes observed patterns in our data to project future values.\nOutput: We obtain forecasts for the next 30 time points, representing predicted air quality levels.\n\nThis step transforms our analytical work into actionable insights for air quality management."
  },
  {
    "objectID": "capstone.html#visualizing-our-results",
    "href": "capstone.html#visualizing-our-results",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "Visualizing Our Results",
    "text": "Visualizing Our Results\nThe final and crucial step of our project is the creation of a comprehensive plot that encapsulates our complex analysis. This visualization serves as the key to understanding and interpreting our findings.\n\nInterpreting the Forecast Plot\nOur plot consists of several key elements:\n\nObserved Values (Blue Line)\n\nRepresents the actual, historical air quality measurements\nProvides a baseline for comparing our predictions\n\nForecasted Values (Orange Line)\n\nDepicts the future air quality levels predicted by our SARIMAX Time Series Model\nAllows us to visualize potential trends and patterns in air quality\n\nConfidence Interval (Shaded Region)\n\nThe shaded area around the forecast line represents the 95% Confidence Interval (CI)\nIndicates the range within which we can be 95% confident that the true future values will fall\nWider intervals suggest greater uncertainty in the prediction\n\n\nThis visual representation not only summarizes our extensive data analysis but also provides a powerful tool for understanding potential future air quality trends. It bridges the gap between complex statistical models and actionable insights, making our findings accessible and meaningful to a broader audience."
  },
  {
    "objectID": "capstone.html#bibliography",
    "href": "capstone.html#bibliography",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "Bibliography",
    "text": "Bibliography\nAirly. (n.d.). How does humidity affect air quality? All you need to know. airly.org/en/how-does-humidity-affect-air-quality-all-you-need-to-know/\nAirNow. (n.d.). Using air quality index. www.airnow.gov/aqi/aqi-basics/using-air-quality-index\nAmerican Lung Association. (n.d.). Key findings: State of the air. www.lung.org/research/sota/key-findings\nCalifornia Air Resources Board. (n.d.). Carbon monoxide & health. ww2.arb.ca.gov/resources/carbon-monoxide-and-health\nCenters for Disease Control and Prevention, Agency for Toxic Substances and Disease Registry. (2014, October 21). Medical management guidelines for sulfur dioxide. wwwn.cdc.gov/TSP/MMG/MMGDetails.aspx?mmgid=249&toxid=46\nCenters for Disease Control and Prevention, Agency for Toxic Substances and Disease Registry. (2023, April 12). Toxic substances portal - Nitrogen oxides. wwwn.cdc.gov/TSP/ToxFAQs/ToxFAQsDetails.aspx?faqid=396&toxid=69\nCongressional Budget Office. (2023, May). Reducing emissions from transportation. www.cbo.gov/publication/60030\nEnvironmental Protection Agency. (n.d.-a). Evolution of the Clean Air Act. www.epa.gov/clean-air-act-overview/evolution-clean-air-act\nEnvironmental Protection Agency. (n.d.-b). Health effects of ozone pollution. www.epa.gov/ground-level-ozone-pollution/health-effects-ozone-pollution\nEnvironmental Protection Agency. (n.d.-c). Particulate matter (PM) basics. www.epa.gov/pm-pollution/particulate-matter-pm-basics\nFederal Transit Administration. (n.d.). NTD data tables. American Public Transportation Association. www.apta.com/research-technical-resources/transit-statistics/ntd-data-tables/\nFuller, R., Landrigan, P. J., Balakrishnan, K., Bathan, G., Bose-O’Reilly, S., Brauer, M., Caravanos, J., Chiles, T., Cohen, A., Corra, L., Cropper, M., Ferraro, G., Hanna, J., Hanrahan, D., Hu, H., Hunter, D., Janata, G., Kupka, R., Lanphear, B., . . . Yadama, G. N. (2022). Pollution and health: A progress update. The Lancet Planetary Health, 6(6), e535-e547. www.thelancet.com/journals/lanplh/article/PIIS2542-5196(22)00090-0/fulltext\nJacobs, E. T., Burgess, J. L., & Abbott, M. B. (2018). The Donora smog revisited: 70 years after the event that inspired the clean air act. American Journal of Public Health, 108(S2), S85-S88. www.ncbi.nlm.nih.gov/pmc/articles/PMC5922205/\nManisalidis, I., Stavropoulou, E., Stavropoulos, A., & Bezirtzoglou, E. (2020). Environmental and health impacts of air pollution: A review. Frontiers in Public Health, 8, 14. www.ncbi.nlm.nih.gov/pmc/articles/PMC7044178/\nNational Oceanic and Atmospheric Administration. (n.d.). What are a nautical mile and a knot? oceanservice.noaa.gov/facts/nautical-mile-knot.html\nNational Weather Service. (n.d.). Pressure and winds. www.weather.gov/source/zhu/ZHU_Training_Page/winds/pressure_winds/Pressure.htm\nOregon Wildfire Response and Recovery. (n.d.). Wildfire prevention. wildfire.oregon.gov/prevention\nWorld Health Organization. (2014, March 25). 7 million premature deaths annually linked to air pollution. www.who.int/news/item/25-03-2014-7-million-premature-deaths-annually-linked-to-air-pollution\nWorld Health Organization. (2022, October 31). Lead poisoning and health. www.who.int/news-room/fact-sheets/detail/lead-poisoning-and-health\nZhang, Y., Cooper, O. R., Gaudel, A., Thompson, A. M., Nédélec, P., Ogino, S. Y., & West, J. J. (2018). Tropospheric ozone change from 1980 to 2010 dominated by equatorward redistribution of emissions. Nature Geoscience, 11, 637-644. acp.copernicus.org/articles/18/15003/2018/"
  },
  {
    "objectID": "capstone.html#additional-resources---eda",
    "href": "capstone.html#additional-resources---eda",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "Additional Resources - EDA",
    "text": "Additional Resources - EDA\n\nExploratory Data Analysis\nWe have new dataset metro_1mil.csv. This file was generated using a SQL statement that joins all relevant tables, filtering for metropolitan areas with populations less than or equal to 1 million. This approach limits our EDA to mid-sized metropolitan cities, such as Portland, Oregon.\nLet’s plot the AQI data distribution\nThe DataFrame contains 147039 rows and 44 columns.\nBy filtering our Dataframe for Oregon state, our DataFrame contains 2922 rows.\n\n\nFeatures Engineering\nDate Column Preprocessing:\n\nConverted the date column to DateTime objects for easier manipulation and analysis.\nExtracted additional time-based features: year, month, day of week, and quarter.\n\nFeature Selection:\n\nRemoved irrelevant columns to focus the analysis on pertinent variables.\nRetained features: pollutant, aqi, wind\n\nMissing Value Treatment:\n\nIdentified columns with missing values: most all of them\nApplied mean() imputation method for numerical columns.\nFor categorical columns: n/a\n\nData Types and Memory Usage:\n\nOptimized data types to reduce memory usage (e.g., using categories for low-cardinality strings, int8/int16 for small integers).\n\nBasic Statistics:\n\nGenerated summary statistics for numerical columns using df.describe().\nCalculated frequency distributions for categorical variables.\n\nDistribution Analysis:\n\nPlotted histograms and kernel density estimates for main numerical features.\n\nTime Series Components:\n\nDecomposed time series data into trend, seasonality, and residual components for relevant variables.\n\n\n\nSweetviz Data Report\nWe have generated Sweetviz statistical report confirming the quality of EDA steps.\n\n\nAdvanced Data Analysis\nWe have also employed the ydata-profiling package, a powerful Time Series Analysis EDA package that offers more detailed analysis.\nWe have unlocked time series-specific features using ydata-profiling: We ensure our DataFrame is sorted or specify the sortby parameter, setting tsmode=True when creating the ProfileReport to allow Time Series Feature Identification\nThe ydata-profiling identifies time-dependent features using autocorrelation analysis.\nFor recognized time series features, the histograms are replaced with line plots and feature details include new autocorrelation and partial autocorrelation plots.\nTo handle Multi-Entity Time Series Data, In our case, with category_id, each pollutants represents a distinct time series. For optimal analysis, we filter and profile each pollutant separately\nTo conclude our exploratory data analysis (EDA) process consisted of two complementary approaches:\n\nManual Investigation: We conducted an in-depth, hands-on examination of the dataset.\nAutomated Analysis: We leveraged two powerful EDA packages: Sweetviz For quick, visual data summaries, ydata-profiling for more detailed, customizable reports\n\nThese methods allowed us to thoroughly evaluate key data quality aspects, including:\n\nClass balance in categorical variables\nPresence and distribution of missing values (NaN)\nFeature distributions and correlations\nPotential time-series characteristics\n\nThis multi-faceted approach ensures a robust understanding of our dataset’s structure, quality, and potential challenges before proceeding with further analysis.\n\n\nTime Series Visualization in Portland\n\nCarbon Monoxyde (CO), Wind and Air Quality Index (AQI)\nCO pollutant refers to carbon monoxide, which is a colorless, odorless, and tasteless gas that can be harmful to human health and the environment. Here’s some key information about CO as a pollutant:\nPrimarily produced by incomplete combustion of carbon-containing fuels Major sources include vehicle exhaust, industrial processes, and some natural sources like volcanoes\n\nSlightly less dense than air\nHighly flammable\n\n\n\n&lt;Figure size 1000x1800 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\n\nNitrogen Dioxide (NO2), Sulfur Dioxyde (SO2) and Ozone (O₃)\nNO2 (nitrogen dioxide) is an important air pollutant. - Reddish-brown gas with a pungent odor - Part of a group of pollutants known as nitrogen oxides (NOx)\nSO2 (sulfur dioxide) is an important air pollutant. - Colorless gas with a sharp, pungent odor - Highly soluble in water\nOzone (O₃) as a pollutant is a complex topic, as it can be both beneficial and harmful depending on its location in the atmosphere. - Colorless to pale blue gas with a distinctive smell - Highly reactive molecule composed of three oxygen atoms\n\n\n&lt;Figure size 1500x2000 with 0 Axes&gt;"
  },
  {
    "objectID": "capstone.html#additional-resources---machine-learning-metrics-table",
    "href": "capstone.html#additional-resources---machine-learning-metrics-table",
    "title": "Unveiling the Drivers of Clean Air",
    "section": "Additional Resources - Machine Learning Metrics Table",
    "text": "Additional Resources - Machine Learning Metrics Table\n\n\n\n\n\n\n\n\n\nTechnique/Metric\nDescription\nPurpose/Formula\nScenario: Cancer prediction\n\n\n\n\n1. Train-Test Split\nSplit the dataset into training and testing subsets\nAssess model performance on unseen data to detect overfitting and ensure generalizability\nAlways used; crucial for unbiased evaluation of model performance\n\n\n2. Cross-Validation\nDivide data into k subsets and train the model k times, using a different subset as test set each time\nProvides robust estimate of model performance by averaging results over multiple splits\nUseful for smaller datasets or when data collection is expensive (e.g., rare cancer types)\n\n\n3. Confusion Matrix\nTable comparing predicted and actual values in classification\nMetrics: True Positives (TP), True Negatives (TN), False Positives (FP), False Negatives (FN)\nFundamental for understanding model performance in classification tasks, like cancer detection\n\n\n4. Accuracy\nRatio of correctly predicted instances to total instances\n\\(\\frac{TP + TN}{TP + TN + FP + FN}\\)\nUsed when classes are balanced; less suitable for rare cancer detection due to class imbalance\n\n\n5a. Precision\nRatio of correctly predicted positive observations to total predicted positives\n\\(\\frac{TP}{TP + FP}\\)\nImportant when false positives are costly (e.g., unnecessary biopsies or treatments)\n\n\n5b. Recall (Sensitivity)\nRatio of correctly predicted positive observations to all actual positive observations\n\\(\\frac{TP}{TP + FN}\\)\nCritical in cancer detection to minimize false negatives (missed cancer cases)\n\n\n5c. F1-Score\nHarmonic mean of Precision and Recall\n\\(2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\\)\nBalances precision and recall; useful when seeking a compromise between false positives and false negatives\n\n\n6. ROC Curve and AUC\nROC: Graph of true positive rate vs false positive rate at various thresholds. AUC: Area under ROC curve\nHigher AUC indicates better model performance\nUseful for comparing models and choosing optimal threshold, especially in diagnostic tests\n\n\n7. Mean Absolute Error (MAE)\nAverage of absolute differences between predicted and actual values\n\\(\\frac{1}{n} \\sum_{i=1}^{n} \\|y_i - \\hat{y}_i\\|\\)\nUsed in regression tasks, e.g., predicting survival time; less sensitive to outliers than MSE\n\n\n8a. Mean Squared Error (MSE)\nAverage of squared differences between predicted and actual values\n\\(\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\\)\nUsed in regression; penalizes large errors more, suitable when large errors are particularly undesirable\n\n\n8b. Root Mean Squared Error (RMSE)\nSquare root of MSE\n\\(\\sqrt{\\text{MSE}}\\)\nSame as MSE, but in the original unit of the target variable, making it more interpretable\n\n\n9. R-squared\nProportion of variance in dependent variable predictable from independent variables\n\\(1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}\\)\nUsed in regression to assess overall fit; indicates how well the model explains the variance in the data\n\n\n10a. Akaike Information Criterion (AIC)\nMeasures relative quality of statistical model for given data\n\\(2k - 2\\ln(L)\\) where \\(k\\) is number of parameters and \\(L\\) is likelihood\nUsed for model selection; helps prevent overfitting by penalizing complex models\n\n\n10b. Bayesian Information Criterion (BIC)\nSimilar to AIC but with stronger penalty term for number of parameters\n\\(k\\ln(n) - 2\\ln(L)\\) where \\(n\\) is number of observations\nAlso used for model selection; tends to favor simpler models compared to AIC"
  }
]