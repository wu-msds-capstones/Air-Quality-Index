---
title: "Result Prophet & Hypothesis Testing"
format: html
#editor: visual
jupyter: r
execute:
  echo: true
  output: true
---

# Prophet AQI Trend Visualization and Forecasting
Prophet by Meta is used as time series prediction to estimate and map trends based on out data. We use this to see how AQI trends vary by day, month, and year. It is also able to give us a forecast for a given period after the end of our data which we can analyze and use to anticipate future AQI values.

```{r}
#| warning: false
library(prophet)
library(DBI)
library(dbplyr)
library(tidyverse)
library(RPostgres)
library(rpivotTable)
```

Initially, we connected the R instance to the PostgreSQL database and pulled information directly using dbConnece and RPostgres. For this report, we simply call our information from a local csv.

```{r}
# con <- dbConnect(RPostgres::Postgres(),
#                  dbname = 'air',
#                  host = 'localhost',
#                  port = 5432,
#                  user = 'postgres',
#                  password = 'postgres')

metro_1mil = read.csv('https://raw.githubusercontent.com/wu-msds-capstones/Air-Quality-Index/main/data/metro_1mil.csv')

#Portland Only

# portland <- tbl(con, sql("SELECT * FROM air.air_quality
#                        LEFT JOIN air.dates USING (date_id)
#                        LEFT JOIN air.locations USING (location_id)
#                        LEFT JOIN air.aqi_categories USING (category_id)
#                        LEFT JOIN air.yearly_transit USING (yearly_transit_id)
#                        WHERE city = 'Portland' AND
#                        state = 'Oregon'
#                        ORDER BY date"))

portland_data = metro_1mil %>%
  filter(city == 'Portland' & state == 'Oregon')

#portland_data <- as.data.frame(portland)
```

## Data Forecasting

To use the package, data must be in the format of a two column graph, with the first column being the date data, and the second being the variable being mapped and preddicted. In this case, we will be predicting AQI.
```{r}
pdx = portland_data %>%
  select(c(date, aqi)) %>%
  rename(
    ds = date,
    y = aqi
  )

head(pdx)
```

We begin the prophet forecast by transforming the dataframe into the prophet object.
```{r}
#| warning: false
pdxprophet = prophet(pdx) 
```

The future data is created with the make_future_dataframe function. Here we want one year of additional data to be forcasted.
```{r}
future <- make_future_dataframe(pdxprophet, periods = 365)
tail(future)
```

We predict future values based on the existing data and the future period. This will return the actual data and predictions, with an error range shown with the upper and lower bounds.
```{r}
forecast <- predict(pdxprophet, future)
tail(forecast[c('ds', 'yhat', 'yhat_lower', 'yhat_upper')])
```

To visualize this we can plot it. The black dots represent the actual values. The dark blue line represents the prediction made by the algorithm. The light blue transparent area represents the upper and lower bounds of the prediction. Right away, we can see the yearly increase in aqi every year during the late summer. The large spike in 2020 will be something to take a closer look at. This corresponds with the large forest fire in the Columbia Gorge. At the end, we can see forcasted data for the year 2023.
```{r}
plot(pdxprophet, forecast)
```

We can also see specific trends including the total (entire eight years), weekly, and yearly trends. This allows us to see how aqi goes up and down fairly consistantly based on the time of year, though the day of the week tends to have very little impact (it may look significant but it is only moving up and down less than 1.5 aqi between days). This allows us to see the consistant increase during the late summer to mid fall each year. 
```{r}
prophet_plot_components(pdxprophet, forecast)
```

## Cross Validation

We can cross validate the predictions to see how accurate they turned out to be. This will predict over the period from the cutoff date up to specified date in the ds column date. The forecast is made for each point between cutoff and cutoff + horizon. We have specified only to predict up to a year out as that is the amount of time we forcasted in the initial Portland forcast above. We can then compute the difference between y and yhat to see how accurate the prediction is.
```{r}
#| warning: false
pdx_cv <- cross_validation(pdxprophet, initial = 730, period = 180, horizon = 365, units = 'days')
head(pdx_cv)
```

This chart shows the mean squared error (MSE), root mean squared error (RMSE), mean absolute error (MAE), mean absolute percent error (MAPE), median absolute percent error (MDAPE) and coverage of the yhat_lower and yhat_upper estimates. As the horizon increases, the errors tend to increase, but overall they are not too large.
```{r}
pdx_perf <- performance_metrics(pdx_cv)
head(pdx_perf)
```

We can plot each of these metrics to see how accurate the predictions are over the estimated period. The light grey datapoints represent the mean absolute percent error. A datapoint with a x value 200 and y value 1 means it was predicted for a period of 200 days after the cutoff date, and was 1% off the actual value. We can see that most predictions are under 1%, making this a pretty decent estimation. The fact that they do not increase over time allows us to have a certain degree of confidence in the prediction even a year out. The blue line shows the mean of these datapoints.
```{r}
#mean absolute percent error
plot_cross_validation_metric(pdx_cv, metric = 'mape')
```
